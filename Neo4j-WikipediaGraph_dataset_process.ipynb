{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import wikipedia\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, preprocess_string, remove_stopwords, strip_tags, strip_punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(password=\"kshen3778\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n': (_5214855:Category:Page {id: 690070, isNew: false, isRedirect: false, title: 'Futurama'})},\n",
       " {'n': (_5214856:Category:Page {id: 690451, isNew: false, isRedirect: false, title: 'World_War_II'})},\n",
       " {'n': (_5214857:Category:Page {id: 690571, isNew: false, isRedirect: false, title: 'Programming_languages'})},\n",
       " {'n': (_5214858:Category:Page {id: 690578, isNew: false, isRedirect: false, title: 'Professional_wrestling'})},\n",
       " {'n': (_5214859:Category:Page {id: 690637, isNew: false, isRedirect: false, title: 'Algebra'})},\n",
       " {'n': (_5214860:Category:Page {id: 690649, isNew: false, isRedirect: false, title: 'Anime'})},\n",
       " {'n': (_5214861:Category:Page {id: 690672, isNew: false, isRedirect: false, title: 'Abstract_algebra'})},\n",
       " {'n': (_5214862:Category:Page {id: 690747, isNew: false, isRedirect: false, title: 'Mathematics'})},\n",
       " {'n': (_5214863:Category:Page {id: 690777, isNew: false, isRedirect: false, title: 'Linear_algebra'})},\n",
       " {'n': (_5214864:Category:Page {id: 690803, isNew: false, isRedirect: false, title: 'Calculus'})},\n",
       " {'n': (_5214865:Category:Page {id: 690889, isNew: false, isRedirect: false, title: 'Monarchs'})},\n",
       " {'n': (_5214866:Category:Page {id: 690932, isNew: false, isRedirect: false, title: 'British_monarchs'})},\n",
       " {'n': (_5214867:Category:Page {id: 690990, isNew: false, isRedirect: false, title: 'Star_Trek'})},\n",
       " {'n': (_5214868:Category:Page {id: 691008, isNew: false, isRedirect: false, title: 'People'})},\n",
       " {'n': (_5214869:Category:Page {id: 691014, isNew: false, isRedirect: false, title: 'Popes'})},\n",
       " {'n': (_5214870:Category:Page {id: 691015, isNew: false, isRedirect: false, title: 'Desserts'})},\n",
       " {'n': (_5214871:Category:Page {id: 691023, isNew: false, isRedirect: false, title: 'Fruit'})},\n",
       " {'n': (_5214872:Category:Page {id: 691070, isNew: false, isRedirect: false, title: 'Lists'})},\n",
       " {'n': (_5214873:Category:Page {id: 691117, isNew: false, isRedirect: false, title: 'Computer_science'})},\n",
       " {'n': (_5214874:Category:Page {id: 691123, isNew: false, isRedirect: false, title: 'The_Simpsons'})},\n",
       " {'n': (_5214875:Category:Page {id: 691136, isNew: false, isRedirect: false, title: 'Algorithms'})},\n",
       " {'n': (_5214876:Category:Page {id: 691150, isNew: false, isRedirect: false, title: 'Data_structures'})},\n",
       " {'n': (_5214877:Category:Page {id: 691158, isNew: false, isRedirect: false, title: 'Monty_Python'})},\n",
       " {'n': (_5214878:Category:Page {id: 691160, isNew: false, isRedirect: false, title: 'Middle-earth_places'})},\n",
       " {'n': (_5214879:Category:Page {id: 691175, isNew: false, isRedirect: false, title: 'Middle-earth_characters'})}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run(\"MATCH (n:Category) RETURN n LIMIT 25\").data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n': (_5214918:Category:Page {id: 691614, isNew: false, isRedirect: false, title: 'Cold_War'})}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run(\"MATCH (n:Category { title: 'Cold_War' }) RETURN n\").data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all sub cat\n",
    "cats = graph.run(\"MATCH (n:Category{title:'Constraint_logic_programming'})-[:BELONGS_TO*..1]-(p:Category) RETURN p LIMIT 100\").data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p': (_6124108:Category:Page {id: 22968506, isNew: false, isRedirect: false, title: 'Constraint_programming'})},\n",
       " {'p': (_5594005:Category:Page {id: 1188828, isNew: false, isRedirect: false, title: 'Logic_programming'})}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Areas_of_computer_science',\n",
       " 'Cognitive_science',\n",
       " 'Computational_neuroscience',\n",
       " 'Cybernetics',\n",
       " 'Emerging_technologies',\n",
       " 'Formal_sciences',\n",
       " 'Futurology',\n",
       " 'Intelligence_by_type',\n",
       " 'Personhood',\n",
       " 'Technology_in_society',\n",
       " 'Unsolved_problems_in_computer_science']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getBadCategories(\"Artificial_intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if a specific sub category references the select category an two way relationship (which we don't want)\n",
    "subs = graph.run(\"MATCH (n:Category{title:'Emerging_technologies'})-[:BELONGS_TO*..1]-(p:Category) RETURN p LIMIT 100\").data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify if category actually exists on online Wikipedia\n",
    "def categoryExist(name):\n",
    "    res = requests.get(\"https://en.wikipedia.org/wiki/Category:\" + name)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    div = soup.find(\"div\", {\"id\": \"mw-normal-catlinks\"})\n",
    "    if(div):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#Use beautifulsoup to scrape the bottom categories of a parent category (these we don't want)\n",
    "def getBadCategories(parent):\n",
    "    res = requests.get(\"https://en.wikipedia.org/wiki/Category:\" + parent)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    div = soup.find(\"div\", {\"id\": \"mw-normal-catlinks\"})\n",
    "    if(div):\n",
    "        to_return = []\n",
    "        for item in div.findAll(\"li\"):\n",
    "            to_return.append(\"_\".join(item.get_text().split(\" \")))\n",
    "        return to_return\n",
    "    else:\n",
    "        #parent does not exist\n",
    "        return []\n",
    "\n",
    "#get all immediate Wikipedia subcategories of main minus two way connections\n",
    "def getAllSubCat(parent):\n",
    "    all_cats = graph.run(\"MATCH (n:Category{title:'\" + parent + \"'})-[:BELONGS_TO*..1]-(p:Category) RETURN p LIMIT 100\").data()\n",
    "    bad_cats = getBadCategories(parent)\n",
    "    filtered = []\n",
    "    for category in all_cats:\n",
    "        cat_title = category['p'][\"title\"]\n",
    "        if (not (cat_title in bad_cats)):\n",
    "            filtered.append(cat_title)\n",
    "    #search all these categories to see if any of them match the other way (if so, we remove)\n",
    "#     filtered = []\n",
    "#     for category in all_cats:\n",
    "#         cat_title = category['p'][\"title\"]\n",
    "#         subs = graph.run(\"MATCH (n:Category{title:'\" + cat_title + \"'})-[:BELONGS_TO*..1]-(p:Category) RETURN p LIMIT 100\").data()\n",
    "#         found = False\n",
    "#         for category_2 in subs:\n",
    "#             sub_title = category_2['p'][\"title\"]\n",
    "#             if(sub_title == parent):\n",
    "#                 found = True\n",
    "#         if (not found):\n",
    "#             filtered.append(cat_title)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial_neural_networks',\n",
       " 'Applied_machine_learning',\n",
       " 'Unsupervised_learning',\n",
       " 'Structured_prediction',\n",
       " 'Loss_functions',\n",
       " 'Support_vector_machines',\n",
       " 'Latent_variable_models',\n",
       " 'Cluster_analysis',\n",
       " 'Signal_processing_conferences',\n",
       " 'Artificial_intelligence_conferences',\n",
       " 'Data_mining_and_machine_learning_software',\n",
       " 'Machine_learning_algorithms',\n",
       " 'Bayesian_networks',\n",
       " 'Machine_learning_portal',\n",
       " 'Statistical_natural_language_processing',\n",
       " 'Markov_models',\n",
       " 'Evolutionary_algorithms',\n",
       " 'Genetic_programming',\n",
       " 'Datasets_in_machine_learning',\n",
       " 'Dimension_reduction',\n",
       " 'Machine_learning_researchers',\n",
       " 'Supervised_learning',\n",
       " 'Semisupervised_learning',\n",
       " 'Computational_learning_theory',\n",
       " 'Kernel_methods_for_machine_learning',\n",
       " 'Learning_in_computer_vision',\n",
       " 'Inductive_logic_programming',\n",
       " 'Log-linear_models',\n",
       " 'Classification_algorithms',\n",
       " 'Machine_learning_task',\n",
       " 'Ensemble_learning']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAllSubCat(\"Machine_learning\")\n",
    "#getBadCategories(\"Constraint_logic_programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-8a5fcb5cee48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MATCH path = (start:Category{title:'Machine_learning'})-[*]-(end:Category{title:'Court_titles'}) RETURN path LIMIT 3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py2neo/database.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautocommit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcypher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseparate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py2neo/database.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                              \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                              \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                              entities=entities))\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCypherError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mGraphError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"message\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py2neo/internal/connectors.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, statement, parameters, tx, graph, keys, entities)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_in_tx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py2neo/internal/connectors.py\u001b[0m in \u001b[0;36m_run_1\u001b[0;34m(self, statement, parameters, graph, keys, entities)\u001b[0m\n\u001b[1;32m    253\u001b[0m                     on_success=result.update_metadata, on_failure=self._fail, on_summary=result.done)\n\u001b[1;32m    254\u001b[0m         \u001b[0mcx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mcx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknown_errors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munresolved_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36m_fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mdetails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neobolt/direct.py\u001b[0m in \u001b[0;36m_receive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreceived\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph.run(\"MATCH path = (start:Category{title:'Machine_learning'})-[*]-(end:Category{title:'Court_titles'}) RETURN path LIMIT 3\").data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = []\n",
    "all_relations = [] #child parent\n",
    "def buildGraph(root, path):\n",
    "    path = path + \"/\" + root\n",
    "    print(\"Current Path: \" + path)\n",
    "    if(not categoryExist(root)):\n",
    "        print(\"Category DNE\")\n",
    "        return\n",
    "    #add the node\n",
    "    all_nodes.append(root)\n",
    "    \n",
    "    #get all subcategories\n",
    "    sub_cat = getAllSubCat(root)\n",
    "    if(len(sub_cat) == 0): #base case\n",
    "        return\n",
    "    \n",
    "    #add all the relationships\n",
    "    for item in sub_cat:\n",
    "        all_relations.append(item + \" \" + root)\n",
    "   \n",
    "    #recurse on all sub nodes\n",
    "    for item in sub_cat:\n",
    "        buildGraph(item, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Path: /Machine_learning\n",
      "Current Path: /Machine_learning/Artificial_neural_networks\n",
      "Current Path: /Machine_learning/Artificial_neural_networks/Neural_network_software\n",
      "Current Path: /Machine_learning/Artificial_neural_networks/Deep_learning\n",
      "Current Path: /Machine_learning/Applied_machine_learning\n",
      "Current Path: /Machine_learning/Applied_machine_learning/AlphaGo\n",
      "Current Path: /Machine_learning/Unsupervised_learning\n",
      "Current Path: /Machine_learning/Structured_prediction\n",
      "Current Path: /Machine_learning/Structured_prediction/Graphical_models\n",
      "Current Path: /Machine_learning/Structured_prediction/Graphical_models/Bayesian_networks\n",
      "Current Path: /Machine_learning/Structured_prediction/Graphical_models/Causal_inference\n",
      "Current Path: /Machine_learning/Structured_prediction/Graphical_models/Markov_networks\n",
      "Current Path: /Machine_learning/Loss_functions\n",
      "Current Path: /Machine_learning/Support_vector_machines\n",
      "Current Path: /Machine_learning/Latent_variable_models\n",
      "Current Path: /Machine_learning/Latent_variable_models/Structural_equation_models\n",
      "Current Path: /Machine_learning/Latent_variable_models/Factor_analysis\n",
      "Current Path: /Machine_learning/Cluster_analysis\n",
      "Current Path: /Machine_learning/Cluster_analysis/Equivalence_classes\n",
      "Category DNE\n",
      "Current Path: /Machine_learning/Cluster_analysis/Clustering_criteria\n",
      "Current Path: /Machine_learning/Cluster_analysis/Cluster_analysis_algorithms\n",
      "Current Path: /Machine_learning/Signal_processing_conferences\n",
      "Current Path: /Machine_learning/Artificial_intelligence_conferences\n",
      "Current Path: /Machine_learning/Data_mining_and_machine_learning_software\n",
      "Current Path: /Machine_learning/Data_mining_and_machine_learning_software/Social_network_analysis_software\n",
      "Current Path: /Machine_learning/Machine_learning_algorithms\n",
      "Current Path: /Machine_learning/Machine_learning_algorithms/Genetic_algorithms\n",
      "Current Path: /Machine_learning/Machine_learning_algorithms/Genetic_algorithms/Artificial_immune_systems\n",
      "Current Path: /Machine_learning/Machine_learning_algorithms/Genetic_algorithms/Gene_expression_programming\n",
      "Current Path: /Machine_learning/Bayesian_networks\n",
      "Current Path: /Machine_learning/Machine_learning_portal\n",
      "Category DNE\n",
      "Current Path: /Machine_learning/Statistical_natural_language_processing\n",
      "Current Path: /Machine_learning/Statistical_natural_language_processing/Language_modeling\n",
      "Current Path: /Machine_learning/Markov_models\n",
      "Current Path: /Machine_learning/Markov_models/Hidden_Markov_models\n",
      "Current Path: /Machine_learning/Markov_models/Markov_networks\n",
      "Current Path: /Machine_learning/Evolutionary_algorithms\n",
      "Current Path: /Machine_learning/Evolutionary_algorithms/Genetic_programming\n",
      "Current Path: /Machine_learning/Evolutionary_algorithms/Genetic_algorithms\n",
      "Current Path: /Machine_learning/Evolutionary_algorithms/Genetic_algorithms/Artificial_immune_systems\n",
      "Current Path: /Machine_learning/Evolutionary_algorithms/Genetic_algorithms/Gene_expression_programming\n",
      "Current Path: /Machine_learning/Evolutionary_algorithms/Gene_expression_programming\n",
      "Current Path: /Machine_learning/Evolutionary_algorithms/Nature-inspired_metaheuristics\n",
      "Current Path: /Machine_learning/Genetic_programming\n",
      "Current Path: /Machine_learning/Datasets_in_machine_learning\n",
      "Current Path: /Machine_learning/Datasets_in_machine_learning/Datasets_in_computer_vision\n",
      "Current Path: /Machine_learning/Dimension_reduction\n",
      "Current Path: /Machine_learning/Dimension_reduction/Factor_analysis\n",
      "Current Path: /Machine_learning/Machine_learning_researchers\n",
      "Current Path: /Machine_learning/Supervised_learning\n",
      "Current Path: /Machine_learning/Semisupervised_learning\n",
      "Current Path: /Machine_learning/Computational_learning_theory\n",
      "Current Path: /Machine_learning/Kernel_methods_for_machine_learning\n",
      "Current Path: /Machine_learning/Kernel_methods_for_machine_learning/Support_vector_machines\n",
      "Current Path: /Machine_learning/Learning_in_computer_vision\n",
      "Current Path: /Machine_learning/Inductive_logic_programming\n",
      "Current Path: /Machine_learning/Log-linear_models\n",
      "Current Path: /Machine_learning/Classification_algorithms\n",
      "Current Path: /Machine_learning/Classification_algorithms/Ensemble_learning\n",
      "Current Path: /Machine_learning/Classification_algorithms/Artificial_neural_networks\n",
      "Current Path: /Machine_learning/Classification_algorithms/Artificial_neural_networks/Neural_network_software\n",
      "Current Path: /Machine_learning/Classification_algorithms/Artificial_neural_networks/Deep_learning\n",
      "Current Path: /Machine_learning/Classification_algorithms/Decision_trees\n",
      "Current Path: /Machine_learning/Machine_learning_task\n",
      "Current Path: /Machine_learning/Ensemble_learning\n"
     ]
    }
   ],
   "source": [
    "buildGraph(\"Machine_learning\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine_learning',\n",
       " 'Artificial_neural_networks',\n",
       " 'Neural_network_software',\n",
       " 'Deep_learning',\n",
       " 'Applied_machine_learning',\n",
       " 'AlphaGo',\n",
       " 'Unsupervised_learning',\n",
       " 'Structured_prediction',\n",
       " 'Graphical_models',\n",
       " 'Bayesian_networks',\n",
       " 'Causal_inference',\n",
       " 'Markov_networks',\n",
       " 'Loss_functions',\n",
       " 'Support_vector_machines',\n",
       " 'Latent_variable_models',\n",
       " 'Structural_equation_models',\n",
       " 'Factor_analysis',\n",
       " 'Cluster_analysis',\n",
       " 'Clustering_criteria',\n",
       " 'Cluster_analysis_algorithms',\n",
       " 'Signal_processing_conferences',\n",
       " 'Artificial_intelligence_conferences',\n",
       " 'Data_mining_and_machine_learning_software',\n",
       " 'Social_network_analysis_software',\n",
       " 'Machine_learning_algorithms',\n",
       " 'Genetic_algorithms',\n",
       " 'Artificial_immune_systems',\n",
       " 'Gene_expression_programming',\n",
       " 'Bayesian_networks',\n",
       " 'Statistical_natural_language_processing',\n",
       " 'Language_modeling',\n",
       " 'Markov_models',\n",
       " 'Hidden_Markov_models',\n",
       " 'Markov_networks',\n",
       " 'Evolutionary_algorithms',\n",
       " 'Genetic_programming',\n",
       " 'Genetic_algorithms',\n",
       " 'Artificial_immune_systems',\n",
       " 'Gene_expression_programming',\n",
       " 'Gene_expression_programming',\n",
       " 'Nature-inspired_metaheuristics',\n",
       " 'Genetic_programming',\n",
       " 'Datasets_in_machine_learning',\n",
       " 'Datasets_in_computer_vision',\n",
       " 'Dimension_reduction',\n",
       " 'Factor_analysis',\n",
       " 'Machine_learning_researchers',\n",
       " 'Supervised_learning',\n",
       " 'Semisupervised_learning',\n",
       " 'Computational_learning_theory',\n",
       " 'Kernel_methods_for_machine_learning',\n",
       " 'Support_vector_machines',\n",
       " 'Learning_in_computer_vision',\n",
       " 'Inductive_logic_programming',\n",
       " 'Log-linear_models',\n",
       " 'Classification_algorithms',\n",
       " 'Ensemble_learning',\n",
       " 'Artificial_neural_networks',\n",
       " 'Neural_network_software',\n",
       " 'Deep_learning',\n",
       " 'Decision_trees',\n",
       " 'Machine_learning_task',\n",
       " 'Ensemble_learning']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial_neural_networks Machine_learning',\n",
       " 'Applied_machine_learning Machine_learning',\n",
       " 'Unsupervised_learning Machine_learning',\n",
       " 'Structured_prediction Machine_learning',\n",
       " 'Loss_functions Machine_learning',\n",
       " 'Support_vector_machines Machine_learning',\n",
       " 'Latent_variable_models Machine_learning',\n",
       " 'Cluster_analysis Machine_learning',\n",
       " 'Signal_processing_conferences Machine_learning',\n",
       " 'Artificial_intelligence_conferences Machine_learning',\n",
       " 'Data_mining_and_machine_learning_software Machine_learning',\n",
       " 'Machine_learning_algorithms Machine_learning',\n",
       " 'Bayesian_networks Machine_learning',\n",
       " 'Machine_learning_portal Machine_learning',\n",
       " 'Statistical_natural_language_processing Machine_learning',\n",
       " 'Markov_models Machine_learning',\n",
       " 'Evolutionary_algorithms Machine_learning',\n",
       " 'Genetic_programming Machine_learning',\n",
       " 'Datasets_in_machine_learning Machine_learning',\n",
       " 'Dimension_reduction Machine_learning',\n",
       " 'Machine_learning_researchers Machine_learning',\n",
       " 'Supervised_learning Machine_learning',\n",
       " 'Semisupervised_learning Machine_learning',\n",
       " 'Computational_learning_theory Machine_learning',\n",
       " 'Kernel_methods_for_machine_learning Machine_learning',\n",
       " 'Learning_in_computer_vision Machine_learning',\n",
       " 'Inductive_logic_programming Machine_learning',\n",
       " 'Log-linear_models Machine_learning',\n",
       " 'Classification_algorithms Machine_learning',\n",
       " 'Machine_learning_task Machine_learning',\n",
       " 'Ensemble_learning Machine_learning',\n",
       " 'Neural_network_software Artificial_neural_networks',\n",
       " 'Deep_learning Artificial_neural_networks',\n",
       " 'AlphaGo Applied_machine_learning',\n",
       " 'Graphical_models Structured_prediction',\n",
       " 'Bayesian_networks Graphical_models',\n",
       " 'Causal_inference Graphical_models',\n",
       " 'Markov_networks Graphical_models',\n",
       " 'Structural_equation_models Latent_variable_models',\n",
       " 'Factor_analysis Latent_variable_models',\n",
       " 'Equivalence_classes Cluster_analysis',\n",
       " 'Clustering_criteria Cluster_analysis',\n",
       " 'Cluster_analysis_algorithms Cluster_analysis',\n",
       " 'Social_network_analysis_software Data_mining_and_machine_learning_software',\n",
       " 'Genetic_algorithms Machine_learning_algorithms',\n",
       " 'Artificial_immune_systems Genetic_algorithms',\n",
       " 'Gene_expression_programming Genetic_algorithms',\n",
       " 'Language_modeling Statistical_natural_language_processing',\n",
       " 'Hidden_Markov_models Markov_models',\n",
       " 'Markov_networks Markov_models',\n",
       " 'Genetic_programming Evolutionary_algorithms',\n",
       " 'Genetic_algorithms Evolutionary_algorithms',\n",
       " 'Gene_expression_programming Evolutionary_algorithms',\n",
       " 'Nature-inspired_metaheuristics Evolutionary_algorithms',\n",
       " 'Artificial_immune_systems Genetic_algorithms',\n",
       " 'Gene_expression_programming Genetic_algorithms',\n",
       " 'Datasets_in_computer_vision Datasets_in_machine_learning',\n",
       " 'Factor_analysis Dimension_reduction',\n",
       " 'Support_vector_machines Kernel_methods_for_machine_learning',\n",
       " 'Ensemble_learning Classification_algorithms',\n",
       " 'Artificial_neural_networks Classification_algorithms',\n",
       " 'Decision_trees Classification_algorithms',\n",
       " 'Neural_network_software Artificial_neural_networks',\n",
       " 'Deep_learning Artificial_neural_networks']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save graph to files\n",
    "with open('nodes.txt', 'w') as f:\n",
    "    for item in all_nodes:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open('relations.txt', 'w') as f:\n",
    "    for item in all_relations:\n",
    "        f.write(\"%s\\n\" % item)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = gensim.utils.simple_preprocess(x)\n",
    "    x = \" \".join(x)\n",
    "    \n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation, remove_stopwords]\n",
    "    x = preprocess_string(x, CUSTOM_FILTERS)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Machine_learning\n",
      "=======\n",
      "machine learn study algorithm statistical model system use perform specific task pattern inference instead subset artificial intelligence machine learn algorithm build mathematical model base sample datum know training data order prediction decision program perform task machine learn algorithm variety application email vision algorithm perform task machine learn related computational statistic focus make prediction study mathematical optimization method theory application field machine learning datum mining field study machine learning focus datum analysis unsupervised learning application problem machine learn predictive machine learning provide definition algorithm study machine learning field program learn experience class task performance measure performance task measure improve experience definition task machine learn definition define field term compute intelligence machine machine characteristic machine machine learn task machine learn task category supervise learn algorithm build mathematical model set data contain input desire output example task image contain object training datum supervise learn algorithm include image object input image label output contain object input semi supervise learn algorithm mathematical model training datum sample input label classification algorithm regression algorithm type supervise learn classification algorithm output set value classification algorithm email input email output email algorithm email output prediction represent value true regression algorithm continuous output mean value example continuous value object unsupervised learn algorithm build mathematical model set data contain input desire output label unsupervised learn algorithm structure datum like group datum unsupervised learn discover pattern data group input category feature learn process feature input set datum learn algorithm desire output train label set input base input training label human user reinforcement learn algorithm give form positive negative reinforcement environment learn game human algorithm machine learning include model program give set language similar machine learn algorithm probability density function density problem learn algorithm learn inductive bias base experience learn algorithm generate sequence learn experience know new self human use learn relationship field field game artificial intelligence term machine learn book machine learn research book learning machine machine learning pattern classification machine learn related pattern recognition book report give neural network learn machine learning artificial intelligence ai researcher machine learn datum attempt approach problem method term neural network model linear model statistic probabilistic employ medical increase knowledge base approach ai machine learn probabilistic system theoretical problem datum representation system come ai statistic knowledge base learning ai lead inductive logic program statistical research field ai pattern recognition information neural network research ai time ai field researcher include come machine learning separate field field goal artificial intelligence problem nature focus approach ai method model statistic probability theory increase information ability datum mining machine learn datum mining employ method machine learn focus prediction base know learn training datum datum mining focus discovery previously unknown datum analysis knowledge discovery database datum mining use machine learning method different goal machine learning employ datum mining method unsupervised learn improve accuracy research separate conference separate journal come machine learning performance usually ability know knowledge knowledge discovery datum mining task discovery previously unknown knowledge know knowledge unsupervised method supervised method task supervised method training datum optimization machine learn optimization learning problem loss function training set example loss function prediction model train problem instance example classification label instance model train predict label set example field goal generalization optimization algorithm loss training set machine learning loss sample statistic machine learning statistic related field term method goal statistic inference sample machine learning predictive pattern machine learn theoretical tool statistic term datum field statistical datum model algorithmic model algorithmic model mean machine learn algorithm like method machine learn lead field statistical learning theory experience generalization context ability learn machine perform new example task experience learn datum set training example come unknown probability consider space build model space prediction new computational analysis machine learn algorithm performance theoretical know computational learning theory training set learning theory usually performance algorithm instead probabilistic performance common bias way generalization good performance context generalization complexity hypothesis complexity function datum hypothesis function model fit data complexity model increase training hypothesis model generalization addition performance learn study time complexity learn computational learn theory consider polynomial time time complexity result positive result class function learn polynomial time negative result class learn polynomial time approach type learn algorithm type machine learn algorithm approach type datum input output type task problem solve supervise learn supervise learn algorithm build mathematical model set data contain input desire output datum know training data set training example training example input desire output know signal mathematical model training example represent vector call feature vector training datum represent matrix optimization function supervise learn algorithm learn function predict output associate new input function allow algorithm output input training data algorithm improve accuracy output prediction time learn perform task supervised learn algorithm include classification regression classification algorithm output set value regression algorithm output value similarity learning area supervise machine learn related regression classification goal learn example similarity function measure similar related object application recommendation system semi supervised learn algorithm training example training label improve model supervised learn training label label result large training set unsupervised learn unsupervised learn algorithm set datum contain input structure datum like group datum algorithm learn test datum label instead unsupervised learn algorithm identify datum base new data application unsupervised learning field density statistic unsupervised learning datum feature cluster analysis set observation subset call cluster observation cluster similar observation different cluster different technique different structure datum define similarity example similarity cluster cluster method base density semi supervise learning semi supervised learning unsupervised learning label training datum supervise learn label training datum machine learning researcher datum label data learn accuracy reinforcement learn reinforcement learning area machine learn software action environment field study game theory theory research information theory base optimization system intelligence statistic genetic algorithm machine learning environment typically represent decision process reinforcement learn algorithm use programming technique reinforcement learn algorithm knowledge mathematical model model reinforcement learn algorithm learn game human self learn self learn machine learn neural network self learn caa learn caa self learn algorithm compute decision action emotion consequence situation emotion self learn algorithm matrix machine learn situation perform action receive consequence situation compute emotion consequence situation input situation output action separate reinforcement input input environment value reinforcement emotion consequence situation caa exist environment environment genetic environment receive emotion situation environment receive vector genetic environment caa learn goal environment contain situation feature learn learn algorithm discover representation input provide training example include component analysis cluster analysis feature learn algorithm call representation learn algorithm attempt information input way make perform classification prediction technique allow input come unknown datum generate feature allow machine learn feature use perform specific task feature learning supervise unsupervised supervised feature learning feature learn label input datum example include artificial neural network supervise dictionary learning unsupervised feature learning feature learn input datum example include dictionary learning component analysis matrix form cluster learn algorithm attempt learn representation dimensional sparse algorithm attempt learn representation sparse mean mathematical model learn algorithm learn dimensional representation representation datum high dimensional vector learn algorithm discover representation feature high feature define term generate feature machine learn representation datum feature learn machine learn task classification input process real datum image datum attempt define specific feature discover feature representation algorithm sparse dictionary learning sparse dictionary learning feature learn method training example represent linear function sparse matrix method solve method sparse dictionary learning algorithm sparse dictionary learning apply classification problem class previously training example dictionary class build new training example associate class represent dictionary sparse dictionary learning apply image image represent image dictionary anomaly detection datum mining anomaly detection know detection item observation datum typically item represent medical problem anomaly context network detection object object pattern common statistical definition object detection method unsupervised algorithm fail datum instead cluster analysis algorithm cluster form pattern category anomaly detection technique exist unsupervised anomaly detection technique anomaly test datum set instance datum set normal instance fit datum set supervised anomaly detection technique datum set label normal train statistical classification problem nature detection semi supervise anomaly detection technique model represent normal give normal training datum set test test instance generate model association rule association rule learning rule base machine learning method relationship variable large database identify rule discover database measure rule base machine learn term machine learning method learn rule apply knowledge define characteristic rule base machine learn algorithm set rule represent knowledge machine learn algorithm identify model apply instance order prediction rule base machine learning approach include learn system association rule learn artificial system base rule association rule discover large datum system example rule datum information decision addition analysis association rule employ application area include mining detection continuous sequence mining association rule learn typically consider order item learn system rule base machine learn algorithm discovery component typically genetic algorithm learn component perform supervised learn reinforcement learn unsupervised learning identify set context rule apply knowledge order prediction inductive logic programming approach rule learn logic programming representation input example knowledge hypothesis give know knowledge set example represent database logic program positive negative example inductive programming related field consider programming language represent hypothesis logic program program inductive logic programming language theoretical inductive machine learn build model inference program logic program positive negative example term inductive theory mathematical order set model perform machine learning model train training datum process datum prediction type model research machine learning system artificial neural network artificial neural network system system neural network brain system learn perform task consider example program task specific rule model base call artificial neuron model neuron brain connection like brain information signal artificial neuron artificial neuron receive signal process signal artificial neuron common signal connection artificial neuron real output artificial neuron compute non linear function input connection artificial neuron call artificial neuron typically learn increase signal connection artificial neuron signal signal typically artificial neuron layer different layer perform different input signal layer input layer layer output layer layer time goal approach solve problem way human brain time perform specific task lead artificial neural network variety task include vision recognition machine network game medical learning layer artificial neural network approach model way human brain process vision application learn vision recognition decision tree decision tree learn use decision tree predictive model observation item represent item value represent predictive approach statistic datum mining machine learning tree model variable set value call classification tree tree structure represent class label represent feature lead class label decision tree variable continuous value typically real call regression tree decision analysis decision tree represent decision decision make datum mining decision tree datum result classification tree input decision make vector machine vector machine svm vector network set related supervised learning method classification regression give set training example category svm training algorithm build model predict new example category svm training algorithm non probabilistic linear method exist use svm probabilistic classification set addition perform linear classification perform non linear classification call input high dimensional feature space regression analysis regression analysis large variety statistical method relationship input variable associate feature common form linear regression good fit give datum mathematical method high bias regression non linear problem model include polynomial regression fit regression statistical classification regression non input variable high dimensional space bayesian network bayesian network network model probabilistic model represent set variable example bayesian network represent probabilistic relationship give network compute probability algorithm exist perform inference learn bayesian network model sequence variable like signal sequence call bayesian network generalization bayesian network represent solve decision problem call genetic algorithm genetic algorithm algorithm technique process method generate new good give problem machine learn genetic algorithm machine learning technique improve performance genetic algorithm training model usually machine learning model data order perform usually train machine learning model large sample datum training set datum training set image datum user training machine learning model learn learn new approach training machine learning model training process allow user datum increase training process example use machine learn train prediction model user google application application machine learn include program predict user improve accuracy exist recommendation algorithm researcher research theory build model good pattern recommendation recommendation journal research use machine learning predict predict medical machine learn medical software report machine learn algorithm apply field study previously nature research book machine learn machine learn field machine learning program fail result datum datum datum bias problem task algorithm tool people problem self fail attempt use machine learn fail time bias machine learning approach different datum bias machine learning train predict new group represent training datum train data machine learn bias language model learn datum contain human like bias machine learning system bias people google people google training datum real similar non people system test learn language use machine learn bias machine learning use human good artificial intelligence include artificial ai people people people tool model classification machine learning model accuracy technique like method datum training test set training set test set performance training model test set method datum subset perform consider subset subset training model addition method sample instance model accuracy addition accuracy report mean true positive rate true negative rate report positive rate negative rate rate fail characteristic method model ability previously rate provide information characteristic associate area machine learning system train bias bias use algorithmic bias example data lead machine learn bias similarity datum algorithmic rule machine learn human language contain bias machine train language learn bias form bias health care health care system generate machine true improve health care increase example algorithm provide test algorithm machine learn health care provide tool bias previously bias software software contain variety machine learn algorithm include software software software journal journal machine learn research machine learn nature machine intelligence neural conference conference neural information system conference machine learn machine learn database machine learn software machine learn google machine learning use\n",
      "=====Artificial_neural_networks\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial neural network ann system computing system biological neural network brain system learn perform task consider example task example image recognition learn identify image cat example image cat cat result identify cat image prior cat example cat identify example process ann base connect unit node call artificial neuron model neuron biological brain connection biological brain signal neuron artificial neuron receive signal process signal neuron connect ann signal connection real number output neuron compute non function input connection call neuron typically weight adjust learn weight increase signal connection neuron threshold signal signal threshold typically neuron layer layer perform input signal layer input layer layer output layer layer multiple time goal ann approach problem human brain time perform task anns task include speech recognition machine network game consider human create model neural network create learn base neural know learn machine call simulate network create network layer method datum handle basic backpropagation control theory principle dynamic programming general method network function backpropagation parameter error gradient backpropagation algorithm training layer network method neural network follow basic process power process neural network introduce recognition level network train level time unsupervised learn backpropagation learn high level layer real value machine model layer create network learn high level concept cat image unsupervised training increase compute power gpus computing allow use large network image recognition problem know deep learning gradient problem gpus backpropagation layer neural network ann begin win ann approach human level task pattern recognition machine learn example long short term memory win connect recognition prior learn pattern human recognition model anns begin architecture human brain perform task algorithm result biological neuron connect pattern allow output neuron input network form artificial neural network simulate neuron neuron node connect node correspond biological connection weight node component neuron ann biological concept artificial neuron receive input input state activation threshold activation function produce output output function input external datum image output task image activation function input value change small change input produce small change output connection weight network connection connection output neuron input neuron connection weight give neuron multiple input output connection function function compute input neuron output neuron connection weight term result neuron typically multiple layer deep learning neuron layer connect neuron follow layer layer receive external data input layer layer produce result output layer layer layer network layer multiple connection pattern connect neuron layer connect neuron layer neuron layer connect neuron layer reduce number neuron layer neuron connection form know network network allow connection neuron layer know network hyperparameter hyperparameter value set learning process begin value parameter learn example hyperparameter include learn rate number layer batch size value hyperparameter hyperparameter example size layer depend number layer learn learn network handle task consider observation learn adjust weight threshold network accuracy result minimize error learn observation reduce error rate learning error rate typically learn error rate high network typically define cost function learn long output learning cost frequently define value output number error low output cat cat small learning reduce observation learn model application optimization theory statistical learning rate learn rate define size step model take adjust error observation high learning rate training time low accuracy low learning rate take long potential accuracy optimization error increase network connection weight rate use learning rate increase concept allow gradient change weight weight depend change gradient value change cost function define cost function frequently function property arise model model model probability cost backpropagation backpropagation method adjust connection weight error learning error connection gradient cost function give state weight weight stochastic gradient method learning machine network train network non neural network learn learning supervise learn unsupervised learn reinforcement learn correspond learning task supervise learn learning use set input output learn task produce output input cost function cost error minimize error network output output task learning pattern recognition know classification know function approximation supervise learn data speech recognition learn form function solution unsupervised learn unsupervised learn input datum give cost function function datum displaystyle textstyle network output cost function task model property model parameter example consider model displaystyle textstyle displaystyle textstyle cost displaystyle textstyle minimize cost produce value displaystyle textstyle datum cost function form depend application example information displaystyle textstyle displaystyle textstyle statistical probability model give data example task unsupervised learn general problem application include statistical distribution reinforcement learn application game take action receive environment goal win game low cost reinforcement learn weight network perform action minimize long term cost time perform action environment observation cost long term cost action cost prior learning environment model decision process state displaystyle textstyle s s action displaystyle textstyle state know probability distribution cost distribution displaystyle textstyle s observation distribution displaystyle textstyle s distribution displaystyle textstyle s s define distribution action give observation take define low cost anns learn component application dynamic programming ann give programming problem game resource anns accuracy reduce solution control problem task reinforcement learn control problem game decision task self learn self learn neural network introduce neural network self learn crossbar caa input situation output action behavior external input external reinforcement input environment caa compute crossbar decision action emotion situation emotion give memory crossbar self learn algorithm perform follow situation perform action receive situation compute emotion situation crossbar memory value reinforcement emotion situation caa exist environment environment environment receive emotion situation environment receive environment caa learn goal behavior environment situation distribution set allow model minimize cost method programming simulate non method optimization learn algorithm learn algorithm model neural network learn stochastic batch stochastic learning input create weight batch learn weight adjust base batch input error batch stochastic learning introduce process local gradient data reduce network local batch learn typically local perform batch error use batch small batch batch select datum set type anns state multiple type component include number unit number layer unit weight dynamic type allow learn learn produce result type allow require learn type hardware general include neural network processing datum long short term memory gradient problem handle signal low high component large speech recognition speech real network network multiple network task win game input network design neural architecture use machine learning ann design approach design network design system basic algorithm model use result network system include design include number type network layer size connection type hyperparameter define design learn neuron layer learning rate step use artificial neural network require model depend data application model learn learn algorithm exist learn algorithm algorithm hyperparameter train datum set select algorithm training datum require model cost function learn algorithm select result ann ann follow function approximation include time approximation model classification include pattern recognition decision datum processing include include control include control application model process artificial neural network application application include control control process control resource general game pattern recognition system signal classification recognition recognition speech recognition system datum machine network anns cancer include cancer cancer cancer cancer information anns anns model model ann example machine learn identify ann system design network anns simulate property system brain anns short term behavior individual neuron dynamic neural arise individual neuron behavior arise neural consider long short term neural system learn memory individual neuron level property power function approximation number neuron require network weight learn parameter architecture value weight real number value weight power machine number neuron connection use value weight result machine power model property correspond model give function information network model solution local exist depend cost function model optimization method begin local large data parameter method application goal create example training arise system network parameter approach training use training select hyperparameter minimize error use form concept perform select large prior probability model statistical learning theory goal minimize correspond error training set error datum supervise neural network use error cost function use statistical method train model set value network output distribution long output probability distribution network activation function function output layer neural network component component base network output probability classification give classification activation function displaystyle train neural network require train real potential solution include training example optimization algorithm large step change network connection follow example example call batch introduce algorithm theory ann function backpropagation step exist biological neural network information real neuron know neuron action potential frequently activation neuron receive action potential frequently information neuron neuron principle information handle biological neural network know anns general principle process information principle define network allow statistical basic function artificial neural network learn recognition result artificial neural network computing system human solution learn neural network handle task game neural network high create number probability resource neural machine biological brain use deep brain brain self signal statistical hardware large neural network require computing resource brain hardware task processing signal neuron simulate neuron architecture memory signal connection neuron require power time neural network hardware computing power gpus increase backpropagation algorithm training network layer deep use gpus reduce training time hardware non neural network type neural network processing call processing unit learn ann learn biological neural network learn algorithm neural network general principle allow learn machine example local non local learning deep architecture approach model neural network approach human external neural network neural network type brain human individual neuron neural network\n",
      "=====Neural_network_software\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural network software research develop artificial neural network software biological neural network adaptive artificial learn simulator neural network simulator software application artificial biological neural network type neural network produce neural network software simulator simulator neural network research simulator type neural network software research neural network type software neural network artificial neural network simulator component base development environment research platform artificial neural network simulator include neural network simulator neural biological neural network software simulator biological neural biological network simulator include datum analysis simulator research simulator datum analysis simulator application artificial neural network datum mining datum analysis simulator development environment datum analysis simulator use simple neural network datum analysis simulator use network type software use neural datum analysis simulator simulator neural network provide simple software software software develop platform development software use tlearn software provide simulator tlearn allow basic network simple network simple tlearn basic simulator basic application platform provide simple tlearn wintempla include network neural network network neural base wintempla neural wintempla neural network wintempla development environment development environment neural network software develop custom type neural network neural network environment analysis component base type development environment use base component base neural network adaptive component allow custom network custom component network allow adaptive adaptive component datum component base component base development environment develop neural network component software component platform component base development environment include software software component base environment include component base development environment simulator learn develop custom neural network neural network custom language platform basic type neural network simple neural network custom provide language neural network model application language model language pmml pmml base language provide application neural network model datum mining model pmml application pmml provide application model model application allow develop model application use application use model pmml model application pmml produce pmml include neural network produce pmml neural learn model pmml produce pmml mining model include neural network datum mining model produce pmml neural network mining model produce pmml neural network datum mining model model neural network learn software datum mining development environment neural network simulator\n",
      "=====Deep_learning\n",
      "=======\n",
      "deep learning deep learn learn machine learning method base artificial neural network learn supervise supervise unsupervised deep learning architecture deep neural network deep belief network recurrent neural network convolutional neural network apply field include vision speech recognition natural language processing recognition network filter machine translation drug medical image analysis game produce result case human artificial neural network anns information processing biological system anns biological brain specifically neural network biological brain deep learning machine learn algorithm use multiple layer extract level feature raw input example image process low layer identify layer identify human face deep learning model base artificial neural network specifically convolutional neural network cnn include organize layer deep generative model deep belief network deep machine deep learning level learn transform input datum representation image recognition application raw input layer encode layer encode layer encode layer recognize image contain face deep learning process learn feature level need hand example number layer layer size provide different word deep deep learning number layer datum transform deep learning system cap depth cap input output cap potentially connection input output feedforward neural network depth cap network number hide layer output layer recurrent neural network signal layer cap depth potentially depth shallow learn deep learning researcher deep learning involve cap depth cap depth show universal function layer function ability network deep model cap extract feature shallow model layer help learn feature deep learning architecture layer layer method deep learning help feature improve performance supervise learn task deep learning method feature translate datum representation layer structure representation deep learning algorithm apply unsupervised learn task datum label example deep structure train unsupervised neural deep belief network interpretation deep neural network term universal approximation probabilistic inference universal approximation concern feedforward neural network layer size approximate function publish activation function multi layer architecture show universal approximation non activation function linear unit universal approximation deep neural network concern network depth allow et al deep neural network activation large input network approximate function small input deep neural network universal probabilistic interpretation field machine learning feature inference training relate specifically probabilistic interpretation consider activation function probabilistic interpretation lead neural network probabilistic interpretation introduce researcher include term deep learning introduce machine learn artificial neural network context neuron learn algorithm supervise deep feedforward publish deep network layer train group method datum algorithm deep learning architecture specifically vision introduce et al apply backpropagation algorithm automatic deep neural network purpose recognize algorithm training require system recognize hand recognize object match image object model et al human brain use object model publish cresceptron method perform object recognition natural image cresceptron start purpose visual learning natural cresceptron layer similar require human hand feature cresceptron learn number feature layer feature represent cresceptron learn object analysis network deep neural network imagenet cresceptron reduce factor publish result multi layer neural network neural network layer self feature neural network multi layer classification neural network train layer feature extract feature layer demonstrate possible train network contain connect layer hide unit algorithm develop factor speed include gradient problem analyze model use task specific feature filter vector machine artificial neural network ann computational lack brain biological network shallow deep learn recurrent net anns year method non model hide model base generative model speech train analyze include gradient structure neural model lack training datum speech recognition researcher neural net generative deep neural network speech speaker recognition speaker recognition lead significant success deep neural network speech process speaker recognition success deep neural network speaker recognition demonstrate similar success speech recognition raw feature hand successfully architecture deep raw linear filter feature show feature contain raw feature speech later produce large scale result speech recognition deep learning method call long term memory lstm recurrent neural network publish lstm rnn gradient problem learn deep learning task require memory event time step speech lstm start speech certain task later classification lstm google speech recognition performance train lstm google search show layer feedforward neural network train layer time layer unsupervised machine backpropagation learn deep belief net deep learn state art system vision automatic speech recognition asr result set timit asr image classification large speech recognition task improve convolutional neural network cnn asr lstm vision deep learning industry early cnn process application deep learn large scale speech recognition start deep learning speech recognition deep generative model speech give capable large scale datum set deep neural net dnn training dnns generative model deep belief net neural net train large train datum backpropagation dnn large context output layer produce error rate low state art model hide model generative model base system recognition error produce type system different integrate deep learning time speech major speech recognition system analysis generative speech model dnn model early deep learning speech recognition lead use industry analysis performance error rate dnns generative model researcher deep learn timit large speech recognition large output layer dnn base context state deep learning involve call deep learning deep learning neural network train process unit gpus year google brain gpus capable dnn gpus increase speed deep learning system time gpus vector computation involve machine learn gpus speed training algorithm reduce time algorithm processing deep learning model deep learn lead win challenge multi task deep neural network predict target drug group deep learning detect target effect drug win datum challenge significant image object recognition cnns train backpropagation year include cnns cnns gpus style need vision approach time performance visual recognition contest win contest win image contest cnns play major vision et al lead show cnn improve vision similar et al win large scale imagenet significant shallow machine learning method et al win contest analysis large medical image detection year challenge error rate imagenet task deep learning reduce similar large scale speech recognition image image classification challenge task generate image cnns researcher imagenet start deep learning transform ai industry deep neural network neural network artificial neural network artificial neural network anns system system biological neural network brain system learn improve ability task consider example task specific example image recognition learn identify image contain cat analyze example image label cat cat result identify cat image use application algorithm base ann base connect unit call artificial neuron biological neuron biological brain connection neuron signal neuron neuron process signal signal neuron connect neuron state represent number typically neuron weight learn increase signal typically neuron organize layer different layer perform different input signal input output layer layer multiple time neural network approach problem way human brain time match specific ability lead backpropagation information network information neural network task include vision speech recognition machine translation network filter play video game medical neural network typically unit connection number number neuron human brain network perform task level human recognize face play deep neural network deep neural network dnn artificial neural network ann multiple layer input output layer dnn find manipulation input output linear relationship non linear relationship network layer output example dnn train recognize give image image certain user result network certain propose label manipulation consider layer dnn layer deep network dnns model non linear relationship dnn architecture generate model object layer layer feature low layer potentially model datum unit perform shallow network deep architecture include approach architecture success specific possible performance multiple architecture datum set dnn typically feedforward network datum input layer output layer dnn neuron value weight connection weight input output network recognize algorithm weight way algorithm certain manipulation process recurrent neural network datum application language model long term memory use convolutional deep neural network cnn vision cnn apply model automatic speech recognition asr challenge anns train dnn overfitte computation time dnn overfitte layer allow model train datum regularization method unit weight regularization regularization apply training overfitte regularization unit hide layer training help method small training set increase size reduce overfitte dnn consider training size number layer number unit layer learning rate weight time computational gradient training example example speed computation large processing architecture gpus produce significant training processing architecture vector computation look type neural network training algorithm model neural network require learning rate weight training process step new datum computational training algorithm linear number neuron involve application automatic speech recognition large scale automatic speech recognition case deep learning lstm rnn learn deep learning task involve multi contain speech event time step time step lstm speech certain task success speech recognition base small scale recognition task base timit datum set contain speaker major speaker sentence small size timit task concern recognition word recognition allow language model model speech recognition error rate list include early result error rate dnns speaker recognition speech recognition lstm major scale dnn training training feature processing deep model dnn relate deep model multi task learning dnn relate deep model cnns speech rnn lstm type deep model include base model integrate deep generative model major commercial speech recognition system google search speech base deep learning image recognition set image classification datum set include training example example timit small size user multiple list result set deep learning base image recognition produce result human deep learning train example analysis analyze case human connect large visual art processing image recognition increase application deep learning technique visual art task dnn capable example identify style give neural style style give apply video generate base visual input field natural language process neural network language model early lstm help improve machine translation language model technique field word embed word embed word layer deep learn architecture transform word representation word word dataset represent point vector word embed rnn input layer allow network sentence vector grammar vector grammar probabilistic context grammar rnn word sentence detect deep neural architecture provide result analysis information language machine translation style recognition classification development word embed sentence embed google translate use large end end long term memory network google neural machine translation use example base machine translation method learn example translate sentence time google translate language network encode sentence translation use language drug large drug win target effect target effect effect research use deep learning predict target target effect drug deep learning structure base drug predict target multiple generative neural network produce way relationship deep learn approximate value possible term value function show natural interpretation value recommendation system recommendation system deep learning extract feature factor model base recommendation deep learning apply learn user multiple model use base approach recommendation multiple task ann predict function relationship medical deep learning predict base datum datum deep learning show medical image analysis deep learning show produce result medical application classification detection image mobile advertising find mobile mobile advertising challenge datum point consider target deep learning large advertising dataset datum point advertising information form machine learning improve image deep learning successfully apply problem application include learn method field image train image dataset deep image train image need detection deep learning successfully apply detection anti deep anti detection recognize relationship datum learn detect predict specific event supervise learning technique classification unsupervised learn detection state defense apply deep learning train robot new task human brain development deep learning theory brain development specifically development propose early theory computational model deep learning system model propose learn brain factor self neural network deep learning model like neural network layer filter layer consider information layer output input layer process self organize state brain organize call factor different brain connect layer brain approach deep learning model hand backpropagation algorithm propose increase process researcher argue unsupervised form deep learning base generative model deep belief network biological generative neural network model relate base process human brain encode deep network example computation perform deep learning unit similar neuron neural representation develop deep learning model similar visual unit level commercial facebook ai perform task google develop capable learning play video game datum input demonstrate learn game google translate use lstm translate language demonstrate mobile application use deep learning recognize object time ai integrate deep learning researcher develop machine learning call training propose new method robot learn perform task human develop tame new algorithm call deep tame later introduce research researcher deep tame deep learning provide robot ability learn new task deep tame robot learn task human video human perform task robot later task help provide deep learning case field theory concern lack theory method learn deep architecture gradient theory algorithm approximate deep learning method look point deep learning look step ai deep learning method lack need research deep learn large challenge machine technique lack way represent relationship way perform inference long way integrate information object typically system like use technique like deep learning technique technique inference deep learning possible train machine vision perform task represent non machine propose concern low level publish representation state deep layer neural network datum image train demonstrate visual research time error deep learning architecture image image image representation multi artificial intelligence architecture deep learning architecture form state image grammar event learn grammar visual training datum term human language artificial intelligence ai deep learning research show artificial neural network identify system use function input anns way ann find match human recognize example image ann find match image look human like search target manipulation term researcher ann image error identify point generate image image look different human group show image successfully image classification defense image search possible image search image identify image group show certain recognition potentially allow researcher ann anns train detect potentially lead similar malware defense industry anns train ann base anti malware defense malware algorithm anti malware ability target group demonstrate certain google malware datum datum machine learning training set human deep learning system training verification datum generate human argue low purpose form human recognize type human generate training datum embed computation task game image recognition google search result face facebook label image information self argue commercial end user application deep learning facebook face recognition need training datum ann train human generate verification datum ann purpose facebook introduce feature user recognize image like label image facebook user generate verification datum train network time argue human user generate training verification datum commercial end user application deep learning system human artificial intelligence application artificial intelligence deep learning state network list artificial intelligence state machine list dataset machine learn research\n",
      "=====Applied_machine_learning\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn study algorithm statistical model system use perform specific task pattern inference instead subset artificial intelligence machine learn algorithm build mathematical model base sample datum know training data order prediction decision program perform task machine learn algorithm variety application email vision algorithm perform task machine learn related computational statistic focus make prediction study mathematical optimization method theory application field machine learning datum mining field study machine learning focus datum analysis unsupervised learning application problem machine learn predictive machine learning provide definition algorithm study machine learning field program learn experience class task performance measure performance task measure improve experience definition task machine learn definition define field term compute intelligence machine machine characteristic machine machine learn task machine learn task category supervise learn algorithm build mathematical model set data contain input desire output example task image contain object training datum supervise learn algorithm include image object input image label output contain object input semi supervise learn algorithm mathematical model training datum sample input label classification algorithm regression algorithm type supervise learn classification algorithm output set value classification algorithm email input email output email algorithm email output prediction represent value true regression algorithm continuous output mean value example continuous value object unsupervised learn algorithm build mathematical model set data contain input desire output label unsupervised learn algorithm structure datum like group datum unsupervised learn discover pattern data group input category feature learn process feature input set datum learn algorithm desire output train label set input base input training label human user reinforcement learn algorithm give form positive negative reinforcement environment learn game human algorithm machine learning include model program give set language similar machine learn algorithm probability density function density problem learn algorithm learn inductive bias base experience learn algorithm generate sequence learn experience know new self human use learn relationship field field game artificial intelligence term machine learn book machine learn research book learning machine machine learning pattern classification machine learn related pattern recognition book report give neural network learn machine learning artificial intelligence ai researcher machine learn datum attempt approach problem method term neural network model linear model statistic probabilistic employ medical increase knowledge base approach ai machine learn probabilistic system theoretical problem datum representation system come ai statistic knowledge base learning ai lead inductive logic program statistical research field ai pattern recognition information neural network research ai time ai field researcher include come machine learning separate field field goal artificial intelligence problem nature focus approach ai method model statistic probability theory increase information ability datum mining machine learn datum mining employ method machine learn focus prediction base know learn training datum datum mining focus discovery previously unknown datum analysis knowledge discovery database datum mining use machine learning method different goal machine learning employ datum mining method unsupervised learn improve accuracy research separate conference separate journal come machine learning performance usually ability know knowledge knowledge discovery datum mining task discovery previously unknown knowledge know knowledge unsupervised method supervised method task supervised method training datum optimization machine learn optimization learning problem loss function training set example loss function prediction model train problem instance example classification label instance model train predict label set example field goal generalization optimization algorithm loss training set machine learning loss sample statistic machine learning statistic related field term method goal statistic inference sample machine learning predictive pattern machine learn theoretical tool statistic term datum field statistical datum model algorithmic model algorithmic model mean machine learn algorithm like method machine learn lead field statistical learning theory experience generalization context ability learn machine perform new example task experience learn datum set training example come unknown probability consider space build model space prediction new computational analysis machine learn algorithm performance theoretical know computational learning theory training set learning theory usually performance algorithm instead probabilistic performance common bias way generalization good performance context generalization complexity hypothesis complexity function datum hypothesis function model fit data complexity model increase training hypothesis model generalization addition performance learn study time complexity learn computational learn theory consider polynomial time time complexity result positive result class function learn polynomial time negative result class learn polynomial time approach type learn algorithm type machine learn algorithm approach type datum input output type task problem solve supervise learn supervise learn algorithm build mathematical model set data contain input desire output datum know training data set training example training example input desire output know signal mathematical model training example represent vector call feature vector training datum represent matrix optimization function supervise learn algorithm learn function predict output associate new input function allow algorithm output input training data algorithm improve accuracy output prediction time learn perform task supervised learn algorithm include classification regression classification algorithm output set value regression algorithm output value similarity learning area supervise machine learn related regression classification goal learn example similarity function measure similar related object application recommendation system semi supervised learn algorithm training example training label improve model supervised learn training label label result large training set unsupervised learn unsupervised learn algorithm set datum contain input structure datum like group datum algorithm learn test datum label instead unsupervised learn algorithm identify datum base new data application unsupervised learning field density statistic unsupervised learning datum feature cluster analysis set observation subset call cluster observation cluster similar observation different cluster different technique different structure datum define similarity example similarity cluster cluster method base density semi supervise learning semi supervised learning unsupervised learning label training datum supervise learn label training datum machine learning researcher datum label data learn accuracy reinforcement learn reinforcement learning area machine learn software action environment field study game theory theory research information theory base optimization system intelligence statistic genetic algorithm machine learning environment typically represent decision process reinforcement learn algorithm use programming technique reinforcement learn algorithm knowledge mathematical model model reinforcement learn algorithm learn game human self learn self learn machine learn neural network self learn caa learn caa self learn algorithm compute decision action emotion consequence situation emotion self learn algorithm matrix machine learn situation perform action receive consequence situation compute emotion consequence situation input situation output action separate reinforcement input input environment value reinforcement emotion consequence situation caa exist environment environment genetic environment receive emotion situation environment receive vector genetic environment caa learn goal environment contain situation feature learn learn algorithm discover representation input provide training example include component analysis cluster analysis feature learn algorithm call representation learn algorithm attempt information input way make perform classification prediction technique allow input come unknown datum generate feature allow machine learn feature use perform specific task feature learning supervise unsupervised supervised feature learning feature learn label input datum example include artificial neural network supervise dictionary learning unsupervised feature learning feature learn input datum example include dictionary learning component analysis matrix form cluster learn algorithm attempt learn representation dimensional sparse algorithm attempt learn representation sparse mean mathematical model learn algorithm learn dimensional representation representation datum high dimensional vector learn algorithm discover representation feature high feature define term generate feature machine learn representation datum feature learn machine learn task classification input process real datum image datum attempt define specific feature discover feature representation algorithm sparse dictionary learning sparse dictionary learning feature learn method training example represent linear function sparse matrix method solve method sparse dictionary learning algorithm sparse dictionary learning apply classification problem class previously training example dictionary class build new training example associate class represent dictionary sparse dictionary learning apply image image represent image dictionary anomaly detection datum mining anomaly detection know detection item observation datum typically item represent medical problem anomaly context network detection object object pattern common statistical definition object detection method unsupervised algorithm fail datum instead cluster analysis algorithm cluster form pattern category anomaly detection technique exist unsupervised anomaly detection technique anomaly test datum set instance datum set normal instance fit datum set supervised anomaly detection technique datum set label normal train statistical classification problem nature detection semi supervise anomaly detection technique model represent normal give normal training datum set test test instance generate model association rule association rule learning rule base machine learning method relationship variable large database identify rule discover database measure rule base machine learn term machine learning method learn rule apply knowledge define characteristic rule base machine learn algorithm set rule represent knowledge machine learn algorithm identify model apply instance order prediction rule base machine learning approach include learn system association rule learn artificial system base rule association rule discover large datum system example rule datum information decision addition analysis association rule employ application area include mining detection continuous sequence mining association rule learn typically consider order item learn system rule base machine learn algorithm discovery component typically genetic algorithm learn component perform supervised learn reinforcement learn unsupervised learning identify set context rule apply knowledge order prediction inductive logic programming approach rule learn logic programming representation input example knowledge hypothesis give know knowledge set example represent database logic program positive negative example inductive programming related field consider programming language represent hypothesis logic program program inductive logic programming language theoretical inductive machine learn build model inference program logic program positive negative example term inductive theory mathematical order set model perform machine learning model train training datum process datum prediction type model research machine learning system artificial neural network artificial neural network system system neural network brain system learn perform task consider example program task specific rule model base call artificial neuron model neuron brain connection like brain information signal artificial neuron artificial neuron receive signal process signal artificial neuron common signal connection artificial neuron real output artificial neuron compute non linear function input connection artificial neuron call artificial neuron typically learn increase signal connection artificial neuron signal signal typically artificial neuron layer different layer perform different input signal layer input layer layer output layer layer time goal approach solve problem way human brain time perform specific task lead artificial neural network variety task include vision recognition machine network game medical learning layer artificial neural network approach model way human brain process vision application learn vision recognition decision tree decision tree learn use decision tree predictive model observation item represent item value represent predictive approach statistic datum mining machine learning tree model variable set value call classification tree tree structure represent class label represent feature lead class label decision tree variable continuous value typically real call regression tree decision analysis decision tree represent decision decision make datum mining decision tree datum result classification tree input decision make vector machine vector machine svm vector network set related supervised learning method classification regression give set training example category svm training algorithm build model predict new example category svm training algorithm non probabilistic linear method exist use svm probabilistic classification set addition perform linear classification perform non linear classification call input high dimensional feature space regression analysis regression analysis large variety statistical method relationship input variable associate feature common form linear regression good fit give datum mathematical method high bias regression non linear problem model include polynomial regression fit regression statistical classification regression non input variable high dimensional space bayesian network bayesian network network model probabilistic model represent set variable example bayesian network represent probabilistic relationship give network compute probability algorithm exist perform inference learn bayesian network model sequence variable like signal sequence call bayesian network generalization bayesian network represent solve decision problem call genetic algorithm genetic algorithm algorithm technique process method generate new good give problem machine learn genetic algorithm machine learning technique improve performance genetic algorithm training model usually machine learning model data order perform usually train machine learning model large sample datum training set datum training set image datum user training machine learning model learn learn new approach training machine learning model training process allow user datum increase training process example use machine learn train prediction model user google application application machine learn include program predict user improve accuracy exist recommendation algorithm researcher research theory build model good pattern recommendation recommendation journal research use machine learning predict predict medical machine learn medical software report machine learn algorithm apply field study previously nature research book machine learn machine learn field machine learning program fail result datum datum datum bias problem task algorithm tool people problem self fail attempt use machine learn fail time bias machine learning approach different datum bias machine learning train predict new group represent training datum train data machine learn bias language model learn datum contain human like bias machine learning system bias people google people google training datum real similar non people system test learn language use machine learn bias machine learning use human good artificial intelligence include artificial ai people people people tool model classification machine learning model accuracy technique like method datum training test set training set test set performance training model test set method datum subset perform consider subset subset training model addition method sample instance model accuracy addition accuracy report mean true positive rate true negative rate report positive rate negative rate rate fail characteristic method model ability previously rate provide information characteristic associate area machine learning system train bias bias use algorithmic bias example data lead machine learn bias similarity datum algorithmic rule machine learn human language contain bias machine train language learn bias form bias health care health care system generate machine true improve health care increase example algorithm provide test algorithm machine learn health care provide tool bias previously bias software software contain variety machine learn algorithm include software software software journal journal machine learn research machine learn nature machine intelligence neural conference conference neural information system conference machine learn machine learn database machine learn software machine learn google machine learning use\n",
      "=====AlphaGo\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphago program play board game deepmind google alphago powerful successor call alphago master alphago zero alphazero october alphago program beat human professional player handicap board beat lee sedol game match time program beat dan professional handicap lose lee sedol fourth game lee game game alphago victory alphago award dan korea association lead match lee sedol title alphago year december future summit successor alphago master beat ke jie world rank player time game match powerful alphago zero alphago award professional dan chinese association alphago successor use tree search algorithm move learn machine learn artificial neural network deep learning method human play neural network train alphago game neural improve strength tree search strong play match alphago ke jie deepmind alphago ai research alphago zero achieve victory champion alphago successor alphazero world player chess computer win game chess make use ai method tree search deep beat world chess champion match strong program artificial intelligence technique reach dan beat professional player handicap program zen run beat stone handicap stone beat stone handicap deepmind alphago research neural network deep learning alphago program game program include stone zen alphago run single win similar alphago run computer win game play program game play alphago run single version october match fan hui october version alphago defeat champion fan hui dan dan professional zero time program beat professional human player board handicap january algorithm match lee sedol alphago play south professional player lee sedol rank dan good player game south korea game alphago win game lee win fourth game record human player beat alphago official game alphago run google server state match chinese think time second version alphago play lee similar fan hui match time play lee sedol second number victory world south player lee world title year single official method rank rank rank lee sedol fourth good player world time alphago train lee human player game win alphago resignation lee lee beat alphago fourth game win resignation alphago achieve fourth win win game resignation million alphago win include lee sedol game win huang deep team th game match alphago lee professional play alphago lead game lee program huang alphago network alphago network lee th alphago game december server server chinese version south korea play game professional player master december move server january january deepmind master play version alphago call alphago master january alphago master record win include victory rank player ke jie master version alphago lose master human player defeat master master play game day ai player game include world champion ke jie fan win champion world huang game game second master play win th game master huang deepmind team game google deepmind say play official game expert expert program play style ke jie state year improve computer human single human future summit future summit alphago master play game ke jie world rank player game chinese professional game team human player google deepmind million game match ke jie master master win game ke jie alphago award professional dan chinese association win game match ke jie world player alphago deepmind team game ai research summit deepmind alphago alphago match community alphago zero alphazero alphago team october alphago zero version human strong human champion version game alphago zero strength alphago lee day win game reach alphago master day version day december deepmind alphago zero single alphazero algorithm achieve play game chess world champion program day version alphago zero december deepmind alphago win alphago master human game alphago master include human version version alphago number run second think time match time achieve google state google include alphago match lee sedol future summit deepmind version alphago summit alphago master strength version alphago lee version lee alphago fan version alphago fan hui stone alphago master stone strong algorithm alphago algorithm use machine learning tree search technique human play use tree search network network deep neural network game match neural network neural network initially human alphago initially train human play match move expert player record game million move reach train play number game learning improve play time program program win probability match lee resignation style play match alphago fan hui program style alphago play style probability win probability win probability win human player move make move human second move human player use victory ai community alphago victory artificial intelligence research machine learning reach time expert think program powerful alphago year expert think computer beat champion match lee beat alphago game player team chess win computer victory board game artificial intelligence deep call alphago victory board game time deep alphago algorithm general community make progress artificial general intelligence alphago victory make good future machine general intelligence alphago play general intelligence learn use ai say ai alphago progress powerful method human match future improve ai general intelligence lead ai ai expert say say think people think people alphago chinese artificial intelligence deepmind alphago team ai alphago say award alphago achieve ai technique state machine learning technique deepmind ai award community game korea match million people player alphago play move initially good player style player alphago move alphago strong october match beat professional time handicap day lee defeat lead south korea say people korea association professional south korea award alphago dan title game progress ke jie year world good player time initially beat alphago play style match progress ke jie state lose match alphago fourth match alphago match fan hui lee general future player computer learn game improve game lee say match single alphago victory lee state game alphago defeat lee defeat defeat lee say machine state game human lee call game victory win similar machine learn tree search strong player program defeat professional human player lose zen similar strength zen lose master record number title win alphago game alphago master december alphago win resignation alphago lee sedol fan hui play alphago lee sedol rank th world fan hui th community move play game player play program artificial intelligence neural network official alphago include alphago game alphago game\n",
      "=====Unsupervised_learning\n",
      "=======\n",
      "unsupervised learning self hebbian learning unknown pattern datum self model machine learn supervise learn supervise learning supervise unsupervised technique method unsupervised learn cluster analysis cluster analysis unsupervised learning order cluster analysis machine learn datum cluster analysis datum approach datum unsupervised learning unsupervised learning datum supervise learn learning datum unsupervised learning network unsupervised learn technique approach algorithm unsupervised learning cluster mean model algorithm neural network hebbian learn network self map approach learn latent variable model algorithm method moment technique analysis analysis neural network unsupervised learn neural network hebbian learning hebbian learning pattern learn neural network model self map unsupervised learn algorithm map model cluster cluster mean network pattern method moment statistical approach unsupervised learn method moment method moment unknown parameter model moment variable unknown parameter moment moment moment order moment order moment mean order moment mean order moment order method moment learning parameter latent variable model latent variable model statistical model variable latent variable latent variable model machine learn topic model statistical model variable document topic latent variable document topic document statistical parameter topic document method moment technique parameter latent variable model algorithm method learn latent variable model algorithm unknown parameter model method moment machine learning cluster analysis algorithm map learn analysis network machine learn isbn unsupervised learn pattern isbn statistical learning datum isbn unsupervised learn neural isbn unsupervised learn neural network\n",
      "=====Structured_prediction\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structure prediction structure learn technique structured technique structure prediction model prediction model model prediction model training learn problem sentence structured prediction problem structured structure prediction sequence tag sequence problem sequence sentence sequence problem tag tag word sequence tag word problem word sentence tag problem tag tag conditional tag word sequence model model conditional tag sequence sentence tag algorithm technique model structure prediction model network algorithm model structure prediction structured network conditional model technique conditional structure structure network network structure perceptron algorithm structured prediction structure perceptron algorithm perceptron algorithm algorithm algorithm sequence training prediction structure problem model prediction displaystyle displaystyle training displaystyle prediction displaystyle displaystyle displaystyle displaystyle displaystyle displaystyle learn displaystyle algorithm algorithm learn perceptron structure prediction training model structure perceptron\n",
      "=====Graphical_models\n",
      "=======\n",
      "graphical model probabilistic graphical model structure probabilistic model probabilistic model graph conditional structure random variable probability bayesian machine learn graphical model probabilistic graphical model graph representation distribution graph representation set independence distribution graphical representation distribution bayesian network markov random field independence set independence distribution bayesian network network structure model direct graph model joint probability random variable displaystyle x x joint probability pa displaystyle x x x pa x pa displaystyle pa x set node displaystyle x node direct displaystyle x joint distribution factor conditional distribution graphical model direct graph graph random variable displaystyle joint probability factor displaystyle node set node set graph independence independence bayesian network graphical model direct graphical model bayesian network network machine learn model markov model network model variable markov model bayesian network tree tree model factor graph undirected graph variable factor factor variable representation tree tree tree tree graph graph direct undirected direct graph direct graph bayesian markov network graph direct undirected random field markov random field markov network model undirected graph graphical model conditional random field model undirected graph machine model undirected graph model structure distribution graphical model model network graphical model structure model bayesian machine learn isbn graphical model machine learn isbn probabilistic network isbn bayesian network isbn probabilistic isbn probability probabilistic graphical model graphical model probabilistic machine learn learn graphical model bayesian network probabilistic graphical model graphical model conditional random field probabilistic graphical model\n",
      "=====Bayesian_networks\n",
      "=======\n",
      "bayesian network baye network network network baye model probabilistic direct acyclic graphical model probabilistic graphical model model represent set variable conditional dependency direct acyclic graph dag bayesian network predict likelihood possible cause example bayesian network represent probabilistic relationship give network compute probability algorithm perform inference learn bayesian network bayesian network model variable call bayesian network bayesian network represent problem call graphical model bayesian network direct acyclic graphs dag node represent variable bayesian quantity variable parameter edge represent conditional dependency node path node represent variable independent node probability function set value node parent variable give probability probability distribution variable node example displaystyle parent node represent displaystyle variable probability function represent table displaystyle displaystyle possible parent graphs markov network example cause grass wet sprinkler rain rain direct effect use sprinkler rain sprinkler model bayesian network variable possible value true false joint probability function pr pr pr pr displaystyle pr pr mid pr mid pr grass wet true false sprinkler turn true false rain true false model answer cause give effect call probability probability rain give grass wet conditional probability sum variable pr pr pr pr pr displaystyle pr mid frac pr pr frac sum pr sum pr joint probability function pr displaystyle pr conditional probability conditional probability table state term sum example pr pr pr pr displaystyle align pr pr mid pr mid pr time time align result variable value pr displaystyle pr mid frac frac answer probability rain give wet grass answer intervention joint distribution function pr pr displaystyle pr mid text pr mid pr displaystyle pr mid intervention distribution value true probability rain action pr pr displaystyle pr mid text pr predict turn sprinkler pr pr pr displaystyle pr mid text pr pr mid term pr displaystyle pr mid action grass rain give unobserved variable problem effect action displaystyle text predict door state set node observed separate door path pr pr pr displaystyle pr mid text frac pr pr mid door path arrow set door call example set predict effect separate door path set separate path effect turn sprinkler grass predict case identify datum causal common cause causal identify bayesian network unobserved variable use term quantity datum bayesian network probability table dependency joint distribution example conditional probability value variable table require space displaystyle value variable local distribution depend parent variable bayesian network displaystyle cdot value bayesian network set direct dependency local distribution complete joint distribution inference learn bayesian network perform inference unobserved variable bayesian network complete model variable relationship answer probabilistic example network state variable variable variable observed process compute posterior distribution variable give call probabilistic inference posterior give application value variable expect function probability error bayesian network baye complex problem common exact inference method variable non observed non variable sum product variable time search space time variable space method complexity network common approximate inference algorithm sample method parameter learning specify bayesian network represent joint probability distribution specify node probability distribution conditional parent distribution conditional parent form common work distribution constraint distribution use maximum distribution give constraint bayesian network conditional distribution state specify maximize process conditional distribution include parameter estimate maximum likelihood approach direct likelihood posterior probability complex give unobserved variable approach problem algorithm compute expect value unobserved variable conditional observed datum maximize complete likelihood posterior compute expect value condition process maximum likelihood maximum posterior value parameter bayesian approach parameter unobserved variable compute posterior distribution conditional observed datum parameter approach model set approach tractable structure learn case bayesian network specify perform inference application define network complex case network structure parameter local distribution learn datum learn graph structure bayesian network learn algorithm develop possible node dag represent dependency displaystyle displaystyle independent give displaystyle identify displaystyle displaystyle independent graphs arrow arrow displaystyle displaystyle common parent condition parent algorithm develop graph arrow conditional independence method learning use search require function search common function posterior probability structure give datum time search structure maximize number variable local search structure search algorithm markov local variable structure maximize parent set node search method exact learning problem problem constraint form method problem variable problem variable approach sample structure respect ordering work search space possible ordering space network structure ordering sample method prove number variable method model form possible structure variable learn bayesian network exact tractable inference case inference complexity time property graph learning process possible use learn introduction give datum displaystyle displaystyle theta bayesian prior probability prior displaystyle theta likelihood displaystyle mid theta compute posterior probability displaystyle theta mid mid theta theta prior displaystyle theta depend turn parameter displaystyle varphi likelihood prior displaystyle theta likelihood displaystyle theta mid varphi prior displaystyle varphi parameter displaystyle varphi require result posterior probability displaystyle theta varphi mid mid theta theta mid varphi varphi example hierarchical baye model process example parameter displaystyle varphi depend turn parameter displaystyle require prior process prior depend parameter example give quantity displaystyle x x error displaystyle displaystyle x sim theta estimate displaystyle theta approach estimate displaystyle theta maximum likelihood approach independent likelihood maximum likelihood estimate displaystyle theta x quantity example displaystyle theta distribution relationship independence complex model displaystyle x sim theta displaystyle theta sim varphi prior displaystyle varphi sim displaystyle sim displaystyle displaystyle identify model model parameter posterior distribution displaystyle theta maximum likelihood estimate common hierarchical baye model prior need prior hierarchical model variable variable displaystyle example prior prior work posterior distribution estimate expect definition definition bayesian network direct acyclic graph dag set variable definition bayesian network respect joint probability function respect product product function conditional parent variable pa displaystyle x x operatorname pa pa set parent edge set variable probability joint distribution conditional probability give ordering displaystyle operatorname x x x x operatorname x x mid x x x x definition parent displaystyle operatorname x x x x operatorname x x mid x x text x text parent x conditional independence variable non descendant give value parent variable local markov property bayesian network respect local markov property variable independent non descendant give parent variable pa displaystyle x perp perp x operatorname mid x operatorname pa text set descendant set non descendant term definition descendant parent displaystyle align operatorname x x mid x x text x text descendant x x x mid x x text x text parent x align set parent set non descendant graph acyclic develop bayesian network develop bayesian network dag local markov property respect causal dag conditional probability distribution variable give parent case case variable joint distribution product conditional distribution bayesian network respect markov blanket markov blanket node set node parent parent markov blanket node independent network joint distribution variable markov blanket node distribution node bayesian network respect node independent node network give markov blanket separation definition define separation node define separation trail define separation node term trail node trail edge path node separate set node condition need direct displaystyle cdot leftarrow leftarrow cdot displaystyle cdot rightarrow rightarrow cdot node displaystyle cdot leftarrow rightarrow cdot node displaystyle cdot rightarrow leftarrow cdot node descendant node separate trail separate separate bayesian network respect node displaystyle x perp perp x mid x set separate markov blanket set node separate node node causal network bayesian network represent causal relationship need case direct edge require bayesian network graphs displaystyle rightarrow rightarrow text leftarrow leftarrow conditional independence causal network bayesian network relationship causal causal network specify node cause give state action probability function network parent set cause value intervention datum prior intervention predict inference complexity approximation algorithm work application prove exact inference bayesian network result approximation algorithm develop tractable approximation probabilistic inference prove result complexity approximation probabilistic inference bayesian network prove tractable algorithm approximate probabilistic inference error prove tractable algorithm approximate probabilistic inference error probability time prove exact inference bayesian network complete number form approximate inference bayesian network term complexity result bayesian network learning application use application need constraint baye network conditional probability algorithm approximation algorithm approximate probabilistic inference bayesian network error approximation algorithm require conditional probability bayesian network number node network software software bayesian network include sampler use sample software include bayesian network software bayesian inference turn sampler represent bayesian network sampler include sampler term bayesian network baye condition causal probabilistic probabilistic property bayesian network introduction bayesian bayesian network introduction graphical model learn datum introduction bayesian network application bayesian probability bayesian method time bayesian network bayesian network learn bayesian network hierarchical baye model sample problem model sample hierarchical baye model sample perform learn variable\n",
      "=====Causal_inference\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causal inference process causal effect causal inference inference effect variable cause science causal inference causal infer cause cause cause cause cause effect time cause effect cause method study different method evidence effect different statistical method statistical inference datum correlation causation method infer causation framework causal inference model causal model epidemiology epidemiology study disease infer cause effect disease causality correlation causation cause disease assess causality variable causality molecular epidemiology study molecular include evidence cause effect evidence molecular disease molecular epidemiology molecular disease assess causality disease disease disease science science cause effect datum time independent variable evidence model model noise model model variable cause variable noise model independent noise model evidence noise model noise noise displaystyle noise displaystyle displaystyle noise displaystyle noise displaystyle model cause cause cause independent causal cause effect cause effect cause model effect cause effect different method causal datum causal statistic statistic causality regression method causality causality variable cause dependent variable causation independent variable dependent variable variable causation variable dependent variable effect cause include regression variable time dependent variable include variable cause correlation correlation process correlation datum regression social science social science quantitative framework assess causality social science methodology science social quantitative method statistical inference subject quantitative method framework infer causality quantitative method infer causality study methodology correlation study subject datum methodology social science time statistical inference framework social science causal inference quantitative method method different methodology different subject study statistic causal inference statistical inference assess effect cause cause effect model causation include process infer causation study process study methodology subject variable statistical inference causality statistic regression regression causality causal inference\n",
      "=====Markov_networks\n",
      "=======\n",
      "probability markov random field mrf markov network undirected model set random variable markov property undirected graph random field markov random field markov property markov network mrf bayesian network dependency bayesian network markov network undirected markov network dependency bayesian network dependency dependency bayesian network dependency graph markov random field joint probability random variable positive random field energy function markov random field ise model markov random field set ise model markov random field model mid image give undirected graph displaystyle set random variable displaystyle x displaystyle form markov random field respect displaystyle markov property markov property variable give variable displaystyle x perp perp x mid x markov property variable variable give displaystyle x perp perp x operatorname mid x operatorname operatorname set displaystyle displaystyle operatorname operatorname displaystyle markov property variable give displaystyle x perp perp x mid x node displaystyle node displaystyle displaystyle markov property markov property markov property positive probability clique markov property probability distribution markov random field factorize clique graph give set random variable displaystyle x displaystyle probability field configuration displaystyle displaystyle displaystyle probability random variable displaystyle value displaystyle displaystyle set probability displaystyle respect joint distribution displaystyle x joint factorize clique displaystyle cl displaystyle operatorname cl x displaystyle form markov random field respect displaystyle cl displaystyle operatorname cl set clique displaystyle clique function factor potential clique potential potential log potential energy configuration displaystyle x mrf factorize example node energy configuration probability energy graph displaystyle mrf factorize positive graph bayesian network possible factor graph network positive markov random field form feature function displaystyle f joint distribution exp displaystyle frac exp leave sum w f x right displaystyle w f x sum w f x field configuration partition function exp displaystyle sum mathcal exp leave sum w f x right displaystyle mathcal set possible assignment value network random variable feature function displaystyle f clique configuration displaystyle f x displaystyle x correspond th possible configuration th clique model clique model give displaystyle operatorname c clique feature displaystyle f correspond correspond clique factor log displaystyle w log c displaystyle c th possible configuration th clique th value clique displaystyle c probability markov field model possible clique factor displaystyle mathcal probability matrix matrix log matrix graph graph matrix partition function markov network partition function problem random variable network example graph partition function exp displaystyle sum mathcal exp leave sum w f x sum j x right respect give value random variable displaystyle x frac leave frac partial partial j right j function displaystyle x x frac leave frac partial partial j partial j right j j markov network model inference model inference example distribution form markov random field respect graph displaystyle correspond matrix matrix displaystyle x mathcal displaystyle inference bayesian network distribution set node displaystyle give value set node displaystyle w w markov random field sum possible assignment displaystyle inference inference problem markov mrfs inference mrfs assignment inference example network model graph form possible variable random field markov random field random field random variable set displaystyle model function displaystyle assignment clique displaystyle form markov network model distribution markov random field field mrfs image image model image model distribution give image mrfs image image image image inference image image problem energy problem problem set feature markov random field markov random field ise model network graph model network ise model log markov markov network mrf\n",
      "=====Loss_functions\n",
      "=======\n",
      "decision theory loss function cost function function event value variable real cost event problem minimize loss function objective function loss function function function utility function function case statistic loss function paramet event function difference estimate value statistic context economic example economic cost regret example context model optimal loss value risk function loss statistic frequentist bayesian loss function argue loss function loss function real decision make actual experience argue real loss function symmetric example regret argue bayesian loss function regret loss decision difference decision decision quadratic loss function use quadratic loss function common example loss function symmetric error target loss error target target quadratic loss function displaystyle value make difference decision common statistic model use theory loss function quadratic loss function quadratic optimal problem problem uncertainty possible value target variable loss quadratic variable value context expect value quadratic loss function statistic decision theory loss function loss function displaystyle hat hat displaystyle function expect loss value loss function variable statistic frequentist bayesian statistical theory make decision expect value loss function frequentist expect loss expect loss frequentist context expect value risk function decision rule paramet decision rule risk function displaystyle theta delta operatorname theta big theta delta big big theta delta big theta displaystyle operatorname theta value event bayesian expect loss bayesian paramet displaystyle theta theta theta choose expect loss choose choose frequentist risk bayesian choose optimal actual choose actual frequentist optimal decision rule function possible problem example statistic paramet decision function displaystyle hat theta estimate quadratic loss function squared error loss displaystyle theta hat theta theta hat theta risk function squared error estimate displaystyle theta hat theta operatorname theta theta hat theta paramet loss function choose function example displaystyle hat hat risk function squared error displaystyle hat operatorname hat economic choice uncertainty economic decision make uncertainty model utility function variable value variable value utility function expect value utility decision rule decision rule make choice choose decision rule loss minimize case possible loss displaystyle delta operatorname theta theta theta delta choose optimal decision rule choose decision rule loss minimize expect value loss function displaystyle delta operatorname operatorname theta theta theta delta delta operatorname theta theta theta delta theta theta select loss function statistical select actual experience context problem use loss function select statistical use model problem loss experience problem common example estimate statistical statistic estimate minimize expect loss experience squared error loss function minimize expect loss experience difference loss function optimal common economic risk objective function expect value risk risk loss utility function objective function expect value utility cost possible example loss function loss function loss displaystyle loss displaystyle loss displaystyle squared loss displaystyle displaystyle value value choice loss function loss function choice example symmetric statistic case argue select loss function real loss symmetric example arrive arrive make arrive arrive cost cost example argue common real problem common symmetric case bayesian regret loss function loss loss rule statistical risk loss function expect doi statistical decision theory bayesian make policy objective rule economic policy doi loss function policy doi utility function optimal policy uncertainty doi\n",
      "=====Support_vector_machines\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn support vector machine svm support vector learning model learn algorithm datum classification regression give set training example belong category svm training algorithm model assign new example category binary linear classifier method scale use svm classification set svm model example point space map example category new example map space belong category base perform linear classification svms efficiently perform linear classification call kernel trick map input high dimensional feature space datum learning learning approach datum group map new datum form group support vector algorithm vladimir vapnik apply support vector support vector machine algorithm datum algorithm application datum common task machine learn give datum point belong class class new data point case support vector machine data point displaystyle dimensional vector displaystyle number know point displaystyle dimensional hyperplane call linear classifier hyperplane classify datum choice good hyperplane large margin class choose hyperplane distance near data point maximize hyperplane know maximum margin hyperplane linear classifier define know maximum margin classifier support vector machine hyperplane set hyperplane high dimensional space classification regression task like good hyperplane large distance near training data point class call margin large margin error original problem finite dimensional space set linearly space propose original finite dimensional space map high dimensional space space svm dot product input datum vector compute term variable original space define term kernel function displaystyle select problem hyperplane high dimensional space define set point dot product vector space set vector set vector define hyperplane vector define hyperplane choose linear combination parameter displaystyle alpha feature vector displaystyle x data base choice hyperplane point displaystyle feature space map hyperplane define displaystyle sum alpha x text note displaystyle small displaystyle displaystyle term sum test point displaystyle datum base point displaystyle x way sum kernel test point datum point set note set point displaystyle map hyperplane result allow set original space application svm solve problem svm text application reduce label training instance transductive method base support vector machine classification perform svms result svms high include version svm use approach suggest vapnik svm svm algorithm apply science classify classify test base svm suggest interpretation svm model support vector machine svm model interpretation support vector machine model feature model prediction new special science original svm algorithm vladimir vapnik vladimir vapnik suggest way nonlinear classifier apply kernel trick maximum margin hyperplane soft margin propose vapnik linear svm give training displaystyle point form displaystyle vec y ldot vec y displaystyle y class point displaystyle vec belong displaystyle vec displaystyle dimensional vector maximum margin hyperplane group point displaystyle vec displaystyle y group point displaystyle y define distance hyperplane near point displaystyle vec group maximize hyperplane set point displaystyle vec displaystyle vec cdot vec displaystyle vec vector hyperplane like form displaystyle vec vector paramet displaystyle vec determine hyperplane vector displaystyle vec margin training datum linearly select hyperplane class data distance large hyperplane call margin maximum margin hyperplane hyperplane lie hyperplane displaystyle vec cdot vec boundary class label displaystyle vec cdot vec boundary class label distance hyperplane displaystyle vec maximize distance minimize displaystyle vec distance compute distance point data point margin follow constraint displaystyle displaystyle vec cdot vec geq displaystyle y displaystyle vec cdot vec leq displaystyle y constraint datum point lie correct margin displaystyle y vec cdot vec geq text leq leq optimization problem minimize displaystyle vec subject displaystyle y vec cdot vec geq displaystyle ldot displaystyle vec displaystyle solve problem determine sgn displaystyle vec operatorname sgn vec cdot vec max margin hyperplane determine displaystyle vec lie near displaystyle vec call support vector soft margin extend svm case datum linearly hinge loss function max displaystyle max leave y vec cdot vec right note displaystyle y target case displaystyle vec cdot vec output function constraint displaystyle vec lie correct margin datum margin function value distance margin minimize max displaystyle leave frac sum max leave y vec cdot vec right right lambda lvert vec rvert paramet displaystyle lambda determine margin displaystyle vec lie correct margin small value displaystyle lambda term loss function margin svm input datum linearly learn classification nonlinear classification original maximum margin hyperplane algorithm propose vapnik linear classifier vladimir vapnik suggest way nonlinear classifier apply kernel trick propose maximum margin hyperplane result algorithm dot product nonlinear kernel function allow algorithm maximum margin hyperplane transform feature space nonlinear transform space high dimensional classifier hyperplane transform feature space nonlinear original input space work high dimensional feature space error support vector machine give algorithm perform common kernel include displaystyle vec x vec x vec x cdot vec x displaystyle vec x vec x vec x cdot vec x function displaystyle vec x vec x gamma vec x vec x displaystyle gamma displaystyle gamma displaystyle vec x vec x vec x cdot vec x displaystyle displaystyle kernel transform displaystyle varphi vec x displaystyle vec x vec x varphi vec x cdot varphi vec x value transform space displaystyle vec sum alpha y varphi vec dot product classification compute kernel trick displaystyle vec cdot varphi vec sum alpha y vec vec svm classifier compute soft margin svm classifier minimize form max displaystyle leave frac sum max leave y cdot x right right lambda lvert rvert soft margin classifier note choose small value displaystyle lambda margin classifier linearly input datum approach reduce quadratic programming problem approach sub gradient descent coordinate descent primal minimize optimization problem function follow way displaystyle ldot variable max displaystyle zeta max leave y cdot x right note displaystyle zeta small number displaystyle y cdot x geq zeta optimization problem follow minimize displaystyle text minimize frac sum zeta lambda subject displaystyle text subject y cdot x geq zeta text zeta geq text call primal problem dual solve dual problem problem maximize displaystyle text maximize c ldot c sum c frac sum sum y c x cdot x y c subject displaystyle text subject sum c y text leq c leq frac lambda text call dual problem dual problem quadratic function displaystyle c subject linear constraint efficiently quadratic programming algorithm variable displaystyle c define displaystyle vec sum c y vec displaystyle c displaystyle vec lie correct margin displaystyle c lambda displaystyle vec lie margin boundary follow displaystyle vec linear combination support vector displaystyle displaystyle vec margin boundary solve displaystyle y vec cdot vec vec cdot vec y note displaystyle y y displaystyle y kernel trick like learn nonlinear classification linear classification transform datum point displaystyle varphi vec give kernel function displaystyle displaystyle vec vec varphi vec cdot varphi vec know classification vector displaystyle vec transform space displaystyle vec sum c y varphi vec displaystyle c solve optimization problem maximize displaystyle begin align text maximize c ldot c sum c frac sum sum y c varphi vec cdot varphi vec y c sum c frac sum sum y c vec vec y c end align subject displaystyle text subject sum c y text leq c leq frac lambda text coefficient displaystyle c solve quadratic programming displaystyle displaystyle c lambda displaystyle varphi vec lie boundary margin transform space solve displaystyle begin align vec cdot varphi vec y leave sum c y varphi vec cdot varphi vec right y leave sum c y vec vec right y end align sgn sgn displaystyle vec operatorname sgn vec cdot varphi vec operatorname sgn leave sum c y vec vec right right method algorithm svm classifier include sub gradient descent coordinate descent technique approach large sub gradient method training example coordinate descent feature space high sub gradient descent sub gradient descent algorithm svm work max displaystyle vec leave frac sum max leave y vec cdot vec right right lambda lvert vec rvert note displaystyle function displaystyle vec displaystyle gradient descent method take function gradient take vector select function sub gradient approach number iteration scale displaystyle number datum point coordinate descent coordinate descent algorithm svm work dual problem maximize displaystyle text maximize c ldot c sum c frac sum sum y c x cdot x y c subject displaystyle text subject sum c y text leq c leq frac lambda text displaystyle ldot coefficient displaystyle c displaystyle c result vector coefficient displaystyle c ldot c near vector coefficient give constraint distance near vector coefficient result algorithm empirical risk minimization soft margin support vector machine example empirical risk minimization algorithm hinge loss way support vector machine belong class algorithm feature hinge loss svms work allow property risk minimization learn give set training example displaystyle x ldot x label displaystyle y ldot y displaystyle y give displaystyle x form hypothesis displaystyle displaystyle x good approximation displaystyle y good approximation define loss function displaystyle ell displaystyle prediction displaystyle like choose hypothesis minimize risk displaystyle varepsilon leave ell y x right case know displaystyle x y case common choose hypothesis minimize empirical risk displaystyle hat varepsilon frac sum ell y x variable displaystyle x y example finite set hypothesis consider small empirical risk risk displaystyle large approach call empirical risk minimization regularization minimization problem define constraint set displaystyle mathcal hypothesis consider displaystyle mathcal space case svm technique consider hypothesis displaystyle displaystyle lvert rvert mathcal regularization displaystyle mathcal lambda lvert rvert mathcal solve new optimization problem displaystyle hat mathcal hat varepsilon mathcal approach call regularization displaystyle mathcal hypothesis displaystyle hypothesis svm hinge loss soft margin svm classifier sgn displaystyle hat operatorname sgn hat cdot choose minimize follow max displaystyle leave frac sum max leave y cdot x right right lambda lvert rvert svm technique empirical risk minimization regularization case loss function hinge loss max displaystyle ell max leave right svm classification algorithm square logistic regression lie choice loss function square empirical risk minimization square loss displaystyle ell logistic regression log loss log ln displaystyle ell log ln target function hinge loss loss function term target function function minimize risk give variable displaystyle displaystyle y displaystyle displaystyle classification set probability probability displaystyle y begin case text probability p text probability p end case classifier displaystyle begin case text p geq text end case square loss target function function displaystyle f leave y right logistic loss function log ln displaystyle f log ln leave p p right target function correct classifier sgn sgn log displaystyle operatorname sgn f operatorname sgn f log displaystyle y target function hinge loss displaystyle hypothesis space choose kernel svm classifier function term displaystyle mathcal classify data extend interpretation svm linear classification empirical risk minimize function margin lie support vector max margin classifier property svm belong linear classifier consider special case regularization special property minimize empirical classification error maximize margin know maximum margin classifier svm classifier paramet svm kernel kernel parameter soft margin paramet common choice kernel paramet displaystyle gamma good combination displaystyle gamma select displaystyle gamma example displaystyle dot displaystyle gamma dot combination paramet choice parameter work bayesian optimization select displaystyle gamma paramet combination model classify new datum training set select parameter svm include follow label input datum class probability svm vapnik probability finite datum svm class task algorithm reduce class task binary problem apply class svm parameter solve model support vector method kernel function learn consider method datum science multiclass svm multiclass svm assign label instance support vector machine label finite set approach reduce multiclass problem binary classification problem common method include binary classifier label versus class versus classification new instance versus case take classifier high output function assign class output function versus approach classification max vote classifier assign instance class vote assign class vote class vote determine instance classification svm error correct output propose multiclass svm method multiclass classification problem optimization problem binary classification problem transductive support vector machine transductive support vector machine extend svms label datum learning follow training set displaystyle mathcal give set displaystyle mathcal star vec star vec star test example classify transductive support vector machine define follow primal optimization problem minimize displaystyle vec vec star displaystyle frac vec subject displaystyle dot displaystyle dot displaystyle y vec cdot vec x geq displaystyle y star vec cdot vec x star geq displaystyle y star transductive support vector machine vladimir vapnik svm svm svms label space regression version svm regression propose vladimir vapnik method call support vector regression model support vector classification training datum function model training point lie margin model training datum function model datum model prediction svm version know square support vector machine svm propose training original solve minimize displaystyle frac subject displaystyle y x leq varepsilon displaystyle x training target value displaystyle y product displaystyle x prediction displaystyle varepsilon paramet prediction displaystyle varepsilon prediction variable allow error allow approximation case problem bayesian svm svm bayesian interpretation technique datum approach svm model parameter probability extend allow application bayesian technique svm feature model version bayesian svm application bayesian svms datum version bayesian kernel support vector machine svm version linear bayesian svm parameter maximum margin hyperplane solve optimization algorithm solve quadratic programming problem svms problem small approach use point method use like iteration primal dual problem solve problem approach solve problem solve linear large kernel approximation kernel trick common method optimization algorithm problem dimensional sub problem solve optimization algorithm algorithm scale property svm problem special case linear support vector machine solve efficiently algorithm logistic regression class algorithm include sub gradient descent coordinate descent training property iteration take linear take datum iteration linear property algorithm kernel svms solve efficiently sub gradient descent allow kernel svms machine learn include learn kernel machine kernel scale kernel regularization support vector machine vector machine kernel model form svm optimization space algorithm support vector machine pdf support vector machine kernel base learning method isbn support vector machine classification pdf method science application support vector machine pdf isbn support vector machine pdf learning application new isbn learn kernel isbn support vector machine new isbn isbn svm large linear classification include svms svm learn classification svm svms\n",
      "=====Latent_variable_models\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent variable observable variable variable directly infer model variable directly measure model variable latent variable latent variable model latent variable model include latent variable measure variable variable observable latent variable datum variable latent variable datum observable variable model datum latent variable observable datum datum model latent variable factor variable variable latent factor model infer factor analysis include latent variable measure factor latent variable include quality life variable measure directly latent variable observable variable latent variable infer observable variable quality life latent variable measure directly observable variable infer quality life observable variable measure quality life include infer latent variable latent variable infer model factor analysis analysis latent analysis latent analysis infer latent variable latent latent latent latent variable\n",
      "=====Structural_equation_models\n",
      "=======\n",
      "structural equation model sem form causal include set model statistical method fit construct sem include factor analysis analysis path analysis partial square path model latent model concept concept structural model structural model structural equation model assess latent construct measurement model latent variable observe variable structural model relationship latent variable construct structural equation model estimate regression equation approach lisrel use sem social science relationship construct latent variable variable provide example concept intelligence measure measure develop hypothesis intelligence measurement item question design measure intelligence hypothesis use sem test hypothesis datum intelligence test sem intelligence latent variable test item observe variable model suggest intelligence measure question measure show sem latent variable show variable show intelligence question score latent variable sem provide estimate parameter model indicate relationship testing theory sem researcher observe variable good indicator latent variable method structural equation model science sem method model structural equation model term psychology social science method path model wright form sem different system equation regression method develop cowle commission iterative maximum likelihood algorithm path analysis develop karl jöreskog testing university iterative fit algorithm path analysis develop university wold time method structural equation path provide method method pls pa algorithm partial square regression square regression path analysis pls pa method small estimation approach show develop algorithm sample size sem small sample size example lisrel pls pa iterative algorithm datum wright path analysis cowle commission simultaneous equation estimation algorithm maximum likelihood estimation form iterative technique develop maximum likelihood parameter structural equation include square square propose method estimate parameter structural equation simultaneous equation maximum likelihood estimation algorithm iterative sem algorithm square method system regression equation approach develop cowle commission model wright path analysis method university university identify path analysis application social science identify wright path method pls pa lisrel social science path causal assumption statistical claim method social science wold wright path analysis large wold karl jöreskog jöreskog lisrel structural equation method analysis large technique algorithm square algorithm path pls path analysis package estimate covariance analysis algorithm wold karl jöreskog lisrel simultaneous equation regression algorithm develop cowle commission sem model propose causal interpretation equation example variable equation variable variable sem estimation effect form equation term analysis system variable interaction causal interpretation sem sem path analysis method social science package program researcher experimental design effect sample size factor good research design causal interpretation psychology social interaction science suggest experimental model sem effect assumption social interaction causal factor example example time causal factor time interaction factor approach sem technique sem different sem method model model sem structural model show causal variable measurement model show latent variable indicator factor analysis model example contain measurement path sem contain structural model modeler relationship free causal relationship variable test free relationship variable estimate relationship base model modeler set model order assess model propose set model modeler account model modeler account number datum point number parameter model estimate identify model identify model model paramet value model different paramet value datum point variable score variable contain score question number time paramet value regression variable factor regression indicator factor datum point number estimate parameter model point account model path mean model estimation free parameter parameter estimation covariance matrix relationship variable estimate covariance matrix model fit criterion provide maximum likelihood estimation maximum likelihood estimation square free method sem analysis program model model fit estimate model model estimate path path model variable assess path path analysis fit estimate model determine model datum sem form model model sem program include matrix estimate relationship variable model fit datum matrix contain relationship datum statistical test fit index develop parameter model estimate model order propose model fit theory estimation method test model statistical hypothesis test sem model test base assumption datum model sem fit different application fit index hypothesis test approach assess fit approach model hypothesis model free parameter aic fit value model measure value account number free parameter different measure fit different fit model different fit measure guideline score fit measure include sem researcher measure fit include measure fit fit measure sample size observe covariance matrix model covariance matrix criterion aic test model fit model aic value aic number parameter statistical model value likelihood model mean square fit index value indicate good fit guideline determine fit researcher indicate fit mean fit indicator suggest small guideline good fit suggest small guideline good fit fit index cfi cfi large size datum variable cfi cfi value measure fit good fit model datum factor sample size indicator factor model example large sample test indicate model datum fit model modification model order fit estimate relationship variable program provide modification index modification modification index change free parameter path model set modification model fit change model modification model structural model change theory claim modification term theory test theory change measurement model claim item datum indicator latent variable theory model model sample size researcher large sample size provide statistical estimate sem method determine sample size determine sample size include number paramet number fit index number researcher propose guideline base sample size sem hypothesis test model algorithm pls pa lisrel system regression equation testing interpretation set model claim construct base good model claim time order term causal model mean model causal assumption model causal datum time point experimental experimental design hypothesis causal good fit model causal hypothesis good fit model causal hypothesis research design hypothesis science modification use measurement technique estimation model different application include analysis test form different latent model model item theory model model latent sem estimation testing technique sample method model structural equation model sem software software package structural equation model lisrel software package statistical package provide application good software package sem analysis different use different method technique causal model model partial square path model partial square regression simultaneous equation model structural equation latent variable criterion fit index covariance analysis criterion structural equation model doi structural equation model ed sage isbn structural equation model ed isbn application structural equation model research psychology doi structural equation model psychology doi interpretation structural equation model science doi latent variable model factor analysis isbn test fit analysis covariance structural equation latent variable isbn structural equation model concept application isbn structural equation model social science statistical simultaneous equation doi ed structural equation model concept application sage isbn jöreskog karl structural equation model model interaction effect ed structural equation model concept application sage isbn structural equation model sage social science research method doi isbn fit structural equation model method research ed structural equation model software structural equation model structural equation model sem research causal interpretation structural equation sem structural equation model structural equation model item measure construct sem\n",
      "=====Factor_analysis\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor analysis statistical method observe correlate variable term low number unobserved variable call factor example possible variation observe variable variation variable factor analysis variation unobserved latent variable observe variable model linear combination factor error term factor analysis aim independent latent variable theory factor method information observed variable reduce set variable factor analysis psychometric personality theory product research data set large number observed variable number underlie latent variable inter technique set variable inter objective latent factor factor analysis relate principal component analysis pca field difference technique exploratory factor analysis principal component analysis pca exploratory factor analysis efa high speed computer pca factor analysis aim reduce set datum approach different technique factor analysis objective identify certain factor observe variable pca address objective pca require factor point exploratory analysis eigenvalue pca component loading error variance statistical model suppose set displaystyle random variable displaystyle x dot x mean displaystyle mu dot mu suppose displaystyle l displaystyle unobserved random variable displaystyle f call common factor influence observe random variable displaystyle dot displaystyle dot displaystyle displaystyle x mu l f cdot l f varepsilon displaystyle varepsilon unobserved error term zero mean variance displaystyle matrix term displaystyle mu varepsilon displaystyle observation displaystyle x time displaystyle l time displaystyle f time column displaystyle displaystyle value particular observation matrix displaystyle observation follow assumption displaystyle displaystyle displaystyle varepsilon independent displaystyle mathrm displaystyle mathrm cov factor uncorrelated solution set equation follow displaystyle define factor displaystyle loading matrix suppose displaystyle mathrm cov mu sigma displaystyle sigma mathrm cov mu mathrm cov varepsilon displaystyle displaystyle sigma mathrm cov mathrm cov varepsilon set displaystyle mathrm cov varepsilon displaystyle sigma note orthogonal matrix displaystyle set displaystyle displaystyle criterion factor factor loading set factor factor loading unique orthogonal example suppose hypothesis intelligence verbal intelligence mathematical intelligence observe hypothesis seek score different field student student choose large student score random variable hypothesis field score group student common value verbal mathematical intelligence time level verbal intelligence time level mathematical intelligence combination factor number particular subject intelligence score hypothesis intelligence level call factor load subject example hypothesis average student aptitude field student verbal intelligence student mathematical intelligence number factor loading associate subject different factor loading student assume degree latent verbal mathematical intelligence different measure aptitude individual aptitude differ average aptitude measurement error difference call error statistical term mean individual measure differ average level intelligence error residual datum factor analysis score student total number factor loading level intelligence student datum mathematical model example follow matrix indicate variable subject indicate value run displaystyle n equal example factor indicate value run displaystyle n equal example sample indicate value run displaystyle n example sample displaystyle n student displaystyle n student score give displaystyle x ai factor analysis correlation variable displaystyle x displaystyle x ai particular set observation order variable equal displaystyle z ai x ai mu sigma sample mean displaystyle mu n sum x ai sample variance give displaystyle sigma n sum x ai mu factor analysis model particular sample displaystyle matrix z ell f ell f varepsilon vdot vdot vdot vdot z ell f ell f varepsilon matrix displaystyle z ai sum ell ap f pi varepsilon ai displaystyle f student verbal intelligence displaystyle f student mathematical intelligence displaystyle ell ap factor loading subject matrix displaystyle observe verbal intelligence component column measure factor loading verbal intelligence make difference model assume standard factor verbal intelligence mathematical intelligence reason assume factor uncorrelated displaystyle sum f pi f delta displaystyle delta delta displaystyle displaystyle error assume independent factor displaystyle sum f pi varepsilon ai note rotation solution solution make interpret factor particular example know type intelligence uncorrelated interpret factor different type intelligence uncorrelated factor correspond verbal intelligence correspond mathematical intelligence value loading average variance error estimate give observed datum assumption level factor give derive displaystyle sum z ai z sum ell ap ell sum varepsilon ai varepsilon term term correlation matrix displaystyle n time n matrix observed datum displaystyle n diagonal element term right diagonal matrix term unity term right reduce correlation matrix equal correlation matrix diagonal value unity diagonal element reduce correlation matrix call communalitie represent variance observe variable account factor displaystyle sum ell ap ell ap sample datum displaystyle z ai equation give sample error model goal analysis model factor displaystyle f pi loading displaystyle ell ap sense good fit data factor analysis good fit define mean square error diagonal residual correlation matrix displaystyle varepsilon sum ab sum z ai z sum ell ap ell right minimize diagonal component error covariance model equation value zero contrast principal component analysis seek minimize mean square error residual high speed computer solution problem estimate communalitie mean problem yield know correlation matrix estimate factor loading high speed computer problem speed communalitie problem mean solution solution factor allow rotation example correspond mathematical model use orthogonal variable factor analysis give datum displaystyle z ai factor displaystyle f pi error displaystyle varepsilon ai vector displaystyle n dimensional sample represent displaystyle mathbf displaystyle mathbf displaystyle boldsymbol varepsilon datum standardize datum vector length displaystyle mathbf cdot mathbf factor vector define displaystyle n dimensional linear hyperplane datum vector follow model equation displaystyle mathbf sum ell ap mathbf boldsymbol varepsilon factor error displaystyle mathbf cdot boldsymbol varepsilon example hyperplane dimensional define factor vector datum vector hyperplane give displaystyle hat mathbf sum ell ap mathbf error vector point datum point hyperplane goal factor analysis hyperplane good fit datum sense factor vector define hyperplane choose independent hyperplane orthogonal displaystyle mathbf cdot mathbf delta set factor hyperplane rotation factor vector define hyperplane solution result example fit hyperplane dimensional know type intelligence uncorrelated interpret factor different type intelligence uncorrelated factor correspond verbal intelligence correspond mathematical intelligence factor linear combination data vector displaystyle mathbf length correlation matrix datum give displaystyle ab mathbf cdot mathbf correlation matrix interpret data vector displaystyle mathbf displaystyle mathbf diagonal element diagonal element value equal unity reduce correlation matrix define displaystyle hat ab hat mathbf cdot hat mathbf goal factor analysis choose fit hyperplane reduce correlation matrix correlation matrix possible diagonal element correlation matrix know value goal possible correlation datum hyperplane mean square error diagonal component displaystyle varepsilon sum ab hat ab right minimize minimize set factor vector displaystyle ab hat ab boldsymbol varepsilon cdot boldsymbol varepsilon term right covariance error model error covariance diagonal matrix problem yield good fit model yield sample estimate error covariance diagonal component minimize mean square sense displaystyle hat orthogonal datum vector length equal length datum vector unity square length diagonal element reduce correlation matrix diagonal element reduce correlation matrix know communalitie displaystyle hat mathbf cdot hat mathbf sum ell ap ell ap large value communalitie indicate hyperplane correlation matrix mean value factor zero follow mean value error zero type factor analysis exploratory factor analysis efa identify item group item researcher make assumption relationship factor factor analysis approach test hypothesis item associate factor use equation model test measurement model loading factor allow relationship observe variable unobserved variable equation model approach measurement error square model test datum analysis loading observe variable latent variable factor correlation latent variable type factor extraction principal component analysis pca method factor extraction efa factor weight compute extract possible variance factoring variance factor model analysis canonical factor analysis call canonical factor different method model pca use principal axis method canonical factor analysis seek factor high canonical correlation observe variable canonical factor analysis data common factor analysis call principal factor analysis principal axis factoring seek number factor account common variance correlation set variable factoring base correlation matrix variable variable variable multiple factoring base factor assume variable sample variable method assume case sample variable factor model model factor model model factor model factor know factor loading square standardize loading item square squared factor load variance variable explain factor variance variable account factor sum squared factor loading factor column number variable note number variable equal sum variance variance standardize variable factor eigenvalue number variable interpret factor loading rule factor analysis loading high independent variable identify represent particular factor level correspond variance explain factor standard high datum criterion researcher exploratory use low level factor factor factor loading interpret theory level oblique rotation pattern matrix structure matrix structure matrix factor load matrix orthogonal rotation represent variance measure variable explain factor unique common pattern matrix contrast coefficient represent unique factor low pattern coefficient rule common variance explain oblique rotation researcher structure pattern coefficient attribute factor oblique rotation derive communality sum squared factor loading factor give variable variance variable account factor communality measure variance give variable factor interpret factor solution communality solution sample extract factor variable variable communality eigenvalue eigenvalue measure variation total sample account factor eigenvalue factor variable factor low eigenvalue variance variable important factor high eigenvalue extraction sum squared loading initial eigenvalue eigenvalue extraction extraction sum squared loading pca extraction extraction method eigenvalue extraction low initial rotation sum squared loading pca eigenvalue differ initial extraction eigenvalue total factor score call component score pca score case factor column compute factor score give case give factor case standardize score variable correspond loading variable give factor sum product compute factor score allow factor factor score variable explain pca factor analysis criterion determine number factor researcher subjective criterion factor sense number objective method problem allow determine solution method analysis suggest factor map suggest researcher factor solution term datum theory criterion analysis base method observe eigenvalue uncorrelated variable factor component retain associate eigenvalue eigenvalue derive random datum rule determine number component retain program include case influence sample item type correlation coefficient map test principal component analysis follow matrix correlation note number square correlation step average square diagonal correlation correlation matrix step principal component associate item average squared diagonal correlation correlation matrix compute step step principal component average square diagonal correlation compute step represent total number variable matrix average squared correlation step step number result low average squared correlation determine number component factor retain method component variance correlation matrix represent variance residual error variance principal component analysis map technique determine number factor retain multiple study procedure method criterion rule drop component eigenvalue eigenvalue equal information account average single item criterion sps statistical criterion estimate number factor extract factor variation method researcher eigenvalue retain factor scree cattell scree test component axis correspond eigenvalue axis right component eigenvalue drop drop make elbow cattell scree test drop component elbow rule researcher elbow subjective multiple elbow researcher set number factor research variance explain criterion researcher use rule factor account variation researcher goal explain variance factor possible criterion low rotation method variance account factor factor orthogonal datum item load factor usually item load factor rotation call simple structure pattern loading item load factor factor rotation orthogonal oblique allow factor correlate varimax rotation orthogonal rotation factor axis variance squared loading factor column variable factor matrix variable extract factor factor large loading particular variable varimax solution yield result possible identify variable single factor common rotation factor assumption oblique rotation orthogonal rotation reason oblique rotation method allow factor correlate psychometric research ability correlate assume rotation orthogonal minimize number factor explain variable type rotation general factor variable load high degree factor structure usually research rotation varimax rotation standard method orthogonal oblique solution factor allow correlate result high eigenvalue factor rotation orthogonal oblique rotation method method large high order factor analysis high order factor analysis statistical method step factor analysis oblique rotation factor analysis factor research structure study interpret result factor pattern matrix high order factor pattern matrix varimax rotation result schmid leiman solution schmid leiman know schmid leiman attribute variation factor order factor psychometric use factor analysis field psychology factor analysis score subject correlate general ability underlie broad field intelligence research know theory student factor analysis study inter individual difference factor analysis subjective individual difference cattell factor theory intelligence test factor analysis factor theory explain intelligence cattell theory address factor include psychology cattell mathematical method psychometric scree test coefficient research theory intelligence personality factor theory personality cattell factor analysis psychometric theory derive research use observation objective study intelligence psychology factor analysis identify factor explain result different test example intelligence research high score test verbal ability good test require verbal ability researcher explain factor analysis factor call verbal intelligence represent degree problem verbal factor analysis psychology associate intelligence research factor broad personality psychometric measure factor number variable variable single factor example run weight single factor general ability usually item matrix factor group item factor analysis technique matrix factor group example group group inter variable relate example factor analysis theory factor call broad visual perception relate good individual visual broad auditory perception factor relate auditory factor call general intelligence relate broad visual perception broad auditory perception mean high high visual perception high auditory perception explain good good different theory differ term axis give solution term model fit theory mean rotation represent different rotation standard factor analysis rotation factor analysis factor analysis good datum allow psychology researcher measure factor analysis base solution datum factor factor analysis identify exploratory factor analysis principal component analysis exploratory factor analysis principal component analysis technique field fabrigar et al factor analysis researcher make assumption underlie model pca variable technique researcher technique mean objective base goal factor model assumption factor analysis result factor analysis good initial model principal component analysis mathematical datum assumption covariance matrix aim pca determine linear combination variable datum set information contrast pca efa fabrigar et al address number reason suggest principal component analysis factor analysis suggest principal component analysis require factor analysis fabrigar et al suggest pca factor analysis result point address fabrigar et al certain case communalitie low technique result fabrigar et al case datum correspond assumption common factor model result pca result certain case factor analysis case variance measure variable estimate account model fabrigar et al suggest case researcher indicate model common factor model case pca approach mean researcher information pca approach individual score certain component information yield factor analysis fabrigar et al aim factor analysis determine factor account structure correlation measure variable require factor score possible compute factor score factor analysis variance covariance factor analysis account random error measurement pca point indicate correlation matrix pca diagonal variance matrix account include variance unique variable variance common variable error variance include variance variable contrast efa communalitie diagonal variance variable account variance unique variable error variance include variance common variable reason factor analysis relationship variable pca goal researcher pattern datum difference procedure result difference principal component analysis factor analysis pca result principal component account variance observe variable fa account common variance datum pca diagonal correlation matrix fa diagonal correlation matrix unique factor pca minimize sum square component axis fa estimate factor influence observe variable component score pca represent linear combination observe variable weight observe variable fa linear combination underlie unique factor pca component yield represent underlie construct fa construct interpret give model step identify attribute use product use research technique datum sample product attribute datum statistical program run factor analysis procedure yield set underlie attribute factor use factor construct map product information datum usually research product sample product attribute attribute choose include use weight attribute choose product study product study datum multiple product statistical program sps analysis analysis underlie factor explain data matrix factor analysis technique set relationship variable independent variable factor analysis assume datum different attribute reduce important possible attribute relate give attribute result influence attribute statistical call score component score underlie factor score degree correlation initial score factor score call factor loading objective subjective attribute subjective attribute score factor analysis identify latent construct analysis researcher ability set product attribute important attribute value procedure reduce set observe variable item factor analysis single factor factor represent relationship factor require theory attribute correlate reason factor analysis important relate different different possible different example associate high level identify factor factor analysis possible suggest factor score different factor correspond different analysis factor analysis high data level case latent variable correspond sample factor analysis statistical analysis program statistical statistical base function fa function rotation factor sps factor analysis fabrigar use exploratory factor analysis research method high order factor analysis rotation simple loading component function oblique case vol pp product oblique rotation simple structure research vol pp approach simple structure rotation vol pp function point analysis vol pp factor analysis factor analysis schmid leiman factor solution exploratory factor analysis item high order factor structure schmid leiman solution sps research method computer factor analysis exploratory factor analysis factor analysis analysis factor analysis factor analysis\n",
      "=====Cluster_analysis\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster analysis clustering task group set object way object group cluster similar group cluster task datum mining common statistical datum analysis include pattern image analysis information datum cluster analysis algorithm general task algorithm cluster popular cluster include group distance cluster member area datum space particular statistical distribution cluster optimization problem appropriate clustering algorithm include parameter distance function use density number cluster datum set use result cluster analysis automatic task process optimization datum model parameter result property term cluster number term similar include automatic classification analysis community detection use result datum mining result group automatic classification result cluster analysis classification cluster define cluster algorithm common group datum object different different cluster model cluster model different algorithm give cluster different algorithm vary cluster model algorithm cluster model include connectivity model example hierarchical clustering model base distance connectivity centroid model example mean algorithm represent cluster single mean distribution model cluster model statistical distribution distribution algorithm density model example dbscan optic define cluster connect datum space subspace model know clustering cluster cluster model cluster member attribute group model algorithm provide model result provide group information graph base model graph edge consider form cluster complete connectivity edge know cluster algorithm sign graph model sign graph sign product sign edge edge sign result graph negative edge result cluster positive edge neural model know neural network map model usually similar model include subspace model neural network form component analysis component analysis clustering set cluster usually contain object datum set cluster example cluster clustering hard clustering object belong cluster clustering clustering object belong cluster example belong cluster possible example partition clustering object belong cluster partition clustering outlier object belong cluster consider outlier overlap cluster clustering clustering object belong cluster usually hard cluster hierarchical clustering object belong cluster belong cluster subspace clustering overlap clustering define subspace cluster overlap algorithm clustering algorithm base cluster model follow example cluster algorithm clustering algorithm provide model cluster algorithm statistic algorithm correct clustering algorithm clustering appropriate clustering algorithm particular problem need choose cluster model algorithm kind model datum set contain different kind model example mean non convex cluster connectivity base cluster hierarchical clustering connectivity base clustering know hierarchical clustering base object object object algorithm connect object form cluster base distance cluster distance need connect cluster different distance different cluster form represent common hierarchical clustering algorithm provide single partitioning datum set provide cluster distance distance cluster object cluster connectivity base cluster family method way distance compute distance function user need linkage criterion cluster consist multiple object multiple compute distance use popular know single linkage clustering object distance complete linkage cluster object distance pair group method mean know average linkage clustering hierarchical clustering single element cluster complete datum set partition method produce unique partitioning datum set user need choose appropriate cluster outlier cluster cluster know particular single linkage clustering general case complexity displaystyle clustering displaystyle clustering make large data set case method complexity displaystyle know single linkage complete linkage clustering datum mining community method cluster analysis consider provide method density base clustering linkage clustering example centroid base clustering centroid base clustering cluster represent necessarily member datum set number cluster mean clustering give optimization problem cluster center assign object cluster center distance cluster optimization problem know hard common approach search know method algorithm mean algorithm algorithm run multiple time different random variation mean include optimization choose multiple run centroid member datum set choose cluster choose center mean cluster mean mean type algorithm number cluster consider algorithm algorithm cluster similar assign object near centroid lead border cluster algorithm optimize cluster center cluster border mean number property partition datum space structure know near neighbor classification popular variation model base clustering algorithm variation algorithm model mean clustering example distribution base cluster clustering model statistic base distribution model cluster define object belong distribution property approach way artificial data set generate random object distribution method problem know model complexity model usually datum make choose appropriate model complexity method know gaussian model algorithm datum set usually model number gaussian distribution parameter optimize datum set multiple run produce different result hard clustering object assign gaussian distribution belong clustering distribution base clustering produce model cluster correlation attribute algorithm user datum set define model gaussian distribution datum gaussian model clustering example density base clustering density base clustering cluster define area high density datum set object area cluster usually consider border point popular density base clustering method dbscan new method define cluster model density similar linkage base clustering base point distance connect point density criterion define number object cluster consist density object form cluster arbitrary method object object range property dbscan complexity low number range result point border point run need run multiple time optic dbscan need choose appropriate value range displaystyle produce hierarchical result linkage clustering density clustering single linkage cluster optic displaystyle parameter optic index dbscan optic kind density detect cluster border data set example overlap gaussian distribution common use case artificial datum cluster border produce algorithm arbitrary cluster density datum set consist gaussian algorithm method cluster model kind datum mean shift clustering approach object area base density object density similar mean cluster density datum set mean shift detect arbitrary cluster similar dbscan density mean shift usually dbscan mean mean shift algorithm datum density result cluster density base clustering example recent development recent exist algorithm recent need process large large data set know data generate cluster lead development clustering method clustering process data set result cluster partitioning datum set partition exist method mean cluster high dimensional datum exist method particular distance function high dimensional space lead new clustering algorithm high dimensional data subspace clustering attribute cluster model include attribute cluster correlation clustering arbitrary subspace cluster model give correlation attribute example cluster algorithm density base clustering method particular dbscan optic family algorithm subspace cluster hierarchical subspace clustering correlation cluster hierarchical correlation cluster correlation connectivity hierarchical density base correlation cluster different clustering base mutual information variation information provide hierarchical clustering algorithm range different function optimize include mutual information recent development statistical lead new type cluster algorithm evaluation evaluation clustering result cluster popular approach internal evaluation clustering single score external evaluation clustering compare exist ground truth classification evaluation human evaluation evaluate clustering application internal evaluation measure problem represent function cluster example cluster datum set silhouette know algorithm internal measure evaluation compare similarity optimization problem necessarily cluster external evaluation similar problem ground truth label need cluster application usually label label possible partitioning datum set exist different clustering approach clustering need human evaluation statistic identify clustering human evaluation internal evaluation clustering result evaluate base datum cluster internal evaluation method usually assign score algorithm produce cluster high similarity cluster low similarity cluster internal criterion cluster evaluation high score internal measure necessarily result information application evaluation algorithm use cluster model example mean cluster optimize object distance distance base internal criterion result cluster internal evaluation measure algorithm algorithm produce result measure index kind structure exist datum set algorithm kind model chance datum set contain different set model evaluation measure different criterion example mean cluster convex cluster evaluation index convex cluster datum set non convex cluster use mean evaluation criterion internal evaluation measure exist usually base item cluster similar item different cluster example follow method cluster algorithm base internal criterion bouldin indexthe bouldin index follow formula max displaystyle frac sum max frac c c number cluster displaystyle c centroid cluster displaystyle displaystyle average distance element cluster displaystyle centroid displaystyle c displaystyle c c distance centroid displaystyle c displaystyle c algorithm produce cluster low intra cluster distance high intra cluster similarity high inter cluster distance low inter cluster similarity low bouldin index clustering algorithm produce cluster bouldin index consider algorithm base criterion dunn indexthe dunn index identify cluster define inter cluster distance intra cluster distance cluster partition dunn index follow formula max displaystyle frac leq leq max leq leq represent distance cluster measure intra cluster distance cluster inter cluster distance cluster number distance measure distance centroid cluster intra cluster distance measure way distance pair element cluster internal criterion cluster high intra cluster similarity low inter cluster similarity algorithm produce cluster high dunn index silhouette silhouette average distance element cluster average distance element cluster object high silhouette value consider object low value outlier index mean cluster number cluster external evaluation external evaluation clustering result evaluate base datum clustering know class label external benchmark benchmark consist set item set human benchmark set evaluation type evaluation method measure clustering benchmark class datum datum set ground truth class contain internal structure attribute cluster class contain point know necessarily result cluster information class label clustering process information evaluation non number measure evaluate classification task number time class assign single datum point know true positive pair pair datum point cluster cluster internal evaluation external evaluation measure exist example purity purity measure cluster contain single class follow cluster number datum point common class cluster sum cluster divide number datum point give set cluster displaystyle set class displaystyle partition displaystyle datum point purity define max displaystyle frac sum max measure cluster example purity score possible data point cluster purity data dataset consist class class contain point point clustering algorithm high purity value rand index rand rand index compute similar cluster return cluster algorithm benchmark classification rand index measure correct algorithm compute follow formula displaystyle frac tp tn tp fp fn tn displaystyle tp number true positive displaystyle tn number true negative displaystyle fp number false positive displaystyle fn number false negative rand index false positive false negative weight clustering application measure chance correct rand index measure false negative weight recall displaystyle beta precision recall external evaluation measure define follow displaystyle frac tp tp fp displaystyle frac tp tp fn displaystyle precision displaystyle recall measure follow formula displaystyle beta frac beta cdot cdot beta cdot displaystyle beta displaystyle recall measure displaystyle beta displaystyle beta weight recall measure displaystyle tn vary jaccard indexthe jaccard index similarity dataset jaccard index value index mean dataset index dataset common element jaccard index define follow formula displaystyle frac frac tp tp fp fn number unique element common set divide number unique element set displaystyle tn vary indexthe measure weight displaystyle tp displaystyle tn displaystyle frac tp tp fp fn fowlke mallow index fowlke mallow fowlke mallow index compute similarity cluster return cluster algorithm benchmark classification high value fowlke mallow index similar cluster benchmark classification compute follow formula displaystyle frac tp tp fp cdot frac tp tp fn displaystyle tp number true positive displaystyle fp number false positive displaystyle fn number false negative displaystyle index mean precision recall displaystyle displaystyle know measure measure mean precision recall know index displaystyle displaystyle chance recall precision measure correlation mutual information information measure information clustering ground truth classification detect non similarity clustering mutual information family correct chance reduce vary cluster number result classification clustering algorithm different cluster cluster cluster measure cluster measure cluster exist datum cluster clustering way compare datum random datum average random datum cluster multiple statistic follow displaystyle set displaystyle datum point displaystyle dimensional space consider random displaystyle datum point member displaystyle generate set displaystyle displaystyle datum point define distance measure displaystyle distance displaystyle near neighbor displaystyle distance displaystyle near neighbor define statistic displaystyle frac sum sum sum random datum value near cluster datum value near datum contain single gaussian score statistic measure distribution make statistic application datum application cluster analysis community generate artificial cluster high number attribute cluster group gene pattern know gene cluster algorithm group contain gene high sequence general sequence analysis sequence clustering group sequence gene family general gene high cluster algorithm assign human clustering similarity datum clustering structure image cluster analysis different type dimensional image different analysis cluster analysis pattern clustering divide map distinct base market cluster analysis market datum market use cluster analysis partition general market different group use market product new product development market group item clustering group item set unique product example item group unique product network analysis network cluster community large group search result process group clustering set search result compare search number base clustering return set result case search term different distinct use term unique cluster result algorithm return result result cluster map optimization map map use cluster reduce number map make reduce cluster reduce property form way image clustering divide image distinct border detection object algorithm clustering identify different algorithm new item base user use cluster algorithm user base user user cluster method cluster distribution detection outlier define cluster structure datum clustering analysis cluster analysis identify area particular type identify distinct area similar time possible datum mining cluster analysis example identify group similar property datum center use cluster analysis cluster algorithm object detect outlier datum similarity example cluster space index pattern analysis cluster cluster analysis datum evaluate property clustering property different type cluster analysis automatic clustering algorithm clustering cluster high dimensional datum clustering clustering cluster community detection datum clustering clustering sequence cluster clustering cluster analysis artificial neural network neighbor search component analysis class analysis datum component analysis cluster weight model number cluster datum set structure datum analysis\n",
      "=====Clustering_criteria\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification score score measure measure precision recall score number positive number positive number positive number positive score mean precision recall score precision recall measure measure score score mean precision recall displaystyle f frac mathrm recall mathrm precision cdot frac mathrm precision cdot mathrm recall mathrm precision mathrm recall positive recall precision displaystyle f beta beta cdot frac mathrm precision cdot mathrm recall beta cdot mathrm precision mathrm recall displaystyle f beta frac beta cdot mathrm positive beta cdot mathrm positive beta cdot mathrm false negative mathrm false positive displaystyle f measure recall precision false negative displaystyle f measure recall precision false negative measure displaystyle f beta measure recall precision measure displaystyle frac frac displaystyle f beta displaystyle frac beta score coefficient coefficient classification recall score score measure classification classification score precision recall displaystyle f beta score measure negative measure coefficient score score precision recall classification precision recall measure measure mean recall precision measure mean coefficient precision recall coefficient coefficient\n",
      "=====Cluster_analysis_algorithms\n",
      "=======\n",
      "cluster analysis clustering task group set object way object group cluster similar group cluster task datum mining common statistical datum analysis include pattern image analysis information datum cluster analysis algorithm general task algorithm cluster popular cluster include group distance cluster member area datum space particular statistical distribution cluster optimization problem appropriate clustering algorithm include parameter distance function use density number cluster datum set use result cluster analysis automatic task process optimization datum model parameter result property term cluster number term similar include automatic classification analysis community detection use result datum mining result group automatic classification result cluster analysis classification cluster define cluster algorithm common group datum object different different cluster model cluster model different algorithm give cluster different algorithm vary cluster model algorithm cluster model include connectivity model example hierarchical clustering model base distance connectivity centroid model example mean algorithm represent cluster single mean distribution model cluster model statistical distribution distribution algorithm density model example dbscan optic define cluster connect datum space subspace model know clustering cluster cluster model cluster member attribute group model algorithm provide model result provide group information graph base model graph edge consider form cluster complete connectivity edge know cluster algorithm sign graph model sign graph sign product sign edge edge sign result graph negative edge result cluster positive edge neural model know neural network map model usually similar model include subspace model neural network form component analysis component analysis clustering set cluster usually contain object datum set cluster example cluster clustering hard clustering object belong cluster clustering clustering object belong cluster example belong cluster possible example partition clustering object belong cluster partition clustering outlier object belong cluster consider outlier overlap cluster clustering clustering object belong cluster usually hard cluster hierarchical clustering object belong cluster belong cluster subspace clustering overlap clustering define subspace cluster overlap algorithm clustering algorithm base cluster model follow example cluster algorithm clustering algorithm provide model cluster algorithm statistic algorithm correct clustering algorithm clustering appropriate clustering algorithm particular problem need choose cluster model algorithm kind model datum set contain different kind model example mean non convex cluster connectivity base cluster hierarchical clustering connectivity base clustering know hierarchical clustering base object object object algorithm connect object form cluster base distance cluster distance need connect cluster different distance different cluster form represent common hierarchical clustering algorithm provide single partitioning datum set provide cluster distance distance cluster object cluster connectivity base cluster family method way distance compute distance function user need linkage criterion cluster consist multiple object multiple compute distance use popular know single linkage clustering object distance complete linkage cluster object distance pair group method mean know average linkage clustering hierarchical clustering single element cluster complete datum set partition method produce unique partitioning datum set user need choose appropriate cluster outlier cluster cluster know particular single linkage clustering general case complexity displaystyle clustering displaystyle clustering make large data set case method complexity displaystyle know single linkage complete linkage clustering datum mining community method cluster analysis consider provide method density base clustering linkage clustering example centroid base clustering centroid base clustering cluster represent necessarily member datum set number cluster mean clustering give optimization problem cluster center assign object cluster center distance cluster optimization problem know hard common approach search know method algorithm mean algorithm algorithm run multiple time different random variation mean include optimization choose multiple run centroid member datum set choose cluster choose center mean cluster mean mean type algorithm number cluster consider algorithm algorithm cluster similar assign object near centroid lead border cluster algorithm optimize cluster center cluster border mean number property partition datum space structure know near neighbor classification popular variation model base clustering algorithm variation algorithm model mean clustering example distribution base cluster clustering model statistic base distribution model cluster define object belong distribution property approach way artificial data set generate random object distribution method problem know model complexity model usually datum make choose appropriate model complexity method know gaussian model algorithm datum set usually model number gaussian distribution parameter optimize datum set multiple run produce different result hard clustering object assign gaussian distribution belong clustering distribution base clustering produce model cluster correlation attribute algorithm user datum set define model gaussian distribution datum gaussian model clustering example density base clustering density base clustering cluster define area high density datum set object area cluster usually consider border point popular density base clustering method dbscan new method define cluster model density similar linkage base clustering base point distance connect point density criterion define number object cluster consist density object form cluster arbitrary method object object range property dbscan complexity low number range result point border point run need run multiple time optic dbscan need choose appropriate value range displaystyle produce hierarchical result linkage clustering density clustering single linkage cluster optic displaystyle parameter optic index dbscan optic kind density detect cluster border data set example overlap gaussian distribution common use case artificial datum cluster border produce algorithm arbitrary cluster density datum set consist gaussian algorithm method cluster model kind datum mean shift clustering approach object area base density object density similar mean cluster density datum set mean shift detect arbitrary cluster similar dbscan density mean shift usually dbscan mean mean shift algorithm datum density result cluster density base clustering example recent development recent exist algorithm recent need process large large data set know data generate cluster lead development clustering method clustering process data set result cluster partitioning datum set partition exist method mean cluster high dimensional datum exist method particular distance function high dimensional space lead new clustering algorithm high dimensional data subspace clustering attribute cluster model include attribute cluster correlation clustering arbitrary subspace cluster model give correlation attribute example cluster algorithm density base clustering method particular dbscan optic family algorithm subspace cluster hierarchical subspace clustering correlation cluster hierarchical correlation cluster correlation connectivity hierarchical density base correlation cluster different clustering base mutual information variation information provide hierarchical clustering algorithm range different function optimize include mutual information recent development statistical lead new type cluster algorithm evaluation evaluation clustering result cluster popular approach internal evaluation clustering single score external evaluation clustering compare exist ground truth classification evaluation human evaluation evaluate clustering application internal evaluation measure problem represent function cluster example cluster datum set silhouette know algorithm internal measure evaluation compare similarity optimization problem necessarily cluster external evaluation similar problem ground truth label need cluster application usually label label possible partitioning datum set exist different clustering approach clustering need human evaluation statistic identify clustering human evaluation internal evaluation clustering result evaluate base datum cluster internal evaluation method usually assign score algorithm produce cluster high similarity cluster low similarity cluster internal criterion cluster evaluation high score internal measure necessarily result information application evaluation algorithm use cluster model example mean cluster optimize object distance distance base internal criterion result cluster internal evaluation measure algorithm algorithm produce result measure index kind structure exist datum set algorithm kind model chance datum set contain different set model evaluation measure different criterion example mean cluster convex cluster evaluation index convex cluster datum set non convex cluster use mean evaluation criterion internal evaluation measure exist usually base item cluster similar item different cluster example follow method cluster algorithm base internal criterion bouldin indexthe bouldin index follow formula max displaystyle frac sum max frac c c number cluster displaystyle c centroid cluster displaystyle displaystyle average distance element cluster displaystyle centroid displaystyle c displaystyle c c distance centroid displaystyle c displaystyle c algorithm produce cluster low intra cluster distance high intra cluster similarity high inter cluster distance low inter cluster similarity low bouldin index clustering algorithm produce cluster bouldin index consider algorithm base criterion dunn indexthe dunn index identify cluster define inter cluster distance intra cluster distance cluster partition dunn index follow formula max displaystyle frac leq leq max leq leq represent distance cluster measure intra cluster distance cluster inter cluster distance cluster number distance measure distance centroid cluster intra cluster distance measure way distance pair element cluster internal criterion cluster high intra cluster similarity low inter cluster similarity algorithm produce cluster high dunn index silhouette silhouette average distance element cluster average distance element cluster object high silhouette value consider object low value outlier index mean cluster number cluster external evaluation external evaluation clustering result evaluate base datum clustering know class label external benchmark benchmark consist set item set human benchmark set evaluation type evaluation method measure clustering benchmark class datum datum set ground truth class contain internal structure attribute cluster class contain point know necessarily result cluster information class label clustering process information evaluation non number measure evaluate classification task number time class assign single datum point know true positive pair pair datum point cluster cluster internal evaluation external evaluation measure exist example purity purity measure cluster contain single class follow cluster number datum point common class cluster sum cluster divide number datum point give set cluster displaystyle set class displaystyle partition displaystyle datum point purity define max displaystyle frac sum max measure cluster example purity score possible data point cluster purity data dataset consist class class contain point point clustering algorithm high purity value rand index rand rand index compute similar cluster return cluster algorithm benchmark classification rand index measure correct algorithm compute follow formula displaystyle frac tp tn tp fp fn tn displaystyle tp number true positive displaystyle tn number true negative displaystyle fp number false positive displaystyle fn number false negative rand index false positive false negative weight clustering application measure chance correct rand index measure false negative weight recall displaystyle beta precision recall external evaluation measure define follow displaystyle frac tp tp fp displaystyle frac tp tp fn displaystyle precision displaystyle recall measure follow formula displaystyle beta frac beta cdot cdot beta cdot displaystyle beta displaystyle recall measure displaystyle beta displaystyle beta weight recall measure displaystyle tn vary jaccard indexthe jaccard index similarity dataset jaccard index value index mean dataset index dataset common element jaccard index define follow formula displaystyle frac frac tp tp fp fn number unique element common set divide number unique element set displaystyle tn vary indexthe measure weight displaystyle tp displaystyle tn displaystyle frac tp tp fp fn fowlke mallow index fowlke mallow fowlke mallow index compute similarity cluster return cluster algorithm benchmark classification high value fowlke mallow index similar cluster benchmark classification compute follow formula displaystyle frac tp tp fp cdot frac tp tp fn displaystyle tp number true positive displaystyle fp number false positive displaystyle fn number false negative displaystyle index mean precision recall displaystyle displaystyle know measure measure mean precision recall know index displaystyle displaystyle chance recall precision measure correlation mutual information information measure information clustering ground truth classification detect non similarity clustering mutual information family correct chance reduce vary cluster number result classification clustering algorithm different cluster cluster cluster measure cluster measure cluster exist datum cluster clustering way compare datum random datum average random datum cluster multiple statistic follow displaystyle set displaystyle datum point displaystyle dimensional space consider random displaystyle datum point member displaystyle generate set displaystyle displaystyle datum point define distance measure displaystyle distance displaystyle near neighbor displaystyle distance displaystyle near neighbor define statistic displaystyle frac sum sum sum random datum value near cluster datum value near datum contain single gaussian score statistic measure distribution make statistic application datum application cluster analysis community generate artificial cluster high number attribute cluster group gene pattern know gene cluster algorithm group contain gene high sequence general sequence analysis sequence clustering group sequence gene family general gene high cluster algorithm assign human clustering similarity datum clustering structure image cluster analysis different type dimensional image different analysis cluster analysis pattern clustering divide map distinct base market cluster analysis market datum market use cluster analysis partition general market different group use market product new product development market group item clustering group item set unique product example item group unique product network analysis network cluster community large group search result process group clustering set search result compare search number base clustering return set result case search term different distinct use term unique cluster result algorithm return result result cluster map optimization map map use cluster reduce number map make reduce cluster reduce property form way image clustering divide image distinct border detection object algorithm clustering identify different algorithm new item base user use cluster algorithm user base user user cluster method cluster distribution detection outlier define cluster structure datum clustering analysis cluster analysis identify area particular type identify distinct area similar time possible datum mining cluster analysis example identify group similar property datum center use cluster analysis cluster algorithm object detect outlier datum similarity example cluster space index pattern analysis cluster cluster analysis datum evaluate property clustering property different type cluster analysis automatic clustering algorithm clustering cluster high dimensional datum clustering clustering cluster community detection datum clustering clustering sequence cluster clustering cluster analysis artificial neural network neighbor search component analysis class analysis datum component analysis cluster weight model number cluster datum set structure datum analysis\n",
      "=====Signal_processing_conferences\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digital signal processing downsample decimation process rate digital signal processing downsample decimation process filter sample rate process sequence sample signal sequence sample signal low rate case decimation signal processing decimation factor sample factor sample sample rate sample second decimate factor sample rate decimation call decimation factor call downsample factor rate factor step process implementation reduce frequency signal digital filter decimate filter signal sample step frequency signal form call aliase step aliase filter call anti aliase filter design decimate signal anti aliase filter design output input second step filter output decimate filter output sample dot product displaystyle sum cdot sequence input sequence downsample dot product case design filter dot product form phase dot product sum dot product sample sequence downsample sample dot product dot product low filter filter phase input output sum implementation input filter output sum call filter implementation phase phase process sequence input rate decimate output factor implementation anti aliase filter anti aliase filter pair pair unit graph pair frequency sample fouri transform low graph sample sample sequence decimate factor case displaystyle tfrac cdot tfrac sample sample rate frequency anti aliase filter cutoff frequency displaystyle tfrac frequency pair fouri transform fouri unit second displaystyle unit mt decimate sequence displaystyle sum infty infty cdot mt mathrm mathrm pi mt frac mt sum infty infty tfrac mt reduce factor second graph aliase anti aliase filter reduce pair frequency displaystyle frequency frequency filter design cutoff frequency unit cutoff frequency displaystyle tfrac cdot tfrac displaystyle tfrac cdot tfrac tfrac unit second sample second sample pair graph transform sequence decimate sequence form displaystyle mathrm mathrm omega transform sequence form fouri displaystyle sum infty infty sum infty infty mathrm mathrm omega frac sum infty infty bigl tfrac omega pi tfrac bigr bigl frac omega pi pi bigr graph graph displaystyle sum infty infty sum infty infty mathrm mathrm omega frac mt sum infty infty bigl tfrac omega pi mt tfrac mt bigr bigl frac omega pi pi mt bigr factor decimation factor increase sequence factor call decimate factor filter increase rate step filter decimation filter low cutoff frequency case anti aliase filter cutoff displaystyle tfrac sample low frequency sample rate digital signal processing isbn digital signal processing isbn sample rate decimation digital signal processing isbn reduce sample frequency increase filter digital signal process isbn sample rate sample rate signal process sample rate call decimation process sample rate increase call digital signal process digital signal processing decimation decimation\n",
      "=====Artificial_intelligence_conferences\n",
      "=======\n",
      "association artificial intelligence aaai research artificial intelligence aaai artificial intelligence ai ai provide research ai association artificial intelligence association artificial intelligence conference aaai provide artificial intelligence aaai conference provide artificial intelligence aaai ai research artificial intelligence research aaai aaai conference artificial intelligence conference artificial intelligence award aaai aaai award aaai award aaai award award association artificial intelligence aaai association aaai award aaai award ai provide ai\n",
      "=====Data_mining_and_machine_learning_software\n",
      "=======\n",
      "waikato analysis weka university waikato new zealand software software datum mining machine learning tool technique weka collection visualization tool algorithm datum analysis predictive user interface access java version weka model algorithm implement datum preprocesse base machine learn version tool datum java base version weka weka include implement java collection datum preprocesse technique user interface weka support datum mining datum preprocesse regression visualization weka technique datum datum attribute attribute attribute support weka provide access database java database database weka provide access learning datum mining software collection database single weka algorithm include weka model user interface weka user interface access base interface predictive weka machine learn algorithm collection interface panel provide access panel database preprocesse datum algorithm datum attribute attribute panel regression algorithm weka predictive model model model visualization tree panel provide access attribute datum panel access technique weka algorithm algorithm learn attribute panel provide algorithm predictive attribute panel native regression tool weka regression tool native package include weka software native weka native package tool model tree package tool regression tool algorithm tree single model tree model tree model tree datum base single provide single support regression datum extension package version package extension package include weka version extension package extension weka software weka extension university waikato new zealand version weka weka java include model algorithm weka datum mining weka datum mining predictive tool weka machine learn weka support weka analysis machine learn datum mining software implement java analysis mining datum university waikato new zealand datum mining software base learning technique datum mining machine learn visualization base learn machine learning implement java weka learn machine learn analysis software university waikato new zealand\n",
      "=====Social_network_analysis_software\n",
      "=======\n",
      "social network analysis software software software analysis social network feature network network network node network feature level individual node tie network node level feature network phenomenon individual software feature network datum individual node level datum network analysis software software network feature feature social network network datum analysis network datum network analysis tool network software analysis network phenomenon tie predict individual level individual level predict network tie network phenomenon predict network phenomenon predict tie social network analysis tool tool social network social network analysis social network network analysis network social network analysis software social network analysis social network analysis tool\n",
      "=====Machine_learning_algorithms\n",
      "=======\n",
      "machine learn study algorithm statistical model system use perform specific task pattern inference instead subset artificial intelligence machine learn algorithm build mathematical model base sample datum know training data order prediction decision program perform task machine learn algorithm variety application email vision algorithm perform task machine learn related computational statistic focus make prediction study mathematical optimization method theory application field machine learning datum mining field study machine learning focus datum analysis unsupervised learning application problem machine learn predictive machine learning provide definition algorithm study machine learning field program learn experience class task performance measure performance task measure improve experience definition task machine learn definition define field term compute intelligence machine machine characteristic machine machine learn task machine learn task category supervise learn algorithm build mathematical model set data contain input desire output example task image contain object training datum supervise learn algorithm include image object input image label output contain object input semi supervise learn algorithm mathematical model training datum sample input label classification algorithm regression algorithm type supervise learn classification algorithm output set value classification algorithm email input email output email algorithm email output prediction represent value true regression algorithm continuous output mean value example continuous value object unsupervised learn algorithm build mathematical model set data contain input desire output label unsupervised learn algorithm structure datum like group datum unsupervised learn discover pattern data group input category feature learn process feature input set datum learn algorithm desire output train label set input base input training label human user reinforcement learn algorithm give form positive negative reinforcement environment learn game human algorithm machine learning include model program give set language similar machine learn algorithm probability density function density problem learn algorithm learn inductive bias base experience learn algorithm generate sequence learn experience know new self human use learn relationship field field game artificial intelligence term machine learn book machine learn research book learning machine machine learning pattern classification machine learn related pattern recognition book report give neural network learn machine learning artificial intelligence ai researcher machine learn datum attempt approach problem method term neural network model linear model statistic probabilistic employ medical increase knowledge base approach ai machine learn probabilistic system theoretical problem datum representation system come ai statistic knowledge base learning ai lead inductive logic program statistical research field ai pattern recognition information neural network research ai time ai field researcher include come machine learning separate field field goal artificial intelligence problem nature focus approach ai method model statistic probability theory increase information ability datum mining machine learn datum mining employ method machine learn focus prediction base know learn training datum datum mining focus discovery previously unknown datum analysis knowledge discovery database datum mining use machine learning method different goal machine learning employ datum mining method unsupervised learn improve accuracy research separate conference separate journal come machine learning performance usually ability know knowledge knowledge discovery datum mining task discovery previously unknown knowledge know knowledge unsupervised method supervised method task supervised method training datum optimization machine learn optimization learning problem loss function training set example loss function prediction model train problem instance example classification label instance model train predict label set example field goal generalization optimization algorithm loss training set machine learning loss sample statistic machine learning statistic related field term method goal statistic inference sample machine learning predictive pattern machine learn theoretical tool statistic term datum field statistical datum model algorithmic model algorithmic model mean machine learn algorithm like method machine learn lead field statistical learning theory experience generalization context ability learn machine perform new example task experience learn datum set training example come unknown probability consider space build model space prediction new computational analysis machine learn algorithm performance theoretical know computational learning theory training set learning theory usually performance algorithm instead probabilistic performance common bias way generalization good performance context generalization complexity hypothesis complexity function datum hypothesis function model fit data complexity model increase training hypothesis model generalization addition performance learn study time complexity learn computational learn theory consider polynomial time time complexity result positive result class function learn polynomial time negative result class learn polynomial time approach type learn algorithm type machine learn algorithm approach type datum input output type task problem solve supervise learn supervise learn algorithm build mathematical model set data contain input desire output datum know training data set training example training example input desire output know signal mathematical model training example represent vector call feature vector training datum represent matrix optimization function supervise learn algorithm learn function predict output associate new input function allow algorithm output input training data algorithm improve accuracy output prediction time learn perform task supervised learn algorithm include classification regression classification algorithm output set value regression algorithm output value similarity learning area supervise machine learn related regression classification goal learn example similarity function measure similar related object application recommendation system semi supervised learn algorithm training example training label improve model supervised learn training label label result large training set unsupervised learn unsupervised learn algorithm set datum contain input structure datum like group datum algorithm learn test datum label instead unsupervised learn algorithm identify datum base new data application unsupervised learning field density statistic unsupervised learning datum feature cluster analysis set observation subset call cluster observation cluster similar observation different cluster different technique different structure datum define similarity example similarity cluster cluster method base density semi supervise learning semi supervised learning unsupervised learning label training datum supervise learn label training datum machine learning researcher datum label data learn accuracy reinforcement learn reinforcement learning area machine learn software action environment field study game theory theory research information theory base optimization system intelligence statistic genetic algorithm machine learning environment typically represent decision process reinforcement learn algorithm use programming technique reinforcement learn algorithm knowledge mathematical model model reinforcement learn algorithm learn game human self learn self learn machine learn neural network self learn caa learn caa self learn algorithm compute decision action emotion consequence situation emotion self learn algorithm matrix machine learn situation perform action receive consequence situation compute emotion consequence situation input situation output action separate reinforcement input input environment value reinforcement emotion consequence situation caa exist environment environment genetic environment receive emotion situation environment receive vector genetic environment caa learn goal environment contain situation feature learn learn algorithm discover representation input provide training example include component analysis cluster analysis feature learn algorithm call representation learn algorithm attempt information input way make perform classification prediction technique allow input come unknown datum generate feature allow machine learn feature use perform specific task feature learning supervise unsupervised supervised feature learning feature learn label input datum example include artificial neural network supervise dictionary learning unsupervised feature learning feature learn input datum example include dictionary learning component analysis matrix form cluster learn algorithm attempt learn representation dimensional sparse algorithm attempt learn representation sparse mean mathematical model learn algorithm learn dimensional representation representation datum high dimensional vector learn algorithm discover representation feature high feature define term generate feature machine learn representation datum feature learn machine learn task classification input process real datum image datum attempt define specific feature discover feature representation algorithm sparse dictionary learning sparse dictionary learning feature learn method training example represent linear function sparse matrix method solve method sparse dictionary learning algorithm sparse dictionary learning apply classification problem class previously training example dictionary class build new training example associate class represent dictionary sparse dictionary learning apply image image represent image dictionary anomaly detection datum mining anomaly detection know detection item observation datum typically item represent medical problem anomaly context network detection object object pattern common statistical definition object detection method unsupervised algorithm fail datum instead cluster analysis algorithm cluster form pattern category anomaly detection technique exist unsupervised anomaly detection technique anomaly test datum set instance datum set normal instance fit datum set supervised anomaly detection technique datum set label normal train statistical classification problem nature detection semi supervise anomaly detection technique model represent normal give normal training datum set test test instance generate model association rule association rule learning rule base machine learning method relationship variable large database identify rule discover database measure rule base machine learn term machine learning method learn rule apply knowledge define characteristic rule base machine learn algorithm set rule represent knowledge machine learn algorithm identify model apply instance order prediction rule base machine learning approach include learn system association rule learn artificial system base rule association rule discover large datum system example rule datum information decision addition analysis association rule employ application area include mining detection continuous sequence mining association rule learn typically consider order item learn system rule base machine learn algorithm discovery component typically genetic algorithm learn component perform supervised learn reinforcement learn unsupervised learning identify set context rule apply knowledge order prediction inductive logic programming approach rule learn logic programming representation input example knowledge hypothesis give know knowledge set example represent database logic program positive negative example inductive programming related field consider programming language represent hypothesis logic program program inductive logic programming language theoretical inductive machine learn build model inference program logic program positive negative example term inductive theory mathematical order set model perform machine learning model train training datum process datum prediction type model research machine learning system artificial neural network artificial neural network system system neural network brain system learn perform task consider example program task specific rule model base call artificial neuron model neuron brain connection like brain information signal artificial neuron artificial neuron receive signal process signal artificial neuron common signal connection artificial neuron real output artificial neuron compute non linear function input connection artificial neuron call artificial neuron typically learn increase signal connection artificial neuron signal signal typically artificial neuron layer different layer perform different input signal layer input layer layer output layer layer time goal approach solve problem way human brain time perform specific task lead artificial neural network variety task include vision recognition machine network game medical learning layer artificial neural network approach model way human brain process vision application learn vision recognition decision tree decision tree learn use decision tree predictive model observation item represent item value represent predictive approach statistic datum mining machine learning tree model variable set value call classification tree tree structure represent class label represent feature lead class label decision tree variable continuous value typically real call regression tree decision analysis decision tree represent decision decision make datum mining decision tree datum result classification tree input decision make vector machine vector machine svm vector network set related supervised learning method classification regression give set training example category svm training algorithm build model predict new example category svm training algorithm non probabilistic linear method exist use svm probabilistic classification set addition perform linear classification perform non linear classification call input high dimensional feature space regression analysis regression analysis large variety statistical method relationship input variable associate feature common form linear regression good fit give datum mathematical method high bias regression non linear problem model include polynomial regression fit regression statistical classification regression non input variable high dimensional space bayesian network bayesian network network model probabilistic model represent set variable example bayesian network represent probabilistic relationship give network compute probability algorithm exist perform inference learn bayesian network model sequence variable like signal sequence call bayesian network generalization bayesian network represent solve decision problem call genetic algorithm genetic algorithm algorithm technique process method generate new good give problem machine learn genetic algorithm machine learning technique improve performance genetic algorithm training model usually machine learning model data order perform usually train machine learning model large sample datum training set datum training set image datum user training machine learning model learn learn new approach training machine learning model training process allow user datum increase training process example use machine learn train prediction model user google application application machine learn include program predict user improve accuracy exist recommendation algorithm researcher research theory build model good pattern recommendation recommendation journal research use machine learning predict predict medical machine learn medical software report machine learn algorithm apply field study previously nature research book machine learn machine learn field machine learning program fail result datum datum datum bias problem task algorithm tool people problem self fail attempt use machine learn fail time bias machine learning approach different datum bias machine learning train predict new group represent training datum train data machine learn bias language model learn datum contain human like bias machine learning system bias people google people google training datum real similar non people system test learn language use machine learn bias machine learning use human good artificial intelligence include artificial ai people people people tool model classification machine learning model accuracy technique like method datum training test set training set test set performance training model test set method datum subset perform consider subset subset training model addition method sample instance model accuracy addition accuracy report mean true positive rate true negative rate report positive rate negative rate rate fail characteristic method model ability previously rate provide information characteristic associate area machine learning system train bias bias use algorithmic bias example data lead machine learn bias similarity datum algorithmic rule machine learn human language contain bias machine train language learn bias form bias health care health care system generate machine true improve health care increase example algorithm provide test algorithm machine learn health care provide tool bias previously bias software software contain variety machine learn algorithm include software software software journal journal machine learn research machine learn nature machine intelligence neural conference conference neural information system conference machine learn machine learn database machine learn software machine learn google machine learning use\n",
      "=====Genetic_algorithms\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research genetic algorithm ga metaheuristic inspire process natural selection evolutionary algorithm genetic algorithm generate high quality solution optimization search problem inspire operator mutation crossover selection john holland introduce genetic algorithm base theory evolution ga optimization problem genetic algorithm population candidate solution call individual optimization problem evolve well solution candidate solution set chromosome mutate solution represent string possible evolution start population randomly generate individual process population iteration call generation generation fitness individual population evaluate fitness value function optimization problem solve fit individual select population individual recombine randomly mutate form new generation new generation candidate solution iteration algorithm algorithm number generation produce fitness level reach population genetic algorithm require genetic representation solution domain fitness function evaluate solution domain representation candidate solution bit type structure way make genetic representation fix size simple crossover variable length representation crossover implementation complex case tree like representation genetic programming form representation evolutionary programming chromosome tree gene expression programming genetic representation fitness function define ga population solution application mutation crossover selection operator population size depend problem typically possible solution population generate randomly allow possible solution search space solution optimal solution selection generation population select new generation individual solution select fitness base process solution measure fitness function typically select certain selection method rate fitness solution select good solution method rate random sample population process time fitness function define genetic representation measure quality represent solution fitness function problem instance knapsack problem value object knapsack fix capacity representation solution bit bit represent different object value bit represent object knapsack representation valid size object capacity knapsack fitness solution value object knapsack representation valid problem define fitness expression case simulation fitness function value computational encode interactive genetic algorithm genetic operator step generate generation population solution select combination genetic operator crossover call recombination mutation new solution produce parent solution select pool select produce child solution method crossover mutation new solution typically parent new parent select new child process new population solution size generate method base use parent inspire research parent generate high quality chromosome process result generation population chromosome different generation fitness increase population organism generation select small fit solution fit solution genetic diversity genetic pool parent genetic diversity generation child crossover mutation mutation base search crossover mutation know genetic operator possible use operator genetic algorithm parameter mutation probability crossover probability population size problem work small mutation rate lead genetic recombination rate high lead convergence genetic algorithm mutation rate high lead good solution selection employ heuristic operator heuristic employ heuristic crossover candidate solution similar population diversity prevent convergence optimal solution process reach solution fix number generation reach time reach solution fitness reach reach iteration produce well result combination build block hypothesis genetic algorithm simple implement difficult understand particular difficult understand algorithm generate solution high fitness apply problem build block hypothesis heuristic perform adaptation recombine building block low order low length schemata fitness hypothesis genetic algorithm perform adaptation implement heuristic heuristic low order fit schemata sample recombine cross form string high fitness way work particular schemata building block complexity problem instead build high performance string combination better well string good solution fit schemata low length low order genetic algorithm building block child simple block genetic algorithm optimal performance low order high performance schemata building block building block hypothesis evaluate estimation distribution algorithm example propose attempt provide environment hypothesis good result problem building block hypothesis gas efficiency work attempt understand estimation distribution algorithm use genetic algorithm optimization algorithm fitness function evaluation complex problem artificial evolutionary algorithm optimal solution complex high problem require fitness function evaluation real problem optimization problem function evaluation require simulation optimization method type problem case evaluation use fitness efficient model approach use ga solve complex real problem genetic algorithm complexity number element mutation increase search space size make difficult use technique problem design order problem evolutionary search representation possible typically evolutionary algorithm encode design instead building instead instead design problem complexity evolve represent good solution mutation particularly fitness require well solution solution result problem problem gas local point global optimum problem mean know term fitness term fitness depend fitness landscape certain problem provide global optimum function local problem different fitness function increase rate mutation selection technique maintain population solution theorem general solution problem technique maintain diversity group individual add representation group generation similar individual maintain population depend landscape problem possible technique population randomly generate individual population similar diversity genetic algorithm genetic programming cross population new solution evolution strategy evolutionary programming diversity mutation datum set difficult early solution valid method propose increase genetic diversity prevent early convergence increase probability mutation solution quality call introduce new randomly generate element gene pool call random evolution strategy evolutionary programming implement call strategy parent maintain new parent select problem gas solve problem fitness measure measure like problem way solution hill climb case random search solution ga allow different result provide fitness measure optimization problem problem instance optimization algorithm efficient genetic algorithm term convergence algorithm include evolution strategy evolutionary programming simulate anneal gaussian adaptation hill climb swarm intelligence optimization particle swarm optimization method base integer programming genetic algorithm problem know problem better approach variant chromosome representation simple algorithm represent chromosome bit typically parameter represent integer possible use point representation point representation natural evolution strategy evolutionary programming real value genetic algorithm represent building block theory propose john holland theory base result algorithm perform crossover mutation bit level variant chromosome list number node list object datum structure crossover mutation perform datum element datum type variation operator design different datum type work better different problem domain bit string representation integer employ way small change integer mutation crossover prevent convergence call mutation crossover order change chromosome well solution approach real value number instead string represent chromosome result theory general small well performance good result obtain real value chromosome set real value population chromosome form selection recombination low point representation genetic algorithm problem domain obtain complex encode solution pool type encode gene chromosome particular approach allow solve optimization problem require domain problem parameter instance problem structure parameter implement different particular form require crossover recombine chromosome model simulation complex adaptive evolution process variant general process new population allow good organism generation strategy know selection solution quality obtain ga generation parallel implementation parallel implementation genetic algorithm parallel genetic algorithm population node individual node parallel genetic algorithm individual node individual selection variant like genetic algorithm optimization problem introduce time fitness function adaptive gas genetic algorithm adaptive parameter adaptive genetic algorithm variant genetic algorithm probability crossover pc mutation pm solution convergence genetic algorithm obtain instead fix value pc pm population information generation pc pm order maintain population diversity convergence capacity adaptive genetic algorithm pc pm depend fitness value solution base adaptive genetic algorithm use optimization state population pc pm depend optimization state ga optimization method ga good good global solution mutation optimum technique simple hill climb efficient optimum ga hill climb efficiency ga hill mean genetic variation different mean natural case instance provide step order cross number step add number step like add landscape efficiency process increase order operator step order order efficiency variation population evolve individual know gene pool recombination number variation attempt performance gas problem high fitness fitness solution variable algorithm learn build block hypothesis recombination example approach include problem domain problem particularly solution genetic algorithm include problem base gas gas apply genetic algorithm apply approach solve global optimization problem general genetic algorithm problem domain complex fitness landscape mutation combination crossover design population local traditional hill climb algorithm crossover operator change population mutation provide genetic algorithm process example problem solve genetic algorithm include design design space method optimal design complex algorithm design genetic algorithm model application term genetic operator like mutation crossover bit string add level complexity problem genetic algorithm time problem evolution require problem genetic algorithm way computational result genetic algorithm simulate anneal heuristic search propose learn machine parallel evolution simulation evolution start early work new start simulation artificial selection organism simulation evolution early method simulation include element genetic algorithm population solution optimization problem recombination mutation selection research include element genetic algorithm early include early work evolution simple artificial evolution optimization method result work early group solve complex problem evolution strategy approach evolutionary programming technique propose generate artificial intelligence evolutionary programming state machine environment variation selection genetic algorithm particular work john holland early particularly adaptation natural artificial work holland holland introduce quality generation know holland theorem research gas genetic algorithm general start genetic algorithm base design process ga new time john interactive genetic algorithm build optimization heuristic algorithm simulate anneal particle swarm optimization genetic algorithm search search search technique parent field genetic algorithm sub field evolutionary algorithm evolutionary metaheuristic optimization optimization field evolutionary algorithm evolutionary algorithm sub field evolutionary evolution strategy evolve individual mean mutation recombination algorithm design particularly solve problem real value domain use self adaptation parameter search self adaptation lead adaptation evolution strategy evolutionary programming population solution mutation selection representation use self adaptation parameter include variation information parent estimation distribution algorithm traditional operator model operator model learn population employ machine technique represent model new solution sample generate crossover gene expression programming use population program complex program encode simple chromosome fix length expression tree expression tree program evolve chromosome mutation recombination similar ga chromosome genetic result valid program genetic programming technique john program function parameter genetic programming use tree base datum structure represent program adaptation instead list structure genetic algorithm group genetic algorithm evolution ga individual item like gas group item ga evolution propose solve complex problem problem set item group item optimal way better make group item gene problem include measure gas perform make gene group chromosome general variable length genetic operator group item particular good technique interactive evolutionary algorithm evolutionary algorithm use evaluation apply domain design computational fitness function example evolve design form fit swarm intelligence swarm intelligence sub field evolutionary optimization use model traverse solution space estimation distribution algorithm particle swarm optimization computational method optimization use population base approach population swarm candidate solution particle search space particle swarm global like genetic algorithm method depend information population problem efficient gas problem variable evolutionary algorithm evolutionary sub field metaheuristic method algorithm evolutionary algorithm simulate research efficient solve optimization problem traditional evolutionary algorithm algorithm provide high capacity search solution space global optimal evolutionary algorithm evaluate quality value solution algorithm call genetic algorithm population base method solution local algorithm gene problem efficient traditional evolutionary algorithm algorithm inspire evolutionary particularly adaptation evolutionary organism environment environment individual fit environment population level apply complex problem datum algorithm population component genetic algorithm component call space search algorithm inspire gaussian adaptation natural adaptation na ga certain theorem valid gaussian distribution efficiency na information theory certain theorem efficiency efficiency define information work information na mean fitness fitness individual landscape certain local fitness landscape na good climb adaptation na information gaussian mean fitness metaheuristic method metaheuristic method method simulate anneal global optimization technique traverse search space random mutation individual solution mutation increase fitness mutation fitness base fitness low instead fitness ga algorithm start high rate mutation time tabu search similar simulate anneal traverse solution space mutation individual solution simulate anneal generate mutate solution tabu search generate mutate solution solution low generate order prevent solution space tabu list maintain solution solution element tabu list solution traverse solution space optimization gas work population candidate solution evolve solution make local component require representation select individual solution component quality measure fitness algorithm low quality component randomly select component ga select good solution attempt well solution method cross method generate candidate solution probability distribution parameter cross generate well sample iteration search optimization sub machine technique search heuristic solve complex optimization problem search self parameter search include machine learn particular learn learn metaheuristic list genetic algorithm application genetic algorithm particle metaheuristic learn base machine learn provide list genetic algorithm field tutorial genetic algorithm program evolve way natural selection solve complex problem understand ga john holland application interactive genetic algorithm tutorial learn ga work learn step step global convergence change population size crossover rate mutation rate selection add genetic algorithm tutorial state tutorial theory metaheuristic global optimization algorithm theory application genetic algorithm tutorial gas implementation genetic algorithm evolve solve\n",
      "=====Artificial_immune_systems\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence artificial immune system ais class base machine system inspire process immune algorithm model immune learn problem solve field artificial immune system ais abstract function immune computational system application system solve computational problem information ais field inspire compute computation machine learn field artificial intelligence artificial immune system ais system inspire immunology immune function model problem solve ais computational immunology immunology computational model immune model field ais provide field ais immune computation field compute ais immune network ais field negative selection ais dasgupta negative selection algorithm work immune network model work nicosia work clonal selection artificial immune system dasgupta new ais theory algorithm inspire immune new new abstract ais algorithm provide ais ais model ais process immune model process immune algorithm problem dasgupta computation work base application inspire theory function immune clonal selection algorithm class algorithm inspire clonal selection theory algorithm theory selection inspire antibody inspire cell inspire clonal selection algorithm pattern domain algorithm negative selection algorithm inspire negative selection process cell cell negative selection cell cell class algorithm pattern problem domain problem model domain algorithm pattern pattern model pattern immune network algorithm algorithm inspire network theory immune antibody antibody antibody class algorithm network antibody antibody cell algorithm base problem immune network algorithm domain artificial network cell algorithm cell algorithm dca immune inspire algorithm algorithm base abstract model cell dca abstract process model function network cell cell dca information inspire compute computational immunology computational intelligence computation computation intelligence learn base machine immune machine learn vol pp problem solve immune network problem solve dasgupta artificial immune system application nicosia problem vol pp artificial immune system theory application compute dca artificial immune system computation vol pp nicosia immune algorithm model computation vol pp nicosia nicosia artificial immune system information ais algorithm network artificial immune system provide information ais network provide ais ais immune system new ais artificial immune system dasgupta work ais\n",
      "=====Gene_expression_programming\n",
      "=======\n",
      "program gene expression programming gep evolutionary algorithm create program model program complex tree structure learn change size shape like like program gep encode simple linear chromosome fix length gep genotype phenotype simple genome genetic complex phenotype explore environment evolutionary algorithm use population individual select individual fitness genetic genetic operator use artificial system solve problem introduction evolution evolutionary algorithm gain good evolutionary algorithm introduction genetic algorithm gene expression programming evolutionary algorithm genetic algorithm genetic programming genetic algorithm linear chromosome fix length genetic programming parse tree size shape gene expression programming linear chromosome work genotype parse tree phenotype create genotype phenotype genotype phenotype multigenic encode multiple parse tree chromosome mean program create gep compose multiple parse tree parse tree result gene expression gep call expression tree encode genotype genome gene expression programming consist linear string chromosome fix length compose gene equal size gene fix length code expression tree different size shape example chromosome gene size string position start gene represent function represent variable constant problem expression tree phenotype show gene gene expression programming size fix length string code expression tree different size mean size gene gene allow evolution example mathematical expression displaystyle represent expression tree represent root function kind expression tree consist expression gep gene gene linear string encode complex structure example linear string correspond expression tree leave linear string call expression expression expression tree simple example follow expression compose different terminal variable different function argument function argument expression give expression gene expression gene expression programming correspond gene express mean sequence gene express true gene terminal expression encode gep gene correspond program expression gene gene expression programming compose different domain head tail different function head encode function variable choose solve problem hand tail encode variable terminal program error gep gene length tail give max displaystyle max head length nmax maximum arity example gene create set function set terminal nmax choose head length give gene length randomly string example gene encode expression tree case use element gene fix length gene code expression tree different size shape compose node element gene terminal compose node element gene element head function maximum arity implement kind genetic modification mutation inversion insertion recombination guarantee result encode correct error program multigenic chromosome chromosome gene expression programming usually compose gene equal length gene code sub expression tree sub et sub program sub et different way form complex program show example program compose sub program sub et link addition function kind link function choose example complex include classification function probability function usually choose problem evolve cellular gene expression programming cell code gene expression programming homeotic gene different sub main program expression gene result different main program cell determine gene express cell sub cell homeotic gene determine sub et call main program cell kind connection homeotic gene cellular homeotic gene kind normal gene contain head domain tail domain head contain link function special kind terminal terminal represent normal gene expression normal gene result usual different sub et cellular call function tail contain terminal algorithm example chromosome normal gene homeotic gene encode main program different function time link way example cellular allow evolution link function code implement multiple main program multicellular system multicellular system compose homeotic gene homeotic gene different sub expression tree create multiple cell main program example program show create cellular cell normal gene multicellular system multiple like multigenic system problem output problem multiple output head tail domain gep gene normal homeotic basic gep algorithm gene expression programming explore complex head tail structure complex structure consist unit gene basic head tail domain extra domain extra domain usually encode random numerical constant algorithm order good solution instance numerical constant weight function problem gep rnc algorithm weight threshold neural network gep nn algorithm numerical constant need design decision tree gep dt algorithm weight need induction random numerical constant value basic gene expression algorithm step basic gene expression algorithm select function set select terminal set dataset fitness create chromosome initial population randomly program population express chromosome program evaluate fitness select program select program form population chromosome genetic operator step step need algorithm step step initial population create randomly element function terminal set population program like evolutionary algorithm gene expression programming work population individual case program kind initial population create start population selection genetic modification initial population genotype phenotype gene expression programming create simple linear chromosome individual program code expression result correct program fitness function selection environment fitness function selection environment call training dataset learn fitness fitness program depend cost function measure training datum choose evaluate fitness selection environment training datum selection environment consist set training record call fitness case fitness case set problem form call training dataset training datum evolution good solution good training set problem hand algorithm addition dataset good choose record training good datum leave record fitness function different kind problem base kind prediction problem involve numeric prediction problem involve nominal prediction problem involve binary boolean prediction type problem regression classification logistic regression special case classification like probability boolean fitness function regression regression variable numeric usually output regression model evaluate fitness evolve model output model value training datum basic fitness function evaluate model base error model output actual value function include mean squared error root mean squared error mean error squared error root squared error error measure solution work problem evolution determine prediction instance actual value hit prediction choose population model evolve base number hit program usually efficient fitness solution usually involve combine measure kind smooth function error measure fitness function base correlation smooth regression problem function work good combine measure measure correlation range value model output combine function work range target value form efficient fitness function model good correlation good actual value fitness function classification logistic regression design fitness function classification logistic regression different classification model hit record hit fitness function simple work simple problem complex problem dataset give result way type hit base fitness function consist correct classification binary classification correct classification mean case represent mean case represent classification type call true true type classification represent call actual value model target model usually confusion matrix assign different weight type classification create smooth efficient fitness function fitness function base confusion matrix include measure correlation cost gain matrix combine cost gain assign different type classification function base confusion matrix solve problem dimension classification model explore solution result new dimension involve explore structure model include domain range model output explore dimension classification model combine model confusion matrix design fitness function allow smooth solution instance combine measure base confusion matrix mean squared error evaluate model output actual value combine measure evaluate model output target cost gain matrix correlation fitness function explore model include measure new dimension classification model assign probability model output logistic regression use probability evaluate mean squared error measure probability actual value combine confusion matrix create efficient fitness function logistic regression example fitness function base probability include maximum fitness function boolean problem model structure classification logistic regression explore domain range function true fitness function boolean base hit confusion matrix selection roulette wheel selection selection scheme evolutionary involve fitness program roulette wheel fitness roulette time program population order population size constant roulette wheel selection program select fitness mean time good combine roulette wheel selection good program generation guarantee good good generation program simple selection scheme reproduction modification reproduction program involve selection reproduction genome genome modification reproduction evolution replication selection selection operator select program replication operator copy depend selection scheme number copy program program copy copy addition selection usually set population size constant generation replication complex time replication replication string artificial evolutionary system copy string genome generation generation replication select program artificial evolutionary system evolution need implement usual copy error genetic create genetic operator mutation recombination transposition inversion mutation gene expression programming mutation genetic operator change genome change element change time create gene expression programming mutation mean gene domain domain symbol replace example head gene function replace terminal function number argument new function terminal replace function terminal recombination recombination usually involve parent chromosome create new chromosome combine different parent chromosome parent chromosome exchange position chromosome new chromosome create recombination encode correct program different kind easily implement change number parent involve choose number way choose exchange example randomly example gene recombination special case recombination exchange gene gene position chromosome exchange gene choose random position chromosome transposition transposition involve introduction insertion sequence chromosome gene expression programming insertion sequence chromosome head gene method guarantee insertion sequence tail result error program transposition work chromosome length gene structure gene expression programming transposition implement different method create insertion follow head sequence target implement method implement chromosome chromosome gene inversion inversion operator consist sequence chromosome gene expression programming easily implement gene domain case correct gene domain sequence range element domain choose random domain genetic operator genetic operator gene expression program different gene gene domain example genetic operator recombination recombination gene recombination recombination gene transposition root transposition domain specific mutation domain specific inversion domain specific transposition easily implement gep rnc algorithm numerical constant element mathematical model allow model design evolutionary algorithm gene expression programming solve problem use extra gene domain dc handle random numerical constant rnc combine domain special terminal rnc create dc come tail length equal size tail compose symbol represent rnc example show simple chromosome compose gene head size dc position terminal represent rnc kind chromosome express show give expression tree replace leave symbol simplicity represent numeral dc give value correspond symbol array simplicity number represent numeral order array instance follow element array expression tree give structure handle random numerical constant different gep system gep neural network gep decision tree like basic gene expression algorithm gep rnc algorithm multigenic chromosome usual express gene link kind genetic operator gep rnc genetic operator basic gep algorithm implement new chromosome hand basic operator mutation inversion transposition recombination gep rnc algorithm special dc specific operator mutation inversion transposition efficient rnc individual program addition special mutation operator allow introduction set rnc initial set rnc randomly create mean gene initial population number numerical constant choose range randomly mutation genetic operator neural network artificial neural network nn consist simple unit neuron connection unit usually weight value weight weight mean learn neural network learn algorithm usually neural network different class unit input unit unit output unit activation input unit input unit unit output unit activation come unit unit weight link activation unit result unit threshold basic neural network unit connection unit weight threshold order artificial neural network encode linear chromosome express way gep neural network gep nn gep net network encode usual structure head tail domain head contain special function neuron output unit gep unit call unit terminal represent input unit tail usual contain terminal input unit head tail neural network gene contain domain dw dt encode weight threshold neural network dw come tail length dw depend head size maximum arity nmax evaluate max displaystyle max dt come dw length dt equal domain compose symbol represent weight threshold neural network nn gene weight threshold create guarantee usual genetic operator mutation transposition inversion recombination addition special operator allow constant genetic set weight example show neural network input unit unit output unit connection correspond weight represent numeral simplicity threshold equal neural network neural network represent tree case correspond represent input represent function function argument activation order determine output output simple case depend threshold unit activation equal threshold output nn tree follow structure position dw encode weight value weight array expression example show neural net gene problem head size dw size expression result follow neural network set weight give solution function simple boolean function binary input binary output gep net algorithm handle kind function neuron linear neuron neuron neuron logistic neuron neuron neuron kind step neuron gep net algorithm use neuron evolution work good solve problem hand gep net boolean problem logistic regression classification regression case gep net implement multigenic system cellular system multicellular classification problem gep net multigenic system multicellular system decision tree decision tree dt classification model node decision tree type node root node node terminal node root node node represent different attribute variable dataset node class label different tree decision tree induction algorithm involve select attribute root node kind decision node tree decision tree create gene expression programming decision tree algorithm kind input different type dt algorithm induce decision tree nominal attribute induce decision tree numeric nominal attribute decision tree induction gene expression programming gep algorithm decision tree induction decision tree algorithm nominal attribute rnc random numerical constant handle nominal numeric attribute decision tree induce gene expression programming attribute function node basic gene expression algorithm class label terminal mean attribute node specific arity number branch determine tree class label like terminal mean class classification terminal set terminal represent different class encode decision tree linear genome encode mathematical expression decision tree induction gene head tail head contain attribute terminal tail contain terminal decision tree design gep program size tail head size number branch attribute branch nmax max displaystyle max example decision tree encode represent attribute attribute represent class label node datum type number branch attribute encode decision tree induction gene expression programming start usual initial population randomly create chromosome chromosome express decision tree fitness evaluate training dataset fitness select modification genetic operator example mutation inversion transposition recombination decision tree nominal numeric attribute easily induce gene expression programming random numerical constant include extra domain encode random numerical constant datum branch node example gene head size dc start position encode decision tree show node head type numeric attribute nominal attribute terminal random numerical constant simplicity example represent numeral random numerical constant encode dc domain expression follow simple scheme leave element dc assign element decision tree follow array decision tree result represent decision tree gep genetic programming method genexprotool genexprotool genexprotool model include logistic regression classification regression time prediction genexprotool implement basic gene expression algorithm gep rnc algorithm model genexprotool gep gep java create gep gene expression programming java implement different gep algorithm include evolve decision tree nominal numeric attribute function gep code gene expression programming create create simple gene expression programming use implement multigenic chromosome genetic operator mutation transposition code java gep create java code use gep gene expression programming mathematical model artificial gene expression programming mathematical model artificial artificial decision tree evolutionary algorithm genetic algorithm genetic programming genexprotool learn neural network link gep gene expression programming genexprotool gep\n",
      "=====Bayesian_networks\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayesian network baye network network network baye model probabilistic direct acyclic graphical model probabilistic graphical model model represent set variable conditional dependency direct acyclic graph dag bayesian network predict likelihood possible cause example bayesian network represent probabilistic relationship give network compute probability algorithm perform inference learn bayesian network bayesian network model variable call bayesian network bayesian network represent problem call graphical model bayesian network direct acyclic graphs dag node represent variable bayesian quantity variable parameter edge represent conditional dependency node path node represent variable independent node probability function set value node parent variable give probability probability distribution variable node example displaystyle parent node represent displaystyle variable probability function represent table displaystyle displaystyle possible parent graphs markov network example cause grass wet sprinkler rain rain direct effect use sprinkler rain sprinkler model bayesian network variable possible value true false joint probability function pr pr pr pr displaystyle pr pr mid pr mid pr grass wet true false sprinkler turn true false rain true false model answer cause give effect call probability probability rain give grass wet conditional probability sum variable pr pr pr pr pr displaystyle pr mid frac pr pr frac sum pr sum pr joint probability function pr displaystyle pr conditional probability conditional probability table state term sum example pr pr pr pr displaystyle align pr pr mid pr mid pr time time align result variable value pr displaystyle pr mid frac frac answer probability rain give wet grass answer intervention joint distribution function pr pr displaystyle pr mid text pr mid pr displaystyle pr mid intervention distribution value true probability rain action pr pr displaystyle pr mid text pr predict turn sprinkler pr pr pr displaystyle pr mid text pr pr mid term pr displaystyle pr mid action grass rain give unobserved variable problem effect action displaystyle text predict door state set node observed separate door path pr pr pr displaystyle pr mid text frac pr pr mid door path arrow set door call example set predict effect separate door path set separate path effect turn sprinkler grass predict case identify datum causal common cause causal identify bayesian network unobserved variable use term quantity datum bayesian network probability table dependency joint distribution example conditional probability value variable table require space displaystyle value variable local distribution depend parent variable bayesian network displaystyle cdot value bayesian network set direct dependency local distribution complete joint distribution inference learn bayesian network perform inference unobserved variable bayesian network complete model variable relationship answer probabilistic example network state variable variable variable observed process compute posterior distribution variable give call probabilistic inference posterior give application value variable expect function probability error bayesian network baye complex problem common exact inference method variable non observed non variable sum product variable time search space time variable space method complexity network common approximate inference algorithm sample method parameter learning specify bayesian network represent joint probability distribution specify node probability distribution conditional parent distribution conditional parent form common work distribution constraint distribution use maximum distribution give constraint bayesian network conditional distribution state specify maximize process conditional distribution include parameter estimate maximum likelihood approach direct likelihood posterior probability complex give unobserved variable approach problem algorithm compute expect value unobserved variable conditional observed datum maximize complete likelihood posterior compute expect value condition process maximum likelihood maximum posterior value parameter bayesian approach parameter unobserved variable compute posterior distribution conditional observed datum parameter approach model set approach tractable structure learn case bayesian network specify perform inference application define network complex case network structure parameter local distribution learn datum learn graph structure bayesian network learn algorithm develop possible node dag represent dependency displaystyle displaystyle independent give displaystyle identify displaystyle displaystyle independent graphs arrow arrow displaystyle displaystyle common parent condition parent algorithm develop graph arrow conditional independence method learning use search require function search common function posterior probability structure give datum time search structure maximize number variable local search structure search algorithm markov local variable structure maximize parent set node search method exact learning problem problem constraint form method problem variable problem variable approach sample structure respect ordering work search space possible ordering space network structure ordering sample method prove number variable method model form possible structure variable learn bayesian network exact tractable inference case inference complexity time property graph learning process possible use learn introduction give datum displaystyle displaystyle theta bayesian prior probability prior displaystyle theta likelihood displaystyle mid theta compute posterior probability displaystyle theta mid mid theta theta prior displaystyle theta depend turn parameter displaystyle varphi likelihood prior displaystyle theta likelihood displaystyle theta mid varphi prior displaystyle varphi parameter displaystyle varphi require result posterior probability displaystyle theta varphi mid mid theta theta mid varphi varphi example hierarchical baye model process example parameter displaystyle varphi depend turn parameter displaystyle require prior process prior depend parameter example give quantity displaystyle x x error displaystyle displaystyle x sim theta estimate displaystyle theta approach estimate displaystyle theta maximum likelihood approach independent likelihood maximum likelihood estimate displaystyle theta x quantity example displaystyle theta distribution relationship independence complex model displaystyle x sim theta displaystyle theta sim varphi prior displaystyle varphi sim displaystyle sim displaystyle displaystyle identify model model parameter posterior distribution displaystyle theta maximum likelihood estimate common hierarchical baye model prior need prior hierarchical model variable variable displaystyle example prior prior work posterior distribution estimate expect definition definition bayesian network direct acyclic graph dag set variable definition bayesian network respect joint probability function respect product product function conditional parent variable pa displaystyle x x operatorname pa pa set parent edge set variable probability joint distribution conditional probability give ordering displaystyle operatorname x x x x operatorname x x mid x x x x definition parent displaystyle operatorname x x x x operatorname x x mid x x text x text parent x conditional independence variable non descendant give value parent variable local markov property bayesian network respect local markov property variable independent non descendant give parent variable pa displaystyle x perp perp x operatorname mid x operatorname pa text set descendant set non descendant term definition descendant parent displaystyle align operatorname x x mid x x text x text descendant x x x mid x x text x text parent x align set parent set non descendant graph acyclic develop bayesian network develop bayesian network dag local markov property respect causal dag conditional probability distribution variable give parent case case variable joint distribution product conditional distribution bayesian network respect markov blanket markov blanket node set node parent parent markov blanket node independent network joint distribution variable markov blanket node distribution node bayesian network respect node independent node network give markov blanket separation definition define separation node define separation trail define separation node term trail node trail edge path node separate set node condition need direct displaystyle cdot leftarrow leftarrow cdot displaystyle cdot rightarrow rightarrow cdot node displaystyle cdot leftarrow rightarrow cdot node displaystyle cdot rightarrow leftarrow cdot node descendant node separate trail separate separate bayesian network respect node displaystyle x perp perp x mid x set separate markov blanket set node separate node node causal network bayesian network represent causal relationship need case direct edge require bayesian network graphs displaystyle rightarrow rightarrow text leftarrow leftarrow conditional independence causal network bayesian network relationship causal causal network specify node cause give state action probability function network parent set cause value intervention datum prior intervention predict inference complexity approximation algorithm work application prove exact inference bayesian network result approximation algorithm develop tractable approximation probabilistic inference prove result complexity approximation probabilistic inference bayesian network prove tractable algorithm approximate probabilistic inference error prove tractable algorithm approximate probabilistic inference error probability time prove exact inference bayesian network complete number form approximate inference bayesian network term complexity result bayesian network learning application use application need constraint baye network conditional probability algorithm approximation algorithm approximate probabilistic inference bayesian network error approximation algorithm require conditional probability bayesian network number node network software software bayesian network include sampler use sample software include bayesian network software bayesian inference turn sampler represent bayesian network sampler include sampler term bayesian network baye condition causal probabilistic probabilistic property bayesian network introduction bayesian bayesian network introduction graphical model learn datum introduction bayesian network application bayesian probability bayesian method time bayesian network bayesian network learn bayesian network hierarchical baye model sample problem model sample hierarchical baye model sample perform learn variable\n",
      "=====Statistical_natural_language_processing\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language processing nlp information intelligence human natural language process large natural language datum natural language processing involve speech recognition natural language natural language natural language processing nlp generally work early intelligence call intelligence involve translation sentence english machine translation problem real research machine translation research machine translation statistical machine translation system develop natural language processing system develop natural language work world write information human human like base example write structure real world information example write include natural language processing system base set hand write rule natural language processing machine learn algorithm language processing increase grammar machine learn approach language processing early machine learn algorithm decision tree produce system rule hand write rule speech use model natural language processing research focus statistical model decision base real input datum language model speech recognition system example statistical model model generally give input especially input common real world datum produce result large multiple subtask early machine translation especially work research statistical model develop system textual produce result call translation language system system develop task system system result research learn datum research focus learn algorithm algorithm learn hand answer datum generally task difficult learning produce result give input datum datum include world result algorithm complexity representation learn machine learning natural language processing result result natural language task example language model parse include use word semantic word increase learn task question answer separate task speech nlp system base approach statistical natural language processing term machine translation learning base approach machine translation learn word language model statistical machine translation rule base statistical nlp early language processing system hand set rule write grammar rule call statistical natural language processing research machine learn machine learn call statistical automatically learn rule analysis large form set human typical real world example different machine learn algorithm natural language processing task algorithm input large set input datum early algorithm decision tree produce system rule system handwritten rule common research focus statistical model decision base real input model different possible answer produce result model include large system base machine learn algorithm hand produce rule learn machine learn automatically focus common write rule hand learning use statistical algorithm produce model input word structure input word word generally input handwritten rule generally system handwritten rule decision difficult system base automatically learn rule input datum system base handwritten rule increase complexity rule difficult task complexity system base rule system datum input machine learning system increase work generally increase complexity process task research task natural language processing task real world serve subtask aid large task natural language processing task give grammar grammar language task base form word segmentation separate word identify task complexity morphology structure word language english morphology especially morphology possible task model possible form word open open open open separate word language language approach possible possible word form speech give sentence determine speech word word especially common serve multiple speech example noun set noun different speech language language morphology english language entity parse determine parse tree analysis give sentence grammar natural language typical sentence multiple possible analysis typical sentence parse human type parse parse parse parse focus relationship word sentence mark like parse focus parse tree grammar grammar sentence sentence boundary give chunk text sentence boundary sentence boundary mark mark serve mark process word form close close close close close word segmentation separate chunk text separate word language like english word separate write language like mark word boundary language text segmentation task morphology word language process like word datum automatically term give semantic semantic word semantic learn semantic representation machine translation automatically text human language difficult problem problem term different type human grammar semantic real world name entity recognition give text determine text name people type aid recognize name entity language english information aid determine type name entity example sentence capitalize name entity word capitalize language language use name example capitalize noun name capitalize name serve natural language information semantic human language natural language chunk text representation structure natural language involve semantic multiple possible semantic natural language form natural language language natural language semantic close world open world semantic recognition give text determine text question answer give human language question determine answer typical question answer open question work question recognize textual give text determine relationship give chunk text identify relationship name entity analysis analysis information set determine especially segmentation recognition give chunk text separate identify word word problem give word word discourse produce chunk text text type research give sentence large chunk text determine word refer entity example task noun name refer task include identify call relationship involve refer example sentence door door refer relationship identify door refer door structure refer discourse analysis include task task identify discourse structure text discourse relationship sentence possible task recognize speech chunk text question question speech speech recognition give people speak determine textual representation speech text speech difficult problem term natural speech word speech segmentation subtask speech recognition speak language process term difficult process give word language speak people different speech recognition recognize input term textual speech segmentation give people speak separate word subtask speech recognition text speech give text produce speak representation text speech aid work intelligence word\n",
      "=====Language_modeling\n",
      "=======\n",
      "language model probability distribution sequence word give sequence probability displaystyle w ldot w sequence language model context word example speech different problem language model word sequence observe probability word previous word gram model unigram model unigram model bag word model likelihood different language generate text language model speech recognition speech recognition recognition information speech recognition word sequence language model model model language model information query likelihood model language model document document probability query document language model displaystyle displaystyle mid unigram language model model unigram unigram model probability different term context displaystyle t t t t t mid t t mid t t displaystyle text t t t t t t model probability word word probability document probability distribution vocabulary model unigram model document term term displaystyle text term text term probability generate query query term query term displaystyle text query text term query text term different document unigram model different probability word probability distribution different document generate probability query document query probability example unigram model document information context unigram language model smooth term generate likelihood model model likelihood model document smooth model gram gram model probability displaystyle w ldot w observe sentence displaystyle w ldot w approximate displaystyle w ldot w w mid w ldot w approx w mid w ldot w probability observe word context word approximate probability observe context word probability gram model count displaystyle w mid w ldot w mathrm count w ldot w w mathrm count w ldot w term language model gram model gram model probability count model problem gram see smooth probability word gram smooth count gram model model representation context word layer example language model probability sentence see red house approximate see red house see see red house red house displaystyle align text see red house approx text mid langle rangle text see mid text text mid text see text red mid text text house mid text red langle rangle mid text house align language model see red house see see red house red red house displaystyle align text see red house approx text mid langle rangle langle rangle text see mid langle rangle text mid text see text red mid text see text house mid text red langle rangle mid text red house align context gram sentence sentence probability sequence see sentence see red house language model word gram feature function displaystyle w w ldot w w ldot w w ldot w displaystyle w ldot w function displaystyle vector displaystyle w ldot w feature function feature function gram use displaystyle log model example language model neural network neural language model language model use representation word model use neural network language model language model train text word vocabulary sequence word vocabulary problem sequence probability neural network problem word neural net neural net approximate language function neural net neural net language model train probability distribution displaystyle w mathrm context network train probability distribution vocabulary give context neural net context previous word network displaystyle w w w feature vector previous word use word word feature probability displaystyle w w w w w gram model previous problem neural network context give word log probability log displaystyle log w w bag word language model bag word gram model word neural net language model probability use representation network layer representation word word vector word layer layer representation gram model model word example model function word vector representation displaystyle mathrm mathrm mathrm approx mathrm language model probability give word text bag model word information sentence use language language language model language model language model model software representation free toolkit neural language model free software language model query train free software language model language model toolkit free language toolkit free software language model free language model toolkit gram model neural network model language model toolkit free software free toolkit neural language model free software language free toolkit neural language model language model free software language model free neural network language model toolkit software language model free software smooth gram model language model train\n",
      "=====Markov_models\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability markov model model model state depend state markov property model field forecasting model markov property markov model different depend state observable observation markov chain markov model markov chain model state random variable markov property distribution variable depend distribution state example markov chain markov chain markov property random distribution hide markov model hide markov model markov chain state partially observable observation state state algorithm hide markov model example sequence observation algorithm compute sequence state algorithm compute probability sequence observation algorithm probability observation hide markov model hide state example algorithm sequence markov decision process markov decision process markov chain state depend state markov decision process compute partially observable markov decision process partially observable markov decision process markov decision process state partially markov random field markov random field markov markov chain markov chain state depend state markov random field state depend markov random field field graph random variable distribution random variable depend variable distribution random variable graph compute graph random variable markov random field distribution graph compute hierarchical markov model hierarchical markov model example observation hierarchical markov model hierarchical hide markov model markov model different model markov model markov model markov chain model probability sequence model different sequence markov chain forecasting model markov chain forecasting example markov chain forecasting model different hide markov model markov chain distribution model markov chain markov markov variable markov model\n",
      "=====Hidden_Markov_models\n",
      "=======\n",
      "hide markov model hmm statistical markov model model assume markov process hidden state hide markov model represent dynamic bayesian hmm baum hmm problem forward simple markov model like markov chain state directly visible observer state transition probability parameter hide markov model state directly visible output datum follow state visible state probability distribution possible output sequence generate hmm give information sequence state know hide state sequence model parameter model model hidden markov model parameter know hide markov model know application learn recognition speech recognition speech tag follow hide markov model consider mixture model hide variable latent variable control mixture observation markov process independent hide markov model markov model markov model allow complex model nonstationary datum displaystyle x displaystyle y discrete time process displaystyle displaystyle x y hide markov model displaystyle x markov process directly hidden displaystyle mathbf bigl y bigl x x x x mathbf bigl y bigl x x displaystyle displaystyle x x arbitrary set displaystyle state process displaystyle x call hide state displaystyle mathbf bigl y bigl x x call emission probability output probability description urn discrete hide markov process urn problem urn urn consider example visible observer genie contain urn contain know ball ball genie choose urn draw ball urn ball observer observe sequence ball sequence urn draw genie choose urn choice urn ball depend random number choice urn ball choice urn directly depend urn choose single previous urn call markov process describe markov process observe sequence ball call hide markov process diagram ball draw state observer know urn observe sequence ball observer urn state genie draw ball observer information likelihood ball urn diagram general hmm represent random variable number value random variable hidden state time model diagram random variable observation time diagram call diagram conditional diagram conditional probability distribution hide variable time give value hide variable time depend value hide variable value time call markov value observe variable depend value hide variable time type hide markov model consider state space hide variable discrete observation discrete typically generate categorical distribution continuous typically gaussian distribution parameter hide markov model type transition probability emission probability know output probability transition probability control hide state time choose give hidden state time displaystyle hide state space assume possible value model categorical distribution extension mean possible state hide variable time transition probability state possible state hide variable time displaystyle total displaystyle transition probability note set transition probability transition give state displaystyle time matrix transition probability markov matrix transition probability determine know total displaystyle transition parameter possible state set emission probability govern distribution observe variable particular time give state hide variable time set depend observe variable example observe variable discrete possible value govern categorical distribution displaystyle parameter total displaystyle emission parameter hide state observe variable vector arbitrary gaussian distribution parameter control mean displaystyle parameter control matrix total displaystyle emission parameter case value small observation vector assume independent independent number adjacent inference inference problem associate hidden markov model probability observe sequence task compute give parameter model probability particular output sequence possible state sequence probability observe sequence displaystyle dot give displaystyle possible hide sequence displaystyle dot apply dynamic problem efficiently forward algorithm probability latent variable number task ask probability latent variable give model parameter sequence observation displaystyle dot filter task compute give model parameter sequence observation distribution hide state latent variable sequence compute displaystyle dot task sequence latent variable state process sequence time correspond observation time ask state process problem efficiently forward algorithm smooth similar ask distribution latent variable sequence compute displaystyle dot displaystyle describe probability distribution hide state time time forward algorithm smooth value hide state variable likely task previous ask probability sequence hide state generate particular sequence observation task hmm apply different problem task filter smooth example speech tag hide state represent speech correspond sequence word case sequence speech speech single word filter smooth compute task maximum possible state sequence efficiently viterbi algorithm statistical problem ask statistical probability sequence draw distribution hmm probability case forward algorithm maximum state sequence probability case viterbi algorithm particular output sequence hmm particular output sequence statistical associate output sequence example consider alice bob day bob activity choice determine weather give day alice information weather know general bob day alice weather like alice weather discrete markov chain state rainy sunny observe directly hide day chance bob follow activity depend weather bob alice activity observation hidden markov model hmm alice know general weather bob like word parameter hmm know represent follow represent alice state hmm bob call know rainy particular probability distribution give transition probability rainy sunny represent weather markov chain example chance sunny rainy represent likely bob activity day rainy chance sunny chance similar example viterbi algorithm learn parameter learn task hmms give output sequence set sequence set state transition emission probability task maximum likelihood parameter hmm give set output sequence algorithm know problem maximum likelihood efficiently baum algorithm algorithm baum algorithm case expectation maximization algorithm hmms time bayesian inference like markov chain single maximum likelihood model computational case computational bayesian inference inference computational expectation maximization exact type bayesian inference description general description basic hide markov model describe follow note model prior distribution state displaystyle x specify typical model correspond assume discrete uniform distribution possible state particular prior distribution assume bayesian set parameter associate random variable follow use displaystyle displaystyle arbitrary distribution observation parameter typically displaystyle prior displaystyle choice displaystyle gaussian categorical simple mixture model distribution observation hide markov model mixture density state correspond mixture hmm correspond mixture model non bayesian mixture model bayesian mixture model example follow description implementation typical non bayesian hmm gaussian observation look like typical bayesian hmm gaussian observation look like typical non bayesian hmm categorical observation look like typical bayesian hmm categorical observation look like note bayesian displaystyle beta concentration paramet control density transition matrix high value displaystyle beta significantly probability control transition particular state similar mean probability transition state word path follow markov chain hide state random value displaystyle beta significantly small number possible transition give state probability path follow hide state level bayesian hmm bayesian example level prior parameter transition matrix follow mean follow displaystyle boldsymbol eta probability distribution state specify state likely probability give state vector likely transition state start state displaystyle gamma control density displaystyle boldsymbol eta value significantly vector state similar prior probability value significantly sparse vector state likely prior probability significantly displaystyle beta control density transition matrix density different probability vector displaystyle boldsymbol varphi dot specify probability transition state state value displaystyle beta significantly different displaystyle boldsymbol varphi vector probability mass state mass displaystyle boldsymbol eta control state likely mass displaystyle beta significantly displaystyle boldsymbol varphi vector sparse probability mass small number state transition state different displaystyle boldsymbol varphi vector start state vector sparse different vector mass different state vector displaystyle boldsymbol eta control state likely mass example displaystyle beta displaystyle boldsymbol varphi sparse give start state set state displaystyle mathbf transition likely occur small typically probability displaystyle boldsymbol eta model displaystyle boldsymbol eta different different state correspond displaystyle mathbf state likely occur give displaystyle mathbf value displaystyle boldsymbol eta state high probability displaystyle mathbf contain state start state transition occur give state level model describe allow independent control density transition matrix density state transition likely density prior distribution state particular hide variable displaystyle x case assume particular state likely information model probability vector displaystyle boldsymbol eta directly specify probability non dirichlet distribution prior distribution displaystyle boldsymbol eta dirichlet distribution single paramet displaystyle gamma general dirichlet vector value displaystyle gamma use general dirichlet value displaystyle gamma state poisson hide markov model poisson hide markov model case hide markov model poisson process different state markov model process markov chain markov process observe poisson observe application hmms apply field datum sequence datum depend sequence application include computational single speech recognition include speech speech tag recognition sequence time activity recognition sequence state forward hmm smooth probability describe hide markov model describe statistical baum application hmms speech recognition start hmms apply sequence particular field type hide markov model model complex markov process state observation probability distribution example gaussian distribution hide markov model state output represent gaussian distribution represent complex output state represent mixture gaussian case probability generate observation probability gaussian probability generate observation gaussian case model datum mixture distribution distribution non distribution gaussian extension hide markov model consider state space hide variable discrete observation discrete typically generate categorical distribution continuous typically gaussian distribution hide markov model allow continuous state space example model markov process hide variable linear linear variable hide variable follow gaussian distribution simple case linear exact inference case filter general exact inference hmms continuous latent variable extend filter filter hide markov model model distribution observation hide state prior distribution hide state transition probability conditional distribution observation give state emission probability model algorithm assume uniform prior distribution transition probability possible hide markov model type prior distribution give categorical distribution transition probability dirichlet distribution prior distribution categorical distribution typically dirichlet distribution choose state likely single paramet distribution concentration paramet control density transition matrix choice uniform distribution value matrix transition probability state likely value sparse matrix give state small number state non transition probability possible use level prior dirichlet distribution dirichlet distribution distribution govern parameter dirichlet distribution distribution govern transition probability distribution govern distribution state determine likely state occur concentration paramet determine density state level prior distribution concentration parameter set sparse distribution example speech tag speech occur learn algorithm assume uniform prior distribution task parameter model non uniform prior distribution learn expectation maximization algorithm extension describe hidden markov model dirichlet prior use dirichlet process dirichlet distribution type model allow number state use level dirichlet process similar describe model level dirichlet distribution model call dirichlet process hide markov model hmm describe hide markov model different type extension use model model hmms type model directly model conditional distribution hide state give observation model distribution example model call maximum markov model memm model conditional distribution state know maximum model type model arbitrary feature observation model allow problem model model model hide state associate observation feature observation associate observation observation arbitrary observation give hide state include process determine value hide state feature independent case feature model arbitrary feature adjacent hide state simple transition probability model type prior distribution hide state possible probability arbitrary observation hmm probability describe model linear chain conditional random field use model markov random field model memm similar model type model call problem memm memm hide markov model allow single observation correspond hidden variable set displaystyle independent markov chain single markov chain single hmm displaystyle state assume displaystyle state chain model sequence displaystyle viterbi algorithm displaystyle exact algorithm displaystyle model extend allow hide state allow give state previous state single previous state transition probability extend set adjacent state general displaystyle adjacent state model dynamic algorithm displaystyle time displaystyle adjacent state displaystyle total observation displaystyle markov chain extension markov model process model datum model markov model allow datum model nonstationary datum note datum different problem model nonstationary datum mean hide markov model small dynamic observe datum information high vector variable hmm state transition probability nonstationary hmm transition probability time datum model model datum latent markov model basic model extend include random model complex datum datum latent markov model model use statistical model hide markov model state hmm expectation maximization hmms hide markov model basic hide markov model hide markov model application hide markov model hmm hide markov model hide markov model implementation process hide markov model package set apply inference discrete time discrete space hide markov model library general discrete hide markov model sequence forward algorithm implementation algorithm viterbi algorithm library library java library general java library hmm statistical implementation hmm package library hide markov model hide markov model hmm viterbi path probability example discrete hidden markov model package hide markov model distribution contain implementation hmms hide markov model java library contain basic hmms java high hide markov model viterbi path datum hmms package latent markov model categorical datum markov latent markov model apply algorithm viterbi algorithm\n",
      "=====Markov_networks\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability markov random field mrf markov network undirected model set random variable markov property undirected graph random field markov random field markov property markov network mrf bayesian network dependency bayesian network markov network undirected markov network dependency bayesian network dependency dependency bayesian network dependency graph markov random field joint probability random variable positive random field energy function markov random field ise model markov random field set ise model markov random field model mid image give undirected graph displaystyle set random variable displaystyle x displaystyle form markov random field respect displaystyle markov property markov property variable give variable displaystyle x perp perp x mid x markov property variable variable give displaystyle x perp perp x operatorname mid x operatorname operatorname set displaystyle displaystyle operatorname operatorname displaystyle markov property variable give displaystyle x perp perp x mid x node displaystyle node displaystyle displaystyle markov property markov property markov property positive probability clique markov property probability distribution markov random field factorize clique graph give set random variable displaystyle x displaystyle probability field configuration displaystyle displaystyle displaystyle probability random variable displaystyle value displaystyle displaystyle set probability displaystyle respect joint distribution displaystyle x joint factorize clique displaystyle cl displaystyle operatorname cl x displaystyle form markov random field respect displaystyle cl displaystyle operatorname cl set clique displaystyle clique function factor potential clique potential potential log potential energy configuration displaystyle x mrf factorize example node energy configuration probability energy graph displaystyle mrf factorize positive graph bayesian network possible factor graph network positive markov random field form feature function displaystyle f joint distribution exp displaystyle frac exp leave sum w f x right displaystyle w f x sum w f x field configuration partition function exp displaystyle sum mathcal exp leave sum w f x right displaystyle mathcal set possible assignment value network random variable feature function displaystyle f clique configuration displaystyle f x displaystyle x correspond th possible configuration th clique model clique model give displaystyle operatorname c clique feature displaystyle f correspond correspond clique factor log displaystyle w log c displaystyle c th possible configuration th clique th value clique displaystyle c probability markov field model possible clique factor displaystyle mathcal probability matrix matrix log matrix graph graph matrix partition function markov network partition function problem random variable network example graph partition function exp displaystyle sum mathcal exp leave sum w f x sum j x right respect give value random variable displaystyle x frac leave frac partial partial j right j function displaystyle x x frac leave frac partial partial j partial j right j j markov network model inference model inference example distribution form markov random field respect graph displaystyle correspond matrix matrix displaystyle x mathcal displaystyle inference bayesian network distribution set node displaystyle give value set node displaystyle w w markov random field sum possible assignment displaystyle inference inference problem markov mrfs inference mrfs assignment inference example network model graph form possible variable random field markov random field random field random variable set displaystyle model function displaystyle assignment clique displaystyle form markov network model distribution markov random field field mrfs image image model image model distribution give image mrfs image image image image inference image image problem energy problem problem set feature markov random field markov random field ise model network graph model network ise model log markov markov network mrf\n",
      "=====Evolutionary_algorithms\n",
      "=======\n",
      "artificial evolutionary algorithm ea evolutionary population base optimization algorithm ea use inspire evolution mutation solution optimization problem individual population fitness function solution function evolution population application evolutionary algorithm solution type problem fitness technique evolutionary algorithm model evolution process model base process application computational complexity computational complexity fitness function fitness solution ea solve problem algorithm complexity problem complexity step population individual step fitness individual population fitness step step individual individual mutation individual fitness individual population individual type technique genetic nature problem genetic algorithm type ea solution problem form problem solve mutation type ea optimization problem genetic programming solution form program fitness solve computational problem evolutionary programming genetic programming program numerical expression programming genetic programming program genotype phenotype program evolution solution use mutation evolution base primarily suit numerical optimization problem genetic programming artificial classifier solution classifier individual classifier use population classifier classifier expression type fitness base process evolutionary algorithm genotype phenotype nature process phenotype genetic search mutation evolution artificial artificial expression programming genotype phenotype genotype phenotype expression program technique algorithm colony optimization base form primarily suit combinatorial optimization problem algorithm inspire function nature artificial bee colony algorithm base bee primarily numerical optimization solve combinatorial optimization problem bee algorithm base bee application search inspire use suit optimization problem optimization base behavior optimization base primarily suit numerical optimization problem population base method search method inspire optimization method combinatorial optimization method search nature inspire technique search algorithm use method base search algorithm inspire behavior optimization search base behavior search algorithm combinatorial optimization optimization base theory fitness theory algorithm method inspire form population base algorithm individual problem search penguin colony method inspire behavior penguin colony penguin colony penguin model evolutionary model optimization springer isbn evolutionary algorithm theory evolution evolutionary programming genetic algorithm evolutionary genetic programming evolutionary springer artificial solve springer solve evolution algorithm inspire theory application isbn genetic programming isbn evolution optimization springer evolution evolutionary optimization algorithm computational springer isbn evolutionary algorithm complexity\n",
      "=====Genetic_programming\n",
      "=======\n",
      "genetic programming gp technique evolve program start population random program fit apply operation genetic population program technique program program operation selection fit program crossover mutation fitness crossover operation random select produce new offspring new generation program mutation random program random program program select current generation new generation selection operation apply new generation program new generation fit generation good generation program good generation program generation individual program fitness algorithm result good solution produce good result start population individual technique machine john koza evolve program publication john holland evolution program tree evolve program language current john holland student genetic algorithm conference evolve program language john koza student john holland program evolution publication conference koza publication genetic programming gp student john holland koza start gp publication genetic programming koza result genetic programming human competitive koza start annual genetic programming conference annual conference gp koza gp gp gp annual genetic programming genetic programming conference gp include student gp current genetic programming application include application use representation include method program representation gp evolve program tree tree tree operator evolve gp use programming language tree programming language non tree representation genetic programming language gp use machine code use program language program representation include program machine programming language genetic programming form gp use representation tree representation program representation code non code gene individual offspring operator individual program representation non code gene program representation non code gene selection selection individual select current generation generation individual select individual select selection method gp selection method fitness selection selection gp generation good individual good individual current generation technique crossover genetic operator crossover mutation apply individual select selection new individual operator apply population mutation offspring new generation application gp programming machine gp form solution solution solution application gp fit selection john koza genetic programming produce result competitive human produce result human competitive result annual genetic conference human competitive human competitive result produce form genetic gp meta genetic programming meta genetic programming meta technique evolve genetic programming genetic programming crossover mutation evolve human meta gp technique algorithm evolution meta genetic programming method offspring evolve program program produce new program population fitness result evolve gp produce result form meta evolve gp produce human algorithm evolve human fitness apply meta gp evolution fitness gene programming genetic genetic representation evolution programming genetic programming programming genetic program machine genetic programming gp john koza genetic programming genetic programming\n",
      "=====Genetic_algorithms\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research genetic algorithm ga metaheuristic inspire process natural selection evolutionary algorithm genetic algorithm generate high quality solution optimization search problem inspire operator mutation crossover selection john holland introduce genetic algorithm base theory evolution ga optimization problem genetic algorithm population candidate solution call individual optimization problem evolve well solution candidate solution set chromosome mutate solution represent string possible evolution start population randomly generate individual process population iteration call generation generation fitness individual population evaluate fitness value function optimization problem solve fit individual select population individual recombine randomly mutate form new generation new generation candidate solution iteration algorithm algorithm number generation produce fitness level reach population genetic algorithm require genetic representation solution domain fitness function evaluate solution domain representation candidate solution bit type structure way make genetic representation fix size simple crossover variable length representation crossover implementation complex case tree like representation genetic programming form representation evolutionary programming chromosome tree gene expression programming genetic representation fitness function define ga population solution application mutation crossover selection operator population size depend problem typically possible solution population generate randomly allow possible solution search space solution optimal solution selection generation population select new generation individual solution select fitness base process solution measure fitness function typically select certain selection method rate fitness solution select good solution method rate random sample population process time fitness function define genetic representation measure quality represent solution fitness function problem instance knapsack problem value object knapsack fix capacity representation solution bit bit represent different object value bit represent object knapsack representation valid size object capacity knapsack fitness solution value object knapsack representation valid problem define fitness expression case simulation fitness function value computational encode interactive genetic algorithm genetic operator step generate generation population solution select combination genetic operator crossover call recombination mutation new solution produce parent solution select pool select produce child solution method crossover mutation new solution typically parent new parent select new child process new population solution size generate method base use parent inspire research parent generate high quality chromosome process result generation population chromosome different generation fitness increase population organism generation select small fit solution fit solution genetic diversity genetic pool parent genetic diversity generation child crossover mutation mutation base search crossover mutation know genetic operator possible use operator genetic algorithm parameter mutation probability crossover probability population size problem work small mutation rate lead genetic recombination rate high lead convergence genetic algorithm mutation rate high lead good solution selection employ heuristic operator heuristic employ heuristic crossover candidate solution similar population diversity prevent convergence optimal solution process reach solution fix number generation reach time reach solution fitness reach reach iteration produce well result combination build block hypothesis genetic algorithm simple implement difficult understand particular difficult understand algorithm generate solution high fitness apply problem build block hypothesis heuristic perform adaptation recombine building block low order low length schemata fitness hypothesis genetic algorithm perform adaptation implement heuristic heuristic low order fit schemata sample recombine cross form string high fitness way work particular schemata building block complexity problem instead build high performance string combination better well string good solution fit schemata low length low order genetic algorithm building block child simple block genetic algorithm optimal performance low order high performance schemata building block building block hypothesis evaluate estimation distribution algorithm example propose attempt provide environment hypothesis good result problem building block hypothesis gas efficiency work attempt understand estimation distribution algorithm use genetic algorithm optimization algorithm fitness function evaluation complex problem artificial evolutionary algorithm optimal solution complex high problem require fitness function evaluation real problem optimization problem function evaluation require simulation optimization method type problem case evaluation use fitness efficient model approach use ga solve complex real problem genetic algorithm complexity number element mutation increase search space size make difficult use technique problem design order problem evolutionary search representation possible typically evolutionary algorithm encode design instead building instead instead design problem complexity evolve represent good solution mutation particularly fitness require well solution solution result problem problem gas local point global optimum problem mean know term fitness term fitness depend fitness landscape certain problem provide global optimum function local problem different fitness function increase rate mutation selection technique maintain population solution theorem general solution problem technique maintain diversity group individual add representation group generation similar individual maintain population depend landscape problem possible technique population randomly generate individual population similar diversity genetic algorithm genetic programming cross population new solution evolution strategy evolutionary programming diversity mutation datum set difficult early solution valid method propose increase genetic diversity prevent early convergence increase probability mutation solution quality call introduce new randomly generate element gene pool call random evolution strategy evolutionary programming implement call strategy parent maintain new parent select problem gas solve problem fitness measure measure like problem way solution hill climb case random search solution ga allow different result provide fitness measure optimization problem problem instance optimization algorithm efficient genetic algorithm term convergence algorithm include evolution strategy evolutionary programming simulate anneal gaussian adaptation hill climb swarm intelligence optimization particle swarm optimization method base integer programming genetic algorithm problem know problem better approach variant chromosome representation simple algorithm represent chromosome bit typically parameter represent integer possible use point representation point representation natural evolution strategy evolutionary programming real value genetic algorithm represent building block theory propose john holland theory base result algorithm perform crossover mutation bit level variant chromosome list number node list object datum structure crossover mutation perform datum element datum type variation operator design different datum type work better different problem domain bit string representation integer employ way small change integer mutation crossover prevent convergence call mutation crossover order change chromosome well solution approach real value number instead string represent chromosome result theory general small well performance good result obtain real value chromosome set real value population chromosome form selection recombination low point representation genetic algorithm problem domain obtain complex encode solution pool type encode gene chromosome particular approach allow solve optimization problem require domain problem parameter instance problem structure parameter implement different particular form require crossover recombine chromosome model simulation complex adaptive evolution process variant general process new population allow good organism generation strategy know selection solution quality obtain ga generation parallel implementation parallel implementation genetic algorithm parallel genetic algorithm population node individual node parallel genetic algorithm individual node individual selection variant like genetic algorithm optimization problem introduce time fitness function adaptive gas genetic algorithm adaptive parameter adaptive genetic algorithm variant genetic algorithm probability crossover pc mutation pm solution convergence genetic algorithm obtain instead fix value pc pm population information generation pc pm order maintain population diversity convergence capacity adaptive genetic algorithm pc pm depend fitness value solution base adaptive genetic algorithm use optimization state population pc pm depend optimization state ga optimization method ga good good global solution mutation optimum technique simple hill climb efficient optimum ga hill climb efficiency ga hill mean genetic variation different mean natural case instance provide step order cross number step add number step like add landscape efficiency process increase order operator step order order efficiency variation population evolve individual know gene pool recombination number variation attempt performance gas problem high fitness fitness solution variable algorithm learn build block hypothesis recombination example approach include problem domain problem particularly solution genetic algorithm include problem base gas gas apply genetic algorithm apply approach solve global optimization problem general genetic algorithm problem domain complex fitness landscape mutation combination crossover design population local traditional hill climb algorithm crossover operator change population mutation provide genetic algorithm process example problem solve genetic algorithm include design design space method optimal design complex algorithm design genetic algorithm model application term genetic operator like mutation crossover bit string add level complexity problem genetic algorithm time problem evolution require problem genetic algorithm way computational result genetic algorithm simulate anneal heuristic search propose learn machine parallel evolution simulation evolution start early work new start simulation artificial selection organism simulation evolution early method simulation include element genetic algorithm population solution optimization problem recombination mutation selection research include element genetic algorithm early include early work evolution simple artificial evolution optimization method result work early group solve complex problem evolution strategy approach evolutionary programming technique propose generate artificial intelligence evolutionary programming state machine environment variation selection genetic algorithm particular work john holland early particularly adaptation natural artificial work holland holland introduce quality generation know holland theorem research gas genetic algorithm general start genetic algorithm base design process ga new time john interactive genetic algorithm build optimization heuristic algorithm simulate anneal particle swarm optimization genetic algorithm search search search technique parent field genetic algorithm sub field evolutionary algorithm evolutionary metaheuristic optimization optimization field evolutionary algorithm evolutionary algorithm sub field evolutionary evolution strategy evolve individual mean mutation recombination algorithm design particularly solve problem real value domain use self adaptation parameter search self adaptation lead adaptation evolution strategy evolutionary programming population solution mutation selection representation use self adaptation parameter include variation information parent estimation distribution algorithm traditional operator model operator model learn population employ machine technique represent model new solution sample generate crossover gene expression programming use population program complex program encode simple chromosome fix length expression tree expression tree program evolve chromosome mutation recombination similar ga chromosome genetic result valid program genetic programming technique john program function parameter genetic programming use tree base datum structure represent program adaptation instead list structure genetic algorithm group genetic algorithm evolution ga individual item like gas group item ga evolution propose solve complex problem problem set item group item optimal way better make group item gene problem include measure gas perform make gene group chromosome general variable length genetic operator group item particular good technique interactive evolutionary algorithm evolutionary algorithm use evaluation apply domain design computational fitness function example evolve design form fit swarm intelligence swarm intelligence sub field evolutionary optimization use model traverse solution space estimation distribution algorithm particle swarm optimization computational method optimization use population base approach population swarm candidate solution particle search space particle swarm global like genetic algorithm method depend information population problem efficient gas problem variable evolutionary algorithm evolutionary sub field metaheuristic method algorithm evolutionary algorithm simulate research efficient solve optimization problem traditional evolutionary algorithm algorithm provide high capacity search solution space global optimal evolutionary algorithm evaluate quality value solution algorithm call genetic algorithm population base method solution local algorithm gene problem efficient traditional evolutionary algorithm algorithm inspire evolutionary particularly adaptation evolutionary organism environment environment individual fit environment population level apply complex problem datum algorithm population component genetic algorithm component call space search algorithm inspire gaussian adaptation natural adaptation na ga certain theorem valid gaussian distribution efficiency na information theory certain theorem efficiency efficiency define information work information na mean fitness fitness individual landscape certain local fitness landscape na good climb adaptation na information gaussian mean fitness metaheuristic method metaheuristic method method simulate anneal global optimization technique traverse search space random mutation individual solution mutation increase fitness mutation fitness base fitness low instead fitness ga algorithm start high rate mutation time tabu search similar simulate anneal traverse solution space mutation individual solution simulate anneal generate mutate solution tabu search generate mutate solution solution low generate order prevent solution space tabu list maintain solution solution element tabu list solution traverse solution space optimization gas work population candidate solution evolve solution make local component require representation select individual solution component quality measure fitness algorithm low quality component randomly select component ga select good solution attempt well solution method cross method generate candidate solution probability distribution parameter cross generate well sample iteration search optimization sub machine technique search heuristic solve complex optimization problem search self parameter search include machine learn particular learn learn metaheuristic list genetic algorithm application genetic algorithm particle metaheuristic learn base machine learn provide list genetic algorithm field tutorial genetic algorithm program evolve way natural selection solve complex problem understand ga john holland application interactive genetic algorithm tutorial learn ga work learn step step global convergence change population size crossover rate mutation rate selection add genetic algorithm tutorial state tutorial theory metaheuristic global optimization algorithm theory application genetic algorithm tutorial gas implementation genetic algorithm evolve solve\n",
      "=====Artificial_immune_systems\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence artificial immune system ais class base machine system inspire process immune algorithm model immune learn problem solve field artificial immune system ais abstract function immune computational system application system solve computational problem information ais field inspire compute computation machine learn field artificial intelligence artificial immune system ais system inspire immunology immune function model problem solve ais computational immunology immunology computational model immune model field ais provide field ais immune computation field compute ais immune network ais field negative selection ais dasgupta negative selection algorithm work immune network model work nicosia work clonal selection artificial immune system dasgupta new ais theory algorithm inspire immune new new abstract ais algorithm provide ais ais model ais process immune model process immune algorithm problem dasgupta computation work base application inspire theory function immune clonal selection algorithm class algorithm inspire clonal selection theory algorithm theory selection inspire antibody inspire cell inspire clonal selection algorithm pattern domain algorithm negative selection algorithm inspire negative selection process cell cell negative selection cell cell class algorithm pattern problem domain problem model domain algorithm pattern pattern model pattern immune network algorithm algorithm inspire network theory immune antibody antibody antibody class algorithm network antibody antibody cell algorithm base problem immune network algorithm domain artificial network cell algorithm cell algorithm dca immune inspire algorithm algorithm base abstract model cell dca abstract process model function network cell cell dca information inspire compute computational immunology computational intelligence computation computation intelligence learn base machine immune machine learn vol pp problem solve immune network problem solve dasgupta artificial immune system application nicosia problem vol pp artificial immune system theory application compute dca artificial immune system computation vol pp nicosia immune algorithm model computation vol pp nicosia nicosia artificial immune system information ais algorithm network artificial immune system provide information ais network provide ais ais immune system new ais artificial immune system dasgupta work ais\n",
      "=====Gene_expression_programming\n",
      "=======\n",
      "program gene expression programming gep evolutionary algorithm create program model program complex tree structure learn change size shape like like program gep encode simple linear chromosome fix length gep genotype phenotype simple genome genetic complex phenotype explore environment evolutionary algorithm use population individual select individual fitness genetic genetic operator use artificial system solve problem introduction evolution evolutionary algorithm gain good evolutionary algorithm introduction genetic algorithm gene expression programming evolutionary algorithm genetic algorithm genetic programming genetic algorithm linear chromosome fix length genetic programming parse tree size shape gene expression programming linear chromosome work genotype parse tree phenotype create genotype phenotype genotype phenotype multigenic encode multiple parse tree chromosome mean program create gep compose multiple parse tree parse tree result gene expression gep call expression tree encode genotype genome gene expression programming consist linear string chromosome fix length compose gene equal size gene fix length code expression tree different size shape example chromosome gene size string position start gene represent function represent variable constant problem expression tree phenotype show gene gene expression programming size fix length string code expression tree different size mean size gene gene allow evolution example mathematical expression displaystyle represent expression tree represent root function kind expression tree consist expression gep gene gene linear string encode complex structure example linear string correspond expression tree leave linear string call expression expression expression tree simple example follow expression compose different terminal variable different function argument function argument expression give expression gene expression gene expression programming correspond gene express mean sequence gene express true gene terminal expression encode gep gene correspond program expression gene gene expression programming compose different domain head tail different function head encode function variable choose solve problem hand tail encode variable terminal program error gep gene length tail give max displaystyle max head length nmax maximum arity example gene create set function set terminal nmax choose head length give gene length randomly string example gene encode expression tree case use element gene fix length gene code expression tree different size shape compose node element gene terminal compose node element gene element head function maximum arity implement kind genetic modification mutation inversion insertion recombination guarantee result encode correct error program multigenic chromosome chromosome gene expression programming usually compose gene equal length gene code sub expression tree sub et sub program sub et different way form complex program show example program compose sub program sub et link addition function kind link function choose example complex include classification function probability function usually choose problem evolve cellular gene expression programming cell code gene expression programming homeotic gene different sub main program expression gene result different main program cell determine gene express cell sub cell homeotic gene determine sub et call main program cell kind connection homeotic gene cellular homeotic gene kind normal gene contain head domain tail domain head contain link function special kind terminal terminal represent normal gene expression normal gene result usual different sub et cellular call function tail contain terminal algorithm example chromosome normal gene homeotic gene encode main program different function time link way example cellular allow evolution link function code implement multiple main program multicellular system multicellular system compose homeotic gene homeotic gene different sub expression tree create multiple cell main program example program show create cellular cell normal gene multicellular system multiple like multigenic system problem output problem multiple output head tail domain gep gene normal homeotic basic gep algorithm gene expression programming explore complex head tail structure complex structure consist unit gene basic head tail domain extra domain extra domain usually encode random numerical constant algorithm order good solution instance numerical constant weight function problem gep rnc algorithm weight threshold neural network gep nn algorithm numerical constant need design decision tree gep dt algorithm weight need induction random numerical constant value basic gene expression algorithm step basic gene expression algorithm select function set select terminal set dataset fitness create chromosome initial population randomly program population express chromosome program evaluate fitness select program select program form population chromosome genetic operator step step need algorithm step step initial population create randomly element function terminal set population program like evolutionary algorithm gene expression programming work population individual case program kind initial population create start population selection genetic modification initial population genotype phenotype gene expression programming create simple linear chromosome individual program code expression result correct program fitness function selection environment fitness function selection environment call training dataset learn fitness fitness program depend cost function measure training datum choose evaluate fitness selection environment training datum selection environment consist set training record call fitness case fitness case set problem form call training dataset training datum evolution good solution good training set problem hand algorithm addition dataset good choose record training good datum leave record fitness function different kind problem base kind prediction problem involve numeric prediction problem involve nominal prediction problem involve binary boolean prediction type problem regression classification logistic regression special case classification like probability boolean fitness function regression regression variable numeric usually output regression model evaluate fitness evolve model output model value training datum basic fitness function evaluate model base error model output actual value function include mean squared error root mean squared error mean error squared error root squared error error measure solution work problem evolution determine prediction instance actual value hit prediction choose population model evolve base number hit program usually efficient fitness solution usually involve combine measure kind smooth function error measure fitness function base correlation smooth regression problem function work good combine measure measure correlation range value model output combine function work range target value form efficient fitness function model good correlation good actual value fitness function classification logistic regression design fitness function classification logistic regression different classification model hit record hit fitness function simple work simple problem complex problem dataset give result way type hit base fitness function consist correct classification binary classification correct classification mean case represent mean case represent classification type call true true type classification represent call actual value model target model usually confusion matrix assign different weight type classification create smooth efficient fitness function fitness function base confusion matrix include measure correlation cost gain matrix combine cost gain assign different type classification function base confusion matrix solve problem dimension classification model explore solution result new dimension involve explore structure model include domain range model output explore dimension classification model combine model confusion matrix design fitness function allow smooth solution instance combine measure base confusion matrix mean squared error evaluate model output actual value combine measure evaluate model output target cost gain matrix correlation fitness function explore model include measure new dimension classification model assign probability model output logistic regression use probability evaluate mean squared error measure probability actual value combine confusion matrix create efficient fitness function logistic regression example fitness function base probability include maximum fitness function boolean problem model structure classification logistic regression explore domain range function true fitness function boolean base hit confusion matrix selection roulette wheel selection selection scheme evolutionary involve fitness program roulette wheel fitness roulette time program population order population size constant roulette wheel selection program select fitness mean time good combine roulette wheel selection good program generation guarantee good good generation program simple selection scheme reproduction modification reproduction program involve selection reproduction genome genome modification reproduction evolution replication selection selection operator select program replication operator copy depend selection scheme number copy program program copy copy addition selection usually set population size constant generation replication complex time replication replication string artificial evolutionary system copy string genome generation generation replication select program artificial evolutionary system evolution need implement usual copy error genetic create genetic operator mutation recombination transposition inversion mutation gene expression programming mutation genetic operator change genome change element change time create gene expression programming mutation mean gene domain domain symbol replace example head gene function replace terminal function number argument new function terminal replace function terminal recombination recombination usually involve parent chromosome create new chromosome combine different parent chromosome parent chromosome exchange position chromosome new chromosome create recombination encode correct program different kind easily implement change number parent involve choose number way choose exchange example randomly example gene recombination special case recombination exchange gene gene position chromosome exchange gene choose random position chromosome transposition transposition involve introduction insertion sequence chromosome gene expression programming insertion sequence chromosome head gene method guarantee insertion sequence tail result error program transposition work chromosome length gene structure gene expression programming transposition implement different method create insertion follow head sequence target implement method implement chromosome chromosome gene inversion inversion operator consist sequence chromosome gene expression programming easily implement gene domain case correct gene domain sequence range element domain choose random domain genetic operator genetic operator gene expression program different gene gene domain example genetic operator recombination recombination gene recombination recombination gene transposition root transposition domain specific mutation domain specific inversion domain specific transposition easily implement gep rnc algorithm numerical constant element mathematical model allow model design evolutionary algorithm gene expression programming solve problem use extra gene domain dc handle random numerical constant rnc combine domain special terminal rnc create dc come tail length equal size tail compose symbol represent rnc example show simple chromosome compose gene head size dc position terminal represent rnc kind chromosome express show give expression tree replace leave symbol simplicity represent numeral dc give value correspond symbol array simplicity number represent numeral order array instance follow element array expression tree give structure handle random numerical constant different gep system gep neural network gep decision tree like basic gene expression algorithm gep rnc algorithm multigenic chromosome usual express gene link kind genetic operator gep rnc genetic operator basic gep algorithm implement new chromosome hand basic operator mutation inversion transposition recombination gep rnc algorithm special dc specific operator mutation inversion transposition efficient rnc individual program addition special mutation operator allow introduction set rnc initial set rnc randomly create mean gene initial population number numerical constant choose range randomly mutation genetic operator neural network artificial neural network nn consist simple unit neuron connection unit usually weight value weight weight mean learn neural network learn algorithm usually neural network different class unit input unit unit output unit activation input unit input unit unit output unit activation come unit unit weight link activation unit result unit threshold basic neural network unit connection unit weight threshold order artificial neural network encode linear chromosome express way gep neural network gep nn gep net network encode usual structure head tail domain head contain special function neuron output unit gep unit call unit terminal represent input unit tail usual contain terminal input unit head tail neural network gene contain domain dw dt encode weight threshold neural network dw come tail length dw depend head size maximum arity nmax evaluate max displaystyle max dt come dw length dt equal domain compose symbol represent weight threshold neural network nn gene weight threshold create guarantee usual genetic operator mutation transposition inversion recombination addition special operator allow constant genetic set weight example show neural network input unit unit output unit connection correspond weight represent numeral simplicity threshold equal neural network neural network represent tree case correspond represent input represent function function argument activation order determine output output simple case depend threshold unit activation equal threshold output nn tree follow structure position dw encode weight value weight array expression example show neural net gene problem head size dw size expression result follow neural network set weight give solution function simple boolean function binary input binary output gep net algorithm handle kind function neuron linear neuron neuron neuron logistic neuron neuron neuron kind step neuron gep net algorithm use neuron evolution work good solve problem hand gep net boolean problem logistic regression classification regression case gep net implement multigenic system cellular system multicellular classification problem gep net multigenic system multicellular system decision tree decision tree dt classification model node decision tree type node root node node terminal node root node node represent different attribute variable dataset node class label different tree decision tree induction algorithm involve select attribute root node kind decision node tree decision tree create gene expression programming decision tree algorithm kind input different type dt algorithm induce decision tree nominal attribute induce decision tree numeric nominal attribute decision tree induction gene expression programming gep algorithm decision tree induction decision tree algorithm nominal attribute rnc random numerical constant handle nominal numeric attribute decision tree induce gene expression programming attribute function node basic gene expression algorithm class label terminal mean attribute node specific arity number branch determine tree class label like terminal mean class classification terminal set terminal represent different class encode decision tree linear genome encode mathematical expression decision tree induction gene head tail head contain attribute terminal tail contain terminal decision tree design gep program size tail head size number branch attribute branch nmax max displaystyle max example decision tree encode represent attribute attribute represent class label node datum type number branch attribute encode decision tree induction gene expression programming start usual initial population randomly create chromosome chromosome express decision tree fitness evaluate training dataset fitness select modification genetic operator example mutation inversion transposition recombination decision tree nominal numeric attribute easily induce gene expression programming random numerical constant include extra domain encode random numerical constant datum branch node example gene head size dc start position encode decision tree show node head type numeric attribute nominal attribute terminal random numerical constant simplicity example represent numeral random numerical constant encode dc domain expression follow simple scheme leave element dc assign element decision tree follow array decision tree result represent decision tree gep genetic programming method genexprotool genexprotool genexprotool model include logistic regression classification regression time prediction genexprotool implement basic gene expression algorithm gep rnc algorithm model genexprotool gep gep java create gep gene expression programming java implement different gep algorithm include evolve decision tree nominal numeric attribute function gep code gene expression programming create create simple gene expression programming use implement multigenic chromosome genetic operator mutation transposition code java gep create java code use gep gene expression programming mathematical model artificial gene expression programming mathematical model artificial artificial decision tree evolutionary algorithm genetic algorithm genetic programming genexprotool learn neural network link gep gene expression programming genexprotool gep\n",
      "=====Gene_expression_programming\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program gene expression programming gep evolutionary algorithm create program model program complex tree structure learn change size shape like like program gep encode simple linear chromosome fix length gep genotype phenotype simple genome genetic complex phenotype explore environment evolutionary algorithm use population individual select individual fitness genetic genetic operator use artificial system solve problem introduction evolution evolutionary algorithm gain good evolutionary algorithm introduction genetic algorithm gene expression programming evolutionary algorithm genetic algorithm genetic programming genetic algorithm linear chromosome fix length genetic programming parse tree size shape gene expression programming linear chromosome work genotype parse tree phenotype create genotype phenotype genotype phenotype multigenic encode multiple parse tree chromosome mean program create gep compose multiple parse tree parse tree result gene expression gep call expression tree encode genotype genome gene expression programming consist linear string chromosome fix length compose gene equal size gene fix length code expression tree different size shape example chromosome gene size string position start gene represent function represent variable constant problem expression tree phenotype show gene gene expression programming size fix length string code expression tree different size mean size gene gene allow evolution example mathematical expression displaystyle represent expression tree represent root function kind expression tree consist expression gep gene gene linear string encode complex structure example linear string correspond expression tree leave linear string call expression expression expression tree simple example follow expression compose different terminal variable different function argument function argument expression give expression gene expression gene expression programming correspond gene express mean sequence gene express true gene terminal expression encode gep gene correspond program expression gene gene expression programming compose different domain head tail different function head encode function variable choose solve problem hand tail encode variable terminal program error gep gene length tail give max displaystyle max head length nmax maximum arity example gene create set function set terminal nmax choose head length give gene length randomly string example gene encode expression tree case use element gene fix length gene code expression tree different size shape compose node element gene terminal compose node element gene element head function maximum arity implement kind genetic modification mutation inversion insertion recombination guarantee result encode correct error program multigenic chromosome chromosome gene expression programming usually compose gene equal length gene code sub expression tree sub et sub program sub et different way form complex program show example program compose sub program sub et link addition function kind link function choose example complex include classification function probability function usually choose problem evolve cellular gene expression programming cell code gene expression programming homeotic gene different sub main program expression gene result different main program cell determine gene express cell sub cell homeotic gene determine sub et call main program cell kind connection homeotic gene cellular homeotic gene kind normal gene contain head domain tail domain head contain link function special kind terminal terminal represent normal gene expression normal gene result usual different sub et cellular call function tail contain terminal algorithm example chromosome normal gene homeotic gene encode main program different function time link way example cellular allow evolution link function code implement multiple main program multicellular system multicellular system compose homeotic gene homeotic gene different sub expression tree create multiple cell main program example program show create cellular cell normal gene multicellular system multiple like multigenic system problem output problem multiple output head tail domain gep gene normal homeotic basic gep algorithm gene expression programming explore complex head tail structure complex structure consist unit gene basic head tail domain extra domain extra domain usually encode random numerical constant algorithm order good solution instance numerical constant weight function problem gep rnc algorithm weight threshold neural network gep nn algorithm numerical constant need design decision tree gep dt algorithm weight need induction random numerical constant value basic gene expression algorithm step basic gene expression algorithm select function set select terminal set dataset fitness create chromosome initial population randomly program population express chromosome program evaluate fitness select program select program form population chromosome genetic operator step step need algorithm step step initial population create randomly element function terminal set population program like evolutionary algorithm gene expression programming work population individual case program kind initial population create start population selection genetic modification initial population genotype phenotype gene expression programming create simple linear chromosome individual program code expression result correct program fitness function selection environment fitness function selection environment call training dataset learn fitness fitness program depend cost function measure training datum choose evaluate fitness selection environment training datum selection environment consist set training record call fitness case fitness case set problem form call training dataset training datum evolution good solution good training set problem hand algorithm addition dataset good choose record training good datum leave record fitness function different kind problem base kind prediction problem involve numeric prediction problem involve nominal prediction problem involve binary boolean prediction type problem regression classification logistic regression special case classification like probability boolean fitness function regression regression variable numeric usually output regression model evaluate fitness evolve model output model value training datum basic fitness function evaluate model base error model output actual value function include mean squared error root mean squared error mean error squared error root squared error error measure solution work problem evolution determine prediction instance actual value hit prediction choose population model evolve base number hit program usually efficient fitness solution usually involve combine measure kind smooth function error measure fitness function base correlation smooth regression problem function work good combine measure measure correlation range value model output combine function work range target value form efficient fitness function model good correlation good actual value fitness function classification logistic regression design fitness function classification logistic regression different classification model hit record hit fitness function simple work simple problem complex problem dataset give result way type hit base fitness function consist correct classification binary classification correct classification mean case represent mean case represent classification type call true true type classification represent call actual value model target model usually confusion matrix assign different weight type classification create smooth efficient fitness function fitness function base confusion matrix include measure correlation cost gain matrix combine cost gain assign different type classification function base confusion matrix solve problem dimension classification model explore solution result new dimension involve explore structure model include domain range model output explore dimension classification model combine model confusion matrix design fitness function allow smooth solution instance combine measure base confusion matrix mean squared error evaluate model output actual value combine measure evaluate model output target cost gain matrix correlation fitness function explore model include measure new dimension classification model assign probability model output logistic regression use probability evaluate mean squared error measure probability actual value combine confusion matrix create efficient fitness function logistic regression example fitness function base probability include maximum fitness function boolean problem model structure classification logistic regression explore domain range function true fitness function boolean base hit confusion matrix selection roulette wheel selection selection scheme evolutionary involve fitness program roulette wheel fitness roulette time program population order population size constant roulette wheel selection program select fitness mean time good combine roulette wheel selection good program generation guarantee good good generation program simple selection scheme reproduction modification reproduction program involve selection reproduction genome genome modification reproduction evolution replication selection selection operator select program replication operator copy depend selection scheme number copy program program copy copy addition selection usually set population size constant generation replication complex time replication replication string artificial evolutionary system copy string genome generation generation replication select program artificial evolutionary system evolution need implement usual copy error genetic create genetic operator mutation recombination transposition inversion mutation gene expression programming mutation genetic operator change genome change element change time create gene expression programming mutation mean gene domain domain symbol replace example head gene function replace terminal function number argument new function terminal replace function terminal recombination recombination usually involve parent chromosome create new chromosome combine different parent chromosome parent chromosome exchange position chromosome new chromosome create recombination encode correct program different kind easily implement change number parent involve choose number way choose exchange example randomly example gene recombination special case recombination exchange gene gene position chromosome exchange gene choose random position chromosome transposition transposition involve introduction insertion sequence chromosome gene expression programming insertion sequence chromosome head gene method guarantee insertion sequence tail result error program transposition work chromosome length gene structure gene expression programming transposition implement different method create insertion follow head sequence target implement method implement chromosome chromosome gene inversion inversion operator consist sequence chromosome gene expression programming easily implement gene domain case correct gene domain sequence range element domain choose random domain genetic operator genetic operator gene expression program different gene gene domain example genetic operator recombination recombination gene recombination recombination gene transposition root transposition domain specific mutation domain specific inversion domain specific transposition easily implement gep rnc algorithm numerical constant element mathematical model allow model design evolutionary algorithm gene expression programming solve problem use extra gene domain dc handle random numerical constant rnc combine domain special terminal rnc create dc come tail length equal size tail compose symbol represent rnc example show simple chromosome compose gene head size dc position terminal represent rnc kind chromosome express show give expression tree replace leave symbol simplicity represent numeral dc give value correspond symbol array simplicity number represent numeral order array instance follow element array expression tree give structure handle random numerical constant different gep system gep neural network gep decision tree like basic gene expression algorithm gep rnc algorithm multigenic chromosome usual express gene link kind genetic operator gep rnc genetic operator basic gep algorithm implement new chromosome hand basic operator mutation inversion transposition recombination gep rnc algorithm special dc specific operator mutation inversion transposition efficient rnc individual program addition special mutation operator allow introduction set rnc initial set rnc randomly create mean gene initial population number numerical constant choose range randomly mutation genetic operator neural network artificial neural network nn consist simple unit neuron connection unit usually weight value weight weight mean learn neural network learn algorithm usually neural network different class unit input unit unit output unit activation input unit input unit unit output unit activation come unit unit weight link activation unit result unit threshold basic neural network unit connection unit weight threshold order artificial neural network encode linear chromosome express way gep neural network gep nn gep net network encode usual structure head tail domain head contain special function neuron output unit gep unit call unit terminal represent input unit tail usual contain terminal input unit head tail neural network gene contain domain dw dt encode weight threshold neural network dw come tail length dw depend head size maximum arity nmax evaluate max displaystyle max dt come dw length dt equal domain compose symbol represent weight threshold neural network nn gene weight threshold create guarantee usual genetic operator mutation transposition inversion recombination addition special operator allow constant genetic set weight example show neural network input unit unit output unit connection correspond weight represent numeral simplicity threshold equal neural network neural network represent tree case correspond represent input represent function function argument activation order determine output output simple case depend threshold unit activation equal threshold output nn tree follow structure position dw encode weight value weight array expression example show neural net gene problem head size dw size expression result follow neural network set weight give solution function simple boolean function binary input binary output gep net algorithm handle kind function neuron linear neuron neuron neuron logistic neuron neuron neuron kind step neuron gep net algorithm use neuron evolution work good solve problem hand gep net boolean problem logistic regression classification regression case gep net implement multigenic system cellular system multicellular classification problem gep net multigenic system multicellular system decision tree decision tree dt classification model node decision tree type node root node node terminal node root node node represent different attribute variable dataset node class label different tree decision tree induction algorithm involve select attribute root node kind decision node tree decision tree create gene expression programming decision tree algorithm kind input different type dt algorithm induce decision tree nominal attribute induce decision tree numeric nominal attribute decision tree induction gene expression programming gep algorithm decision tree induction decision tree algorithm nominal attribute rnc random numerical constant handle nominal numeric attribute decision tree induce gene expression programming attribute function node basic gene expression algorithm class label terminal mean attribute node specific arity number branch determine tree class label like terminal mean class classification terminal set terminal represent different class encode decision tree linear genome encode mathematical expression decision tree induction gene head tail head contain attribute terminal tail contain terminal decision tree design gep program size tail head size number branch attribute branch nmax max displaystyle max example decision tree encode represent attribute attribute represent class label node datum type number branch attribute encode decision tree induction gene expression programming start usual initial population randomly create chromosome chromosome express decision tree fitness evaluate training dataset fitness select modification genetic operator example mutation inversion transposition recombination decision tree nominal numeric attribute easily induce gene expression programming random numerical constant include extra domain encode random numerical constant datum branch node example gene head size dc start position encode decision tree show node head type numeric attribute nominal attribute terminal random numerical constant simplicity example represent numeral random numerical constant encode dc domain expression follow simple scheme leave element dc assign element decision tree follow array decision tree result represent decision tree gep genetic programming method genexprotool genexprotool genexprotool model include logistic regression classification regression time prediction genexprotool implement basic gene expression algorithm gep rnc algorithm model genexprotool gep gep java create gep gene expression programming java implement different gep algorithm include evolve decision tree nominal numeric attribute function gep code gene expression programming create create simple gene expression programming use implement multigenic chromosome genetic operator mutation transposition code java gep create java code use gep gene expression programming mathematical model artificial gene expression programming mathematical model artificial artificial decision tree evolutionary algorithm genetic algorithm genetic programming genexprotool learn neural network link gep gene expression programming genexprotool gep\n",
      "=====Nature-inspired_metaheuristics\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization metaheuristic heuristic design heuristic search algorithm solution optimization problem computation metaheuristic solution metaheuristic optimization problem problem optimization algorithm method metaheuristic optimal solution problem metaheuristic optimization solution variable combinatorial optimization search solution metaheuristic solution optimization algorithm method simple heuristic approach optimization problem metaheuristic nature base find global metaheuristic method include metaheuristic metaheuristic strategy guide search search optimal solution metaheuristic algorithm simple local search metaheuristic algorithm metaheuristic problem metaheuristic local search global search approach search strategy search strategy simple local search algorithm local search algorithm method local find global solution metaheuristic propose improve local search heuristic solution metaheuristic include simulate anneal tabu search local search variable search metaheuristic local search base global search metaheuristic global search metaheuristic local search base population base metaheuristic metaheuristic include ant colony optimization evolutionary computation particle swarm optimization genetic algorithm single solution population base single solution population base search single solution approach improve single solution single solution metaheuristic include simulate anneal local search variable search guide local search population base approach improve solution population guide search population base metaheuristic include evolutionary computation genetic algorithm particle swarm optimization metaheuristic swarm population swarm ant colony optimization particle swarm optimization optimization memetic algorithm metaheuristic metaheuristic optimization approach algorithm programming programming metaheuristic guide search memetic algorithm evolutionary population base approach local problem search memetic algorithm local search algorithm evolutionary algorithm parallel metaheuristic parallel metaheuristic parallel programming metaheuristic search parallel simple search improve solution nature inspire base metaheuristic design nature inspire metaheuristic metaheuristic evolutionary computation base algorithm inspire nature design problem metaheuristic include simulate anneal evolutionary algorithm ant colony optimization particle swarm optimization inspire metaheuristic metaheuristic combinatorial optimization optimal solution search problem problem search solution problem search optimal solution combinatorial problem include design problem find find search method metaheuristic problem metaheuristic combinatorial problem include simulate anneal et al genetic algorithm et al search tabu search glover metaheuristic optimization glover metaheuristic metaheuristic propose optimization method optimization problem propose search propose optimization propose heuristic problem strategy algorithm et al propose evolutionary programming propose algorithm propose propose method variable search base tabu search propose genetic algorithm glover propose search propose genetic programming et al propose simulate anneal glover propose tabu search metaheuristic propose memetic algorithm propose simulate anneal search metaheuristic ant colony optimization search optimization heuristic swarm genetic algorithm simulate anneal glover metaheuristic heuristic glover metaheuristic\n",
      "=====Genetic_programming\n",
      "=======\n",
      "genetic programming gp technique evolve program start population random program fit apply operation genetic population program technique program program operation selection fit program crossover mutation fitness crossover operation random select produce new offspring new generation program mutation random program random program program select current generation new generation selection operation apply new generation program new generation fit generation good generation program good generation program generation individual program fitness algorithm result good solution produce good result start population individual technique machine john koza evolve program publication john holland evolution program tree evolve program language current john holland student genetic algorithm conference evolve program language john koza student john holland program evolution publication conference koza publication genetic programming gp student john holland koza start gp publication genetic programming koza result genetic programming human competitive koza start annual genetic programming conference annual conference gp koza gp gp gp annual genetic programming genetic programming conference gp include student gp current genetic programming application include application use representation include method program representation gp evolve program tree tree tree operator evolve gp use programming language tree programming language non tree representation genetic programming language gp use machine code use program language program representation include program machine programming language genetic programming form gp use representation tree representation program representation code non code gene individual offspring operator individual program representation non code gene program representation non code gene selection selection individual select current generation generation individual select individual select selection method gp selection method fitness selection selection gp generation good individual good individual current generation technique crossover genetic operator crossover mutation apply individual select selection new individual operator apply population mutation offspring new generation application gp programming machine gp form solution solution solution application gp fit selection john koza genetic programming produce result competitive human produce result human competitive result annual genetic conference human competitive human competitive result produce form genetic gp meta genetic programming meta genetic programming meta technique evolve genetic programming genetic programming crossover mutation evolve human meta gp technique algorithm evolution meta genetic programming method offspring evolve program program produce new program population fitness result evolve gp produce result form meta evolve gp produce human algorithm evolve human fitness apply meta gp evolution fitness gene programming genetic genetic representation evolution programming genetic programming programming genetic program machine genetic programming gp john koza genetic programming genetic programming\n",
      "=====Datasets_in_machine_learning\n",
      "=======\n",
      "dataset machine learn dataset machine learn learn algorithm high dataset high label dataset machine learn algorithm label datum label high dataset learn image datum dataset image recognition label recognition image recognition system image recognition recognition recognition image image datum dataset analysis analysis sound datum dataset sound sound sound signal datum dataset signal signal analysis signal datum dataset system high system datum dataset system datum datum dataset datum dataset analysis algorithm dataset dataset dataset dataset machine learn machine learn dataset algorithm dataset algorithm algorithm dataset machine learn algorithm dataset image\n",
      "=====Datasets_in_computer_vision\n",
      "=======\n",
      "labelme project create provide dataset image annotation dataset use use labelme vision research labelme image image label object create labelme available datum vision available datum research problem new datum problem labelme create available datum labelme class object instead object example dataset contain image dog labelme contain image dog object scene instead image display object annotation instead label image image contain object labelme allow annotation object image polygon contain object contain object class allow new class image labelme contain image scene provide image allow annotation create annotation tool labelme annotation tool provide user project tool tool user tool choose image labelme dataset display image object label image polygon object label display color image label user use polygon contain object image example image person user click point person click point polygon allow user label object user choose label user object user image user click outline polygon object polygon text label new image user available labelme dataset datum user use tool user image image click image display user problem datum labelme dataset problem datum object image image image object scene image problem user annotation tool problem user choose object scene outline person label object outline object label user object outline polygon person outline outline object user choose text label object label person labelme image image provide datum datum wordnet text label object provide labelme user label object example dog label dog datum object class dog text label wordnet database word allow assign word wordnet sense sense assignment author labelme sense assignment instead assign word sense new label labelme project growth polygon growth word growth word growth polygon labelme wordnet assignment search labelme database example search dog assignment label search object label dog wordnet allow search dog object wordnet labelme database object dataset object overlap allow provide datum object object example label assign object assign label label label label label let displaystyle mathrm mathrm image contain object let displaystyle mathrm mathrm image contain let overlap object displaystyle mathrm mathrm mathrm area area polygon displaystyle mathrm mathrm mathrm mathrm mathrm let displaystyle mathrm mathrm mathrm mathrm mathrm image object polygon displaystyle mathrm mathrm mathrm displaystyle author labelme use displaystyle object label displaystyle mathrm mathrm mathrm mathrm mathrm displaystyle mathrm mathrm mathrm displaystyle mathrm mathrm image displaystyle mathrm mathrm mathrm displaystyle mathrm mathrm displaystyle author labelme use displaystyle allow object object contain object object object overlap object example image contain person person label person instead object overlap object foreground author labelme object contain object object foreground image object object label foreground example object polygon point area foreground author histogram color histogram area color histogram object object color histogram assign foreground polygon point labelme project provide tool labelme dataset research allow dataset tool vision dataset allow dataset research database image annotation tool labelme database tool image annotation color vision labelme labelme annotation tool\n",
      "=====Dimension_reduction\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn information dimensionality reduction dimension reduction reduce variable principal variable approach feature selection feature feature selection feature selection approach variable feature strategy strategy information strategy search embed strategy feature base datum analysis reduce space original space feature projection feature projection feature datum high dimensional space space dimension datum linear principal component analysis pca nonlinear dimensionality reduction technique representation dimensionality reduction learn principal component analysis pca linear technique dimensionality reduction principal component analysis perform linear datum low dimensional space variance datum low dimensional representation matrix datum eigenvector matrix eigenvector principal component variance original datum eigenvector low dimensional original space dimension reduce datum variance space eigenvector non negative matrix nmf nmf non negative matrix non negative non negative nmf datum nmf component linear nmf preserve method pca nmf matrix non negative nmf preserve information pca kernel pca principal component analysis nonlinear kernel technique nonlinear variance datum technique kernel pca base kernel pca nonlinear technique technique linear embed method base space analysis technique low dimensional datum representation function datum base kernel kernel pca technique kernel learn kernel technique variance preserve distance neighbor space distance neighbor approach function distance space technique pca distance space distance space neighbor embed component analysis approach nonlinear dimensionality reduction perform machine base linear discriminant analysis lda linear discriminant analysis lda linear discriminant method machine learn linear feature discriminant analysis gda gda nonlinear discriminant analysis kernel function machine gda method high dimensional feature space lda gda projection feature low dimensional space learn non linear dimension reduction function function original representation dimension reduction high dimensional dimension dimension reduction perform neighbor dimensionality feature dimension reduction principal component analysis pca linear discriminant analysis lda analysis non negative matrix nmf technique feature reduce dimension space machine low dimensional embed high dimensional perform search datum high dimensional search projection high dimensional search technique dimensionality reduction reduce space machine datum reduce low dimension dimensionality dimensionality reduction technique dimension low dimensional representation information original datum preserve dimension reduction machine learn dimension reduction technique dimension reduction variable feature selection linear embed nonlinear dimensionality reduction\n",
      "=====Factor_analysis\n",
      "=======\n",
      "factor analysis statistical method observe correlate variable term low number unobserved variable call factor example possible variation observe variable variation variable factor analysis variation unobserved latent variable observe variable model linear combination factor error term factor analysis aim independent latent variable theory factor method information observed variable reduce set variable factor analysis psychometric personality theory product research data set large number observed variable number underlie latent variable inter technique set variable inter objective latent factor factor analysis relate principal component analysis pca field difference technique exploratory factor analysis principal component analysis pca exploratory factor analysis efa high speed computer pca factor analysis aim reduce set datum approach different technique factor analysis objective identify certain factor observe variable pca address objective pca require factor point exploratory analysis eigenvalue pca component loading error variance statistical model suppose set displaystyle random variable displaystyle x dot x mean displaystyle mu dot mu suppose displaystyle l displaystyle unobserved random variable displaystyle f call common factor influence observe random variable displaystyle dot displaystyle dot displaystyle displaystyle x mu l f cdot l f varepsilon displaystyle varepsilon unobserved error term zero mean variance displaystyle matrix term displaystyle mu varepsilon displaystyle observation displaystyle x time displaystyle l time displaystyle f time column displaystyle displaystyle value particular observation matrix displaystyle observation follow assumption displaystyle displaystyle displaystyle varepsilon independent displaystyle mathrm displaystyle mathrm cov factor uncorrelated solution set equation follow displaystyle define factor displaystyle loading matrix suppose displaystyle mathrm cov mu sigma displaystyle sigma mathrm cov mu mathrm cov varepsilon displaystyle displaystyle sigma mathrm cov mathrm cov varepsilon set displaystyle mathrm cov varepsilon displaystyle sigma note orthogonal matrix displaystyle set displaystyle displaystyle criterion factor factor loading set factor factor loading unique orthogonal example suppose hypothesis intelligence verbal intelligence mathematical intelligence observe hypothesis seek score different field student student choose large student score random variable hypothesis field score group student common value verbal mathematical intelligence time level verbal intelligence time level mathematical intelligence combination factor number particular subject intelligence score hypothesis intelligence level call factor load subject example hypothesis average student aptitude field student verbal intelligence student mathematical intelligence number factor loading associate subject different factor loading student assume degree latent verbal mathematical intelligence different measure aptitude individual aptitude differ average aptitude measurement error difference call error statistical term mean individual measure differ average level intelligence error residual datum factor analysis score student total number factor loading level intelligence student datum mathematical model example follow matrix indicate variable subject indicate value run displaystyle n equal example factor indicate value run displaystyle n equal example sample indicate value run displaystyle n example sample displaystyle n student displaystyle n student score give displaystyle x ai factor analysis correlation variable displaystyle x displaystyle x ai particular set observation order variable equal displaystyle z ai x ai mu sigma sample mean displaystyle mu n sum x ai sample variance give displaystyle sigma n sum x ai mu factor analysis model particular sample displaystyle matrix z ell f ell f varepsilon vdot vdot vdot vdot z ell f ell f varepsilon matrix displaystyle z ai sum ell ap f pi varepsilon ai displaystyle f student verbal intelligence displaystyle f student mathematical intelligence displaystyle ell ap factor loading subject matrix displaystyle observe verbal intelligence component column measure factor loading verbal intelligence make difference model assume standard factor verbal intelligence mathematical intelligence reason assume factor uncorrelated displaystyle sum f pi f delta displaystyle delta delta displaystyle displaystyle error assume independent factor displaystyle sum f pi varepsilon ai note rotation solution solution make interpret factor particular example know type intelligence uncorrelated interpret factor different type intelligence uncorrelated factor correspond verbal intelligence correspond mathematical intelligence value loading average variance error estimate give observed datum assumption level factor give derive displaystyle sum z ai z sum ell ap ell sum varepsilon ai varepsilon term term correlation matrix displaystyle n time n matrix observed datum displaystyle n diagonal element term right diagonal matrix term unity term right reduce correlation matrix equal correlation matrix diagonal value unity diagonal element reduce correlation matrix call communalitie represent variance observe variable account factor displaystyle sum ell ap ell ap sample datum displaystyle z ai equation give sample error model goal analysis model factor displaystyle f pi loading displaystyle ell ap sense good fit data factor analysis good fit define mean square error diagonal residual correlation matrix displaystyle varepsilon sum ab sum z ai z sum ell ap ell right minimize diagonal component error covariance model equation value zero contrast principal component analysis seek minimize mean square error residual high speed computer solution problem estimate communalitie mean problem yield know correlation matrix estimate factor loading high speed computer problem speed communalitie problem mean solution solution factor allow rotation example correspond mathematical model use orthogonal variable factor analysis give datum displaystyle z ai factor displaystyle f pi error displaystyle varepsilon ai vector displaystyle n dimensional sample represent displaystyle mathbf displaystyle mathbf displaystyle boldsymbol varepsilon datum standardize datum vector length displaystyle mathbf cdot mathbf factor vector define displaystyle n dimensional linear hyperplane datum vector follow model equation displaystyle mathbf sum ell ap mathbf boldsymbol varepsilon factor error displaystyle mathbf cdot boldsymbol varepsilon example hyperplane dimensional define factor vector datum vector hyperplane give displaystyle hat mathbf sum ell ap mathbf error vector point datum point hyperplane goal factor analysis hyperplane good fit datum sense factor vector define hyperplane choose independent hyperplane orthogonal displaystyle mathbf cdot mathbf delta set factor hyperplane rotation factor vector define hyperplane solution result example fit hyperplane dimensional know type intelligence uncorrelated interpret factor different type intelligence uncorrelated factor correspond verbal intelligence correspond mathematical intelligence factor linear combination data vector displaystyle mathbf length correlation matrix datum give displaystyle ab mathbf cdot mathbf correlation matrix interpret data vector displaystyle mathbf displaystyle mathbf diagonal element diagonal element value equal unity reduce correlation matrix define displaystyle hat ab hat mathbf cdot hat mathbf goal factor analysis choose fit hyperplane reduce correlation matrix correlation matrix possible diagonal element correlation matrix know value goal possible correlation datum hyperplane mean square error diagonal component displaystyle varepsilon sum ab hat ab right minimize minimize set factor vector displaystyle ab hat ab boldsymbol varepsilon cdot boldsymbol varepsilon term right covariance error model error covariance diagonal matrix problem yield good fit model yield sample estimate error covariance diagonal component minimize mean square sense displaystyle hat orthogonal datum vector length equal length datum vector unity square length diagonal element reduce correlation matrix diagonal element reduce correlation matrix know communalitie displaystyle hat mathbf cdot hat mathbf sum ell ap ell ap large value communalitie indicate hyperplane correlation matrix mean value factor zero follow mean value error zero type factor analysis exploratory factor analysis efa identify item group item researcher make assumption relationship factor factor analysis approach test hypothesis item associate factor use equation model test measurement model loading factor allow relationship observe variable unobserved variable equation model approach measurement error square model test datum analysis loading observe variable latent variable factor correlation latent variable type factor extraction principal component analysis pca method factor extraction efa factor weight compute extract possible variance factoring variance factor model analysis canonical factor analysis call canonical factor different method model pca use principal axis method canonical factor analysis seek factor high canonical correlation observe variable canonical factor analysis data common factor analysis call principal factor analysis principal axis factoring seek number factor account common variance correlation set variable factoring base correlation matrix variable variable variable multiple factoring base factor assume variable sample variable method assume case sample variable factor model model factor model model factor model factor know factor loading square standardize loading item square squared factor load variance variable explain factor variance variable account factor sum squared factor loading factor column number variable note number variable equal sum variance variance standardize variable factor eigenvalue number variable interpret factor loading rule factor analysis loading high independent variable identify represent particular factor level correspond variance explain factor standard high datum criterion researcher exploratory use low level factor factor factor loading interpret theory level oblique rotation pattern matrix structure matrix structure matrix factor load matrix orthogonal rotation represent variance measure variable explain factor unique common pattern matrix contrast coefficient represent unique factor low pattern coefficient rule common variance explain oblique rotation researcher structure pattern coefficient attribute factor oblique rotation derive communality sum squared factor loading factor give variable variance variable account factor communality measure variance give variable factor interpret factor solution communality solution sample extract factor variable variable communality eigenvalue eigenvalue measure variation total sample account factor eigenvalue factor variable factor low eigenvalue variance variable important factor high eigenvalue extraction sum squared loading initial eigenvalue eigenvalue extraction extraction sum squared loading pca extraction extraction method eigenvalue extraction low initial rotation sum squared loading pca eigenvalue differ initial extraction eigenvalue total factor score call component score pca score case factor column compute factor score give case give factor case standardize score variable correspond loading variable give factor sum product compute factor score allow factor factor score variable explain pca factor analysis criterion determine number factor researcher subjective criterion factor sense number objective method problem allow determine solution method analysis suggest factor map suggest researcher factor solution term datum theory criterion analysis base method observe eigenvalue uncorrelated variable factor component retain associate eigenvalue eigenvalue derive random datum rule determine number component retain program include case influence sample item type correlation coefficient map test principal component analysis follow matrix correlation note number square correlation step average square diagonal correlation correlation matrix step principal component associate item average squared diagonal correlation correlation matrix compute step step principal component average square diagonal correlation compute step represent total number variable matrix average squared correlation step step number result low average squared correlation determine number component factor retain method component variance correlation matrix represent variance residual error variance principal component analysis map technique determine number factor retain multiple study procedure method criterion rule drop component eigenvalue eigenvalue equal information account average single item criterion sps statistical criterion estimate number factor extract factor variation method researcher eigenvalue retain factor scree cattell scree test component axis correspond eigenvalue axis right component eigenvalue drop drop make elbow cattell scree test drop component elbow rule researcher elbow subjective multiple elbow researcher set number factor research variance explain criterion researcher use rule factor account variation researcher goal explain variance factor possible criterion low rotation method variance account factor factor orthogonal datum item load factor usually item load factor rotation call simple structure pattern loading item load factor factor rotation orthogonal oblique allow factor correlate varimax rotation orthogonal rotation factor axis variance squared loading factor column variable factor matrix variable extract factor factor large loading particular variable varimax solution yield result possible identify variable single factor common rotation factor assumption oblique rotation orthogonal rotation reason oblique rotation method allow factor correlate psychometric research ability correlate assume rotation orthogonal minimize number factor explain variable type rotation general factor variable load high degree factor structure usually research rotation varimax rotation standard method orthogonal oblique solution factor allow correlate result high eigenvalue factor rotation orthogonal oblique rotation method method large high order factor analysis high order factor analysis statistical method step factor analysis oblique rotation factor analysis factor research structure study interpret result factor pattern matrix high order factor pattern matrix varimax rotation result schmid leiman solution schmid leiman know schmid leiman attribute variation factor order factor psychometric use factor analysis field psychology factor analysis score subject correlate general ability underlie broad field intelligence research know theory student factor analysis study inter individual difference factor analysis subjective individual difference cattell factor theory intelligence test factor analysis factor theory explain intelligence cattell theory address factor include psychology cattell mathematical method psychometric scree test coefficient research theory intelligence personality factor theory personality cattell factor analysis psychometric theory derive research use observation objective study intelligence psychology factor analysis identify factor explain result different test example intelligence research high score test verbal ability good test require verbal ability researcher explain factor analysis factor call verbal intelligence represent degree problem verbal factor analysis psychology associate intelligence research factor broad personality psychometric measure factor number variable variable single factor example run weight single factor general ability usually item matrix factor group item factor analysis technique matrix factor group example group group inter variable relate example factor analysis theory factor call broad visual perception relate good individual visual broad auditory perception factor relate auditory factor call general intelligence relate broad visual perception broad auditory perception mean high high visual perception high auditory perception explain good good different theory differ term axis give solution term model fit theory mean rotation represent different rotation standard factor analysis rotation factor analysis factor analysis good datum allow psychology researcher measure factor analysis base solution datum factor factor analysis identify exploratory factor analysis principal component analysis exploratory factor analysis principal component analysis technique field fabrigar et al factor analysis researcher make assumption underlie model pca variable technique researcher technique mean objective base goal factor model assumption factor analysis result factor analysis good initial model principal component analysis mathematical datum assumption covariance matrix aim pca determine linear combination variable datum set information contrast pca efa fabrigar et al address number reason suggest principal component analysis factor analysis suggest principal component analysis require factor analysis fabrigar et al suggest pca factor analysis result point address fabrigar et al certain case communalitie low technique result fabrigar et al case datum correspond assumption common factor model result pca result certain case factor analysis case variance measure variable estimate account model fabrigar et al suggest case researcher indicate model common factor model case pca approach mean researcher information pca approach individual score certain component information yield factor analysis fabrigar et al aim factor analysis determine factor account structure correlation measure variable require factor score possible compute factor score factor analysis variance covariance factor analysis account random error measurement pca point indicate correlation matrix pca diagonal variance matrix account include variance unique variable variance common variable error variance include variance variable contrast efa communalitie diagonal variance variable account variance unique variable error variance include variance common variable reason factor analysis relationship variable pca goal researcher pattern datum difference procedure result difference principal component analysis factor analysis pca result principal component account variance observe variable fa account common variance datum pca diagonal correlation matrix fa diagonal correlation matrix unique factor pca minimize sum square component axis fa estimate factor influence observe variable component score pca represent linear combination observe variable weight observe variable fa linear combination underlie unique factor pca component yield represent underlie construct fa construct interpret give model step identify attribute use product use research technique datum sample product attribute datum statistical program run factor analysis procedure yield set underlie attribute factor use factor construct map product information datum usually research product sample product attribute attribute choose include use weight attribute choose product study product study datum multiple product statistical program sps analysis analysis underlie factor explain data matrix factor analysis technique set relationship variable independent variable factor analysis assume datum different attribute reduce important possible attribute relate give attribute result influence attribute statistical call score component score underlie factor score degree correlation initial score factor score call factor loading objective subjective attribute subjective attribute score factor analysis identify latent construct analysis researcher ability set product attribute important attribute value procedure reduce set observe variable item factor analysis single factor factor represent relationship factor require theory attribute correlate reason factor analysis important relate different different possible different example associate high level identify factor factor analysis possible suggest factor score different factor correspond different analysis factor analysis high data level case latent variable correspond sample factor analysis statistical analysis program statistical statistical base function fa function rotation factor sps factor analysis fabrigar use exploratory factor analysis research method high order factor analysis rotation simple loading component function oblique case vol pp product oblique rotation simple structure research vol pp approach simple structure rotation vol pp function point analysis vol pp factor analysis factor analysis schmid leiman factor solution exploratory factor analysis item high order factor structure schmid leiman solution sps research method computer factor analysis exploratory factor analysis factor analysis analysis factor analysis factor analysis\n",
      "=====Machine_learning_researchers\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset machine learn dataset machine learn learn algorithm high dataset high label dataset machine learn algorithm label datum label high dataset learn image datum dataset image recognition label recognition image recognition system image recognition recognition recognition image image datum dataset analysis analysis sound datum dataset sound sound sound signal datum dataset signal signal analysis signal datum dataset system high system datum dataset system datum datum dataset datum dataset analysis algorithm dataset dataset dataset dataset machine learn machine learn dataset algorithm dataset algorithm algorithm dataset machine learn algorithm dataset image\n",
      "=====Supervised_learning\n",
      "=======\n",
      "supervise learn machine learn learn function input output base example input output function label training datum set training example supervise learn example input object typically vector desire output value call supervise learn algorithm training datum function example algorithm determine label require learn algorithm training datum bias human learn give problem supervise learn perform determine training example user training set case analysis example gather training set training set function set input object gather output gather human determine input feature learn function learn function input object typically input object feature vector contain number feature object number feature large dimensionality contain information predict output determine learn function learn algorithm example engineer choose support vector machine decision tree learn algorithm gather training set supervised learn algorithm require user determine call validation set training set validation learn function learn function set training set algorithm supervise learn algorithm learn algorithm work supervise learning problem issue consider supervise learn bias variance tradeoff issue tradeoff bias variance different training datum set learn algorithm bias input displaystyle train datum set predict output displaystyle learn algorithm high variance input displaystyle predict different output value train different training set error learn classifier sum bias variance learn algorithm tradeoff bias variance learn algorithm low bias fit datum learn algorithm fit training datum set high variance supervise learning method able tradeoff bias variance bias variance user function complexity training datum issue training datum complexity true function classifier regression function true function learn algorithm high bias low variance able learn datum true function complex complex interaction different input feature different input space function able learn large training datum learning algorithm low bias high variance dimensionality input space issue dimensionality input space input feature vector high learning problem true function number feature learn algorithm high variance high input typically require classifier low variance high bias engineer feature input datum learn function algorithm feature seek feature dimensionality seek input datum low space prior supervise learn algorithm noise output value issue noise desire output value desire output value human error error learn algorithm function training example fit datum overfitte error noise function learn complex learning model function model training datum call noise noise high bias low variance noise output value overfitte noisy training example prior training supervise learn algorithm algorithm noisy training example noisy training example prior training error consider consider choose apply learn algorithm include datum feature vector include feature different value algorithm apply algorithm include support vector machine linear regression logistic regression neural network nearest neighbor method require input feature method function nearest neighbor method support vector machine decision tree datum datum input feature contain information feature learn algorithm linear regression logistic regression base method perform problem form regularization interaction feature output algorithm base linear function linear regression logistic regression support vector machine naive baye function nearest neighbor method support vector machine perform complex interaction feature algorithm decision tree neural network work interaction linear method apply engineer interaction consider engineer learn algorithm determine work problem validation learn algorithm time give time training datum feature time learn algorithm algorithm learn algorithm support vector machine linear regression logistic regression naive baye linear analysis decision tree nearest neighbor algorithm neural network learn supervise learn algorithm work give set displaystyle training example form displaystyle x y x y displaystyle x feature vector example displaystyle y label learn algorithm seek function displaystyle displaystyle input space displaystyle output space function displaystyle space function displaystyle call space displaystyle function displaystyle time displaystyle displaystyle value give high displaystyle displaystyle space function displaystyle displaystyle space function learn algorithm model displaystyle form conditional probability model displaystyle displaystyle form probability model displaystyle example naive baye linear analysis probability model logistic regression conditional probability model choose displaystyle displaystyle empirical risk minimization structural risk minimization empirical risk minimization seek function fit train datum structural risk minimization include penalty function bias variance tradeoff case training set displaystyle x y function fit train datum loss function displaystyle time training example displaystyle x y loss predict value displaystyle displaystyle y risk displaystyle function displaystyle loss displaystyle training datum displaystyle sum y x empirical risk minimization empirical risk minimization supervise learn algorithm seek function displaystyle displaystyle supervise learn algorithm apply algorithm displaystyle displaystyle conditional probability displaystyle loss function log log displaystyle log empirical risk minimization displaystyle contain function training set large empirical risk minimization high variance learn algorithm able training example call overfitte structural risk minimization structural risk minimization seek overfitte regularization penalty regularization penalty form function complex penalty different complexity example consider case function displaystyle linear function form displaystyle sum beta x regularization penalty displaystyle sum beta norm displaystyle norm norm include displaystyle norm displaystyle sum beta displaystyle norm number displaystyle beta penalty displaystyle supervise learn problem function displaystyle displaystyle lambda displaystyle lambda bias variance tradeoff displaystyle lambda give empirical risk minimization low bias high variance displaystyle lambda large learn algorithm high bias low variance value displaystyle lambda choose validation complexity penalty log prior probability displaystyle log displaystyle log case displaystyle displaystyle generative training training method training method seek function displaystyle different output value model case displaystyle probability loss function log log displaystyle sum log x y risk minimization algorithm perform generative training displaystyle generative model datum generative training algorithm training algorithm case form naive baye linear analysis supervised learning problem supervised learning set desire output value training datum datum set noisy training datum learn training example give learn algorithm example typically human user base datum supervised learn learn desire output value complex object tree label method learn input set object desire output object method algorithm learn neural network algorithm case base decision tree learn regression method datum learn learn classifier decision tree decision learn naive baye classifier conditional neighbor algorithm learn learn machine learn algorithm machine learn algorithm support vector machine complexity machine classifier datum learning algorithm recognition information learn information object recognition recognition recognition recognition supervise learn case issue learning bias overfitte machine learn probability learn space machine learn machine learn\n",
      "=====Semisupervised_learning\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semi supervised learning class machine learn use unlabeled datum training label datum unlabeled datum semi supervised learning unsupervised learning label training datum supervise learn label training datum machine learning unlabele datum label data learn label datum learning problem human process label training set unlabele datum semi supervised learn semi supervise learn machine learn model human learning supervise learn framework give set displaystyle example displaystyle x dot x label displaystyle y dot y give displaystyle unlabeled example displaystyle x dot x semi supervised learning use unlabeled datum supervise learn label unsupervised learn semi supervised learning transductive learning inductive learning transductive learning correct label give unlabeled datum displaystyle x dot x inductive learning correct displaystyle displaystyle learn problem label datum example problem class set problem transductive set problem inductive problem class transductive learning input space algorithm assumption use unlabeled datum distribution datum semi supervise learn algorithm use assumption assumption point label supervised learning yield decision boundary case semi supervised learn smoothness assumption yield decision boundary low density point different class cluster assumption datum cluster point cluster label datum label cluster case smoothness assumption give learn algorithm manifold assumption datum manifold low input space case learn manifold label unlabeled data learning distance density manifold manifold assumption datum generate process model instance human image case use distance smoothness space generate problem space image approach self training self learn self label approach semi supervised learning example instance transductive learning framework inductive learn generative model correct learning semi supervised learn mixture semi supervise learning problem unlabele datum image method generative model generative approach learning displaystyle distribution datum point class displaystyle give point displaystyle label displaystyle displaystyle semi supervised learn generative model supervise learn displaystyle unsupervised learn label generative model distribution displaystyle theta vector displaystyle theta assumption unlabeled datum label datum assumption correct unlabeled datum unlabele datum mixture class distribution learn mixture distribution unlabele datum different yield different sum distribution mixture distribution generative model distribution displaystyle theta theta theta vector displaystyle theta decision argmax displaystyle theta underset operatorname argmax theta base label unlabeled datum displaystyle lambda argmax log log displaystyle underset theta operatorname argmax log x y theta lambda log x theta low density class method boundary datum point label unlabele algorithm transductive support vector machine tsvm inductive learning support vector machine supervise learn decision boundary label data tsvm label unlabeled datum decision boundary datum displaystyle label data displaystyle unlabeled datum displaystyle operatorname tsvm displaystyle space displaystyle mathcal regularize argmin displaystyle underset operatorname argmin displaystyle sum y x lambda mathcal lambda sum x displaystyle approach low density process model regularization tsvm case graph base method graph base method semi supervised learn use graph datum label unlabeled example graph example method datum point displaystyle example distance displaystyle displaystyle displaystyle x displaystyle x set displaystyle x x framework manifold regularization graph manifold regularization problem smoothness manifold space problem input space problem argmin displaystyle underset mathcal operatorname argmin displaystyle sum x y lambda mathcal lambda mathcal mathcal displaystyle mathcal space displaystyle mathcal manifold datum regularization displaystyle lambda displaystyle lambda smoothness space graph regularization graph laplacian displaystyle displaystyle sum displaystyle vector displaystyle x dot x displaystyle displaystyle sum mathcal mathcal laplacian supervise learn algorithm regularize support vector machine semi supervised laplacian regularize laplacian approach method semi supervised learn learning unlabeled label datum use unlabeled datum supervise learn framework instance label unlabeled example displaystyle x dot x distance datum unsupervised supervise learning label example self training method semi supervise learn supervised learn algorithm base label data unlabeled datum generate label example input supervise learn algorithm label training self different set generate label example human human semi supervised learning problem yield unlabele datum learning problem instance semi supervised learn human learn unlabele human unlabele image unlabeled example process label example learn graph base semi supervised algorithm laplacian support vector machine laplacian regularize semi supervised learning semi supervised learn semi supervise algorithm learn\n",
      "=====Computational_learning_theory\n",
      "=======\n",
      "computational learning theory learn theory machine learn algorithm result machine learn learning learning learn algorithm sample label sample label algorithm label sample label sample sample algorithm learn algorithm sample computational learning theory time learn computational learn theory polynomial time time result result polynomial time result learn polynomial time result computational different computational learning theory different inference different probability probability bayesian probability different sample different learn probably learn pac learn theory bayesian inference learn theory machine learning learn computational learning theory algorithm pac theory theory machine bayesian inference theory learn theory pac learn computational learning theory proceeding acm theory page http acm haussler probably learning proceeding page http citeseer ist psu edu haussler probably html probability theory probability pac learn proceeding http citeseer ist psu edu pac html inference learn learn algorithm http ist psu edu result kearn learn proceeding acm theory page acm http citeseer ist psu edu kearn html machine learn machine learn http citeseer ist psu edu html learn haussler warmuth haussler warmuth acm probably learn theory acm kearn learn http citeseer ist psu edu kearn learn html kearn learn proceeding acm theory page http citeseer ist psu edu kearn html haussler kearn warmuth polynomial acm computational learning theory warmuth machine learn learn theory bayesian inference\n",
      "=====Kernel_methods_for_machine_learning\n",
      "=======\n",
      "machine learn kernel method algorithm analysis support vector machine svm analysis example algorithm datum representation feature vector representation feature kernel method kernel similarity function datum representation kernel method kernel function feature space datum space inner product datum feature space call kernel trick kernel function datum vector algorithm kernel kernel support vector machine svm analysis analysis linear linear linear kernel trick feature kernel function kernel algorithm example kernel method learn set feature input displaystyle training example displaystyle mathbf y learn weight displaystyle input training set similarity function displaystyle call kernel input displaystyle mathbf training input displaystyle mathbf classifier weight sum similarity sgn displaystyle sgn sum y mathbf mathbf displaystyle classifier input displaystyle mathbf displaystyle displaystyle mathcal time mathcal mathbb kernel function measure similarity input displaystyle mathbf mathbf mathcal sum example displaystyle mathbf y classifier training set displaystyle y displaystyle mathbb weight training example learn algorithm function sgn displaystyle sgn displaystyle positive kernel classifier kernel support vector machine svm svm kernel trick kernel trick linear learn algorithm learn function displaystyle mathbf displaystyle mathbf input space displaystyle mathcal function displaystyle mathbf mathbf inner product space displaystyle mathcal function displaystyle mathcal time mathcal mathbb kernel kernel function kernel function weight sum machine learn function displaystyle kernel feature displaystyle varphi mathcal mathcal displaystyle mathbf mathbf varphi mathbf varphi mathbf mathcal displaystyle mathcal inner product representation displaystyle varphi displaystyle mathcal inner product space mercer theorem function displaystyle varphi space displaystyle mathcal measure function displaystyle mercer condition mercer theorem linear inner product positive matrix mercer condition measure measure displaystyle displaystyle set displaystyle mercer theorem displaystyle sum sum mathbf mathbf c c displaystyle mathbf mathbf displaystyle mathcal displaystyle displaystyle c c positive kernel function displaystyle mercer condition algorithm space displaystyle mathcal linear set space displaystyle varphi linear algorithm displaystyle varphi support vector machine time algorithm matrix displaystyle mathbf mathbb time displaystyle mathbf mathbf call kernel matrix displaystyle mathbf mathbf positive machine learn function displaystyle mercer condition displaystyle similarity displaystyle mercer kernel displaystyle kernel kernel function displaystyle function matrix displaystyle mathbf call matrix kernel method kernel kernel kernel kernel kernel function kernel kernel kernel kernel method vector theorem kernel machine support vector machine support vector machine kernel method\n",
      "=====Support_vector_machines\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn support vector machine svm support vector learning model learn algorithm datum classification regression give set training example belong category svm training algorithm model assign new example category binary linear classifier method scale use svm classification set svm model example point space map example category new example map space belong category base perform linear classification svms efficiently perform linear classification call kernel trick map input high dimensional feature space datum learning learning approach datum group map new datum form group support vector algorithm vladimir vapnik apply support vector support vector machine algorithm datum algorithm application datum common task machine learn give datum point belong class class new data point case support vector machine data point displaystyle dimensional vector displaystyle number know point displaystyle dimensional hyperplane call linear classifier hyperplane classify datum choice good hyperplane large margin class choose hyperplane distance near data point maximize hyperplane know maximum margin hyperplane linear classifier define know maximum margin classifier support vector machine hyperplane set hyperplane high dimensional space classification regression task like good hyperplane large distance near training data point class call margin large margin error original problem finite dimensional space set linearly space propose original finite dimensional space map high dimensional space space svm dot product input datum vector compute term variable original space define term kernel function displaystyle select problem hyperplane high dimensional space define set point dot product vector space set vector set vector define hyperplane vector define hyperplane choose linear combination parameter displaystyle alpha feature vector displaystyle x data base choice hyperplane point displaystyle feature space map hyperplane define displaystyle sum alpha x text note displaystyle small displaystyle displaystyle term sum test point displaystyle datum base point displaystyle x way sum kernel test point datum point set note set point displaystyle map hyperplane result allow set original space application svm solve problem svm text application reduce label training instance transductive method base support vector machine classification perform svms result svms high include version svm use approach suggest vapnik svm svm algorithm apply science classify classify test base svm suggest interpretation svm model support vector machine svm model interpretation support vector machine model feature model prediction new special science original svm algorithm vladimir vapnik vladimir vapnik suggest way nonlinear classifier apply kernel trick maximum margin hyperplane soft margin propose vapnik linear svm give training displaystyle point form displaystyle vec y ldot vec y displaystyle y class point displaystyle vec belong displaystyle vec displaystyle dimensional vector maximum margin hyperplane group point displaystyle vec displaystyle y group point displaystyle y define distance hyperplane near point displaystyle vec group maximize hyperplane set point displaystyle vec displaystyle vec cdot vec displaystyle vec vector hyperplane like form displaystyle vec vector paramet displaystyle vec determine hyperplane vector displaystyle vec margin training datum linearly select hyperplane class data distance large hyperplane call margin maximum margin hyperplane hyperplane lie hyperplane displaystyle vec cdot vec boundary class label displaystyle vec cdot vec boundary class label distance hyperplane displaystyle vec maximize distance minimize displaystyle vec distance compute distance point data point margin follow constraint displaystyle displaystyle vec cdot vec geq displaystyle y displaystyle vec cdot vec leq displaystyle y constraint datum point lie correct margin displaystyle y vec cdot vec geq text leq leq optimization problem minimize displaystyle vec subject displaystyle y vec cdot vec geq displaystyle ldot displaystyle vec displaystyle solve problem determine sgn displaystyle vec operatorname sgn vec cdot vec max margin hyperplane determine displaystyle vec lie near displaystyle vec call support vector soft margin extend svm case datum linearly hinge loss function max displaystyle max leave y vec cdot vec right note displaystyle y target case displaystyle vec cdot vec output function constraint displaystyle vec lie correct margin datum margin function value distance margin minimize max displaystyle leave frac sum max leave y vec cdot vec right right lambda lvert vec rvert paramet displaystyle lambda determine margin displaystyle vec lie correct margin small value displaystyle lambda term loss function margin svm input datum linearly learn classification nonlinear classification original maximum margin hyperplane algorithm propose vapnik linear classifier vladimir vapnik suggest way nonlinear classifier apply kernel trick propose maximum margin hyperplane result algorithm dot product nonlinear kernel function allow algorithm maximum margin hyperplane transform feature space nonlinear transform space high dimensional classifier hyperplane transform feature space nonlinear original input space work high dimensional feature space error support vector machine give algorithm perform common kernel include displaystyle vec x vec x vec x cdot vec x displaystyle vec x vec x vec x cdot vec x function displaystyle vec x vec x gamma vec x vec x displaystyle gamma displaystyle gamma displaystyle vec x vec x vec x cdot vec x displaystyle displaystyle kernel transform displaystyle varphi vec x displaystyle vec x vec x varphi vec x cdot varphi vec x value transform space displaystyle vec sum alpha y varphi vec dot product classification compute kernel trick displaystyle vec cdot varphi vec sum alpha y vec vec svm classifier compute soft margin svm classifier minimize form max displaystyle leave frac sum max leave y cdot x right right lambda lvert rvert soft margin classifier note choose small value displaystyle lambda margin classifier linearly input datum approach reduce quadratic programming problem approach sub gradient descent coordinate descent primal minimize optimization problem function follow way displaystyle ldot variable max displaystyle zeta max leave y cdot x right note displaystyle zeta small number displaystyle y cdot x geq zeta optimization problem follow minimize displaystyle text minimize frac sum zeta lambda subject displaystyle text subject y cdot x geq zeta text zeta geq text call primal problem dual solve dual problem problem maximize displaystyle text maximize c ldot c sum c frac sum sum y c x cdot x y c subject displaystyle text subject sum c y text leq c leq frac lambda text call dual problem dual problem quadratic function displaystyle c subject linear constraint efficiently quadratic programming algorithm variable displaystyle c define displaystyle vec sum c y vec displaystyle c displaystyle vec lie correct margin displaystyle c lambda displaystyle vec lie margin boundary follow displaystyle vec linear combination support vector displaystyle displaystyle vec margin boundary solve displaystyle y vec cdot vec vec cdot vec y note displaystyle y y displaystyle y kernel trick like learn nonlinear classification linear classification transform datum point displaystyle varphi vec give kernel function displaystyle displaystyle vec vec varphi vec cdot varphi vec know classification vector displaystyle vec transform space displaystyle vec sum c y varphi vec displaystyle c solve optimization problem maximize displaystyle begin align text maximize c ldot c sum c frac sum sum y c varphi vec cdot varphi vec y c sum c frac sum sum y c vec vec y c end align subject displaystyle text subject sum c y text leq c leq frac lambda text coefficient displaystyle c solve quadratic programming displaystyle displaystyle c lambda displaystyle varphi vec lie boundary margin transform space solve displaystyle begin align vec cdot varphi vec y leave sum c y varphi vec cdot varphi vec right y leave sum c y vec vec right y end align sgn sgn displaystyle vec operatorname sgn vec cdot varphi vec operatorname sgn leave sum c y vec vec right right method algorithm svm classifier include sub gradient descent coordinate descent technique approach large sub gradient method training example coordinate descent feature space high sub gradient descent sub gradient descent algorithm svm work max displaystyle vec leave frac sum max leave y vec cdot vec right right lambda lvert vec rvert note displaystyle function displaystyle vec displaystyle gradient descent method take function gradient take vector select function sub gradient approach number iteration scale displaystyle number datum point coordinate descent coordinate descent algorithm svm work dual problem maximize displaystyle text maximize c ldot c sum c frac sum sum y c x cdot x y c subject displaystyle text subject sum c y text leq c leq frac lambda text displaystyle ldot coefficient displaystyle c displaystyle c result vector coefficient displaystyle c ldot c near vector coefficient give constraint distance near vector coefficient result algorithm empirical risk minimization soft margin support vector machine example empirical risk minimization algorithm hinge loss way support vector machine belong class algorithm feature hinge loss svms work allow property risk minimization learn give set training example displaystyle x ldot x label displaystyle y ldot y displaystyle y give displaystyle x form hypothesis displaystyle displaystyle x good approximation displaystyle y good approximation define loss function displaystyle ell displaystyle prediction displaystyle like choose hypothesis minimize risk displaystyle varepsilon leave ell y x right case know displaystyle x y case common choose hypothesis minimize empirical risk displaystyle hat varepsilon frac sum ell y x variable displaystyle x y example finite set hypothesis consider small empirical risk risk displaystyle large approach call empirical risk minimization regularization minimization problem define constraint set displaystyle mathcal hypothesis consider displaystyle mathcal space case svm technique consider hypothesis displaystyle displaystyle lvert rvert mathcal regularization displaystyle mathcal lambda lvert rvert mathcal solve new optimization problem displaystyle hat mathcal hat varepsilon mathcal approach call regularization displaystyle mathcal hypothesis displaystyle hypothesis svm hinge loss soft margin svm classifier sgn displaystyle hat operatorname sgn hat cdot choose minimize follow max displaystyle leave frac sum max leave y cdot x right right lambda lvert rvert svm technique empirical risk minimization regularization case loss function hinge loss max displaystyle ell max leave right svm classification algorithm square logistic regression lie choice loss function square empirical risk minimization square loss displaystyle ell logistic regression log loss log ln displaystyle ell log ln target function hinge loss loss function term target function function minimize risk give variable displaystyle displaystyle y displaystyle displaystyle classification set probability probability displaystyle y begin case text probability p text probability p end case classifier displaystyle begin case text p geq text end case square loss target function function displaystyle f leave y right logistic loss function log ln displaystyle f log ln leave p p right target function correct classifier sgn sgn log displaystyle operatorname sgn f operatorname sgn f log displaystyle y target function hinge loss displaystyle hypothesis space choose kernel svm classifier function term displaystyle mathcal classify data extend interpretation svm linear classification empirical risk minimize function margin lie support vector max margin classifier property svm belong linear classifier consider special case regularization special property minimize empirical classification error maximize margin know maximum margin classifier svm classifier paramet svm kernel kernel parameter soft margin paramet common choice kernel paramet displaystyle gamma good combination displaystyle gamma select displaystyle gamma example displaystyle dot displaystyle gamma dot combination paramet choice parameter work bayesian optimization select displaystyle gamma paramet combination model classify new datum training set select parameter svm include follow label input datum class probability svm vapnik probability finite datum svm class task algorithm reduce class task binary problem apply class svm parameter solve model support vector method kernel function learn consider method datum science multiclass svm multiclass svm assign label instance support vector machine label finite set approach reduce multiclass problem binary classification problem common method include binary classifier label versus class versus classification new instance versus case take classifier high output function assign class output function versus approach classification max vote classifier assign instance class vote assign class vote class vote determine instance classification svm error correct output propose multiclass svm method multiclass classification problem optimization problem binary classification problem transductive support vector machine transductive support vector machine extend svms label datum learning follow training set displaystyle mathcal give set displaystyle mathcal star vec star vec star test example classify transductive support vector machine define follow primal optimization problem minimize displaystyle vec vec star displaystyle frac vec subject displaystyle dot displaystyle dot displaystyle y vec cdot vec x geq displaystyle y star vec cdot vec x star geq displaystyle y star transductive support vector machine vladimir vapnik svm svm svms label space regression version svm regression propose vladimir vapnik method call support vector regression model support vector classification training datum function model training point lie margin model training datum function model datum model prediction svm version know square support vector machine svm propose training original solve minimize displaystyle frac subject displaystyle y x leq varepsilon displaystyle x training target value displaystyle y product displaystyle x prediction displaystyle varepsilon paramet prediction displaystyle varepsilon prediction variable allow error allow approximation case problem bayesian svm svm bayesian interpretation technique datum approach svm model parameter probability extend allow application bayesian technique svm feature model version bayesian svm application bayesian svms datum version bayesian kernel support vector machine svm version linear bayesian svm parameter maximum margin hyperplane solve optimization algorithm solve quadratic programming problem svms problem small approach use point method use like iteration primal dual problem solve problem approach solve problem solve linear large kernel approximation kernel trick common method optimization algorithm problem dimensional sub problem solve optimization algorithm algorithm scale property svm problem special case linear support vector machine solve efficiently algorithm logistic regression class algorithm include sub gradient descent coordinate descent training property iteration take linear take datum iteration linear property algorithm kernel svms solve efficiently sub gradient descent allow kernel svms machine learn include learn kernel machine kernel scale kernel regularization support vector machine vector machine kernel model form svm optimization space algorithm support vector machine pdf support vector machine kernel base learning method isbn support vector machine classification pdf method science application support vector machine pdf isbn support vector machine pdf learning application new isbn learn kernel isbn support vector machine new isbn isbn svm large linear classification include svms svm learn classification svm svms\n",
      "=====Learning_in_computer_vision\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vision scientific field deal computer high level understanding digital image video engineering seek automate task human visual vision task include method acquire process analyze understanding digital image extraction high dimensional datum real world order produce symbolic information form decision understanding mean visual image input description world process image understanding see symbolic information image datum model geometry physics learn theory scientific discipline vision theory artificial system extract information image image datum form video sequence view multiple camera multi dimensional datum medical scanner discipline vision seek apply theory model vision system vision include scene reconstruction event detection video tracking object recognition pose estimation learn motion estimation image vision field deal computer high level understanding digital image video engineering seek automate task human visual vision automatic extraction analysis information image sequence image automatic visual understanding scientific discipline vision theory artificial system extract information image image datum form video sequence view multiple camera multi dimensional datum medical scanner discipline vision seek apply theory model vision system vision artificial intelligence mean human visual robot camera see vision field digital image processing time extract dimensional structure image scene understanding study form vision algorithm include extraction edge image line model object small structure optical flow motion estimation see study base mathematical analysis vision include concept scale space inference focus model mathematical concept optimization field research topic research reconstruction lead understanding camera optimization method camera theory field lead method reconstruction scene multiple image problem multi view technique time solve image segmentation time learning technique image significant field graphic vision include image base image view image light field see feature base method machine learning technique optimization learning technique field vision learn algorithm vision datum set task range classification segmentation optical flow method relate field artificial intelligence area artificial intelligence deal autonomous system environment understanding environment require information environment provide vision vision sensor provide high level information environment robot artificial intelligence vision topic recognition learning technique vision see artificial intelligence field field information engineering vision information engineering physics physics field closely related vision vision system image sensor detect typically form visible light sensor design physics process light physics physics image system image sensor require provide complete understanding image process measurement problem physics vision example motion field study biological vision study structure process visual human lead description real vision system order solve certain vision relate task lead vision artificial system design processing biological system different level learn base method vision neural learning base image feature analysis classification vision research closely related study biological vision research closely research human use visual information field biological vision study model process visual human vision study process software hardware artificial vision system biological vision field signal processing field relate vision signal processing method process variable signal typically temporal signal processing variable signal multi variable signal vision specific image method vision processing variable signal multi signal signal processing vision field view vision related research topic study mathematical point view example method vision base optimization geometry significant field vision method software hardware method order process speed vision search field closely related vision image processing image analysis machine vision significant range technique application imply technique field field different research scientific conference field field graphic produce image datum model vision produce model image datum discipline relevant image processing image analysis focus image image local edge extraction noise removal image imply image processing analysis require assumption produce image content vision include analysis image analyze scene image structure information scene image vision assumption scene image machine vision process apply range technology method provide image base automatic inspection process control robot guidance industrial application machine vision focus application vision base robot system vision base inspection measurement imply image sensor technology control theory processing image datum control robot real time processing mean hardware software imply light control machine vision vision use different algorithm field call image focus process produce image deal process analysis image example medical include analysis image medical application recognition field use method extract information signal base approach artificial neural network significant field apply method image datum vision vision application application range task industrial machine vision system speed line research artificial intelligence computer robot world vision machine vision field significant vision technology automate image analysis field machine vision usually refer process automate image analysis method technology provide automate inspection robot guidance industrial application vision application computer pre solve task method base learn example application vision include system automatic inspection application human identification task identification process industrial robot detect event visual input human model object environment medical image analysis autonomous vehicle robot information image image sequence application field medical vision medical image processing extraction information image datum example detection measurement flow example support medical research provide new information structure medical application vision medical area include image human image image example noise second application area vision call machine vision information extract support process example control order example measurement robot machine vision process process call optical military application large area vision example detection vehicle missile guidance system missile guidance missile area specific missile area base acquire image datum military concept imply sensor include image sensor provide set information scene support decision automatic processing datum information multiple sensor new application area autonomous vehicle include base vehicle small robot car vehicle vehicle level range autonomous vehicle vehicle vision base system support autonomous vehicle typically use vision produce environment detect detect certain task specific event example support system system car system autonomous car system autonomous car technology level example military autonomous vehicle range missile missile guidance space autonomous vehicle vision application area include support visual camera tracking tracking biological typical task application area range vision task measurement problem processing problem solve method example typical vision task vision task include method acquire process analyze understanding digital image extraction high dimensional datum real world order produce symbolic information form decision understanding mean visual image input description world process image understanding see symbolic information image datum model geometry physics learn theory recognition problem vision image processing machine vision image datum contain specific object feature different recognition problem object recognition call object classification pre learn object object class usually image pose scene provide identification object example include identification specific identification identification specific vehicle detection image datum specific example include detection medical image detection vehicle automatic detection base small region image datum analyze technique produce algorithm task base neural network large scale visual recognition object classification detection image object class neural network human algorithm object small small image filter digital camera image human human example object class neural network task base recognition content base image image large set image specific content content different example relative image image image high level search text input image contain car pose estimation specific object relative camera example application technique robot object line optical recognition image text usually view text code code datum code recognition recognition technology system human object motion analysis task relate motion estimation image sequence process produce point image scene camera produce image example task motion camera image sequence produce camera tracking usually small set point object vehicle human image sequence optical flow point image point relative image motion motion point scene camera relative scene scene reconstruction typically image scene video scene reconstruction model scene model set point method produce complete model require motion related processing algorithm field base acquire image multiple algorithm multiple image point model image image removal noise sensor noise motion image approach noise removal filter filter filter method model local image structure noise image datum local image structure line edge control filter base local information analysis level noise removal usually approach example field method vision application system application solve specific measurement detection problem large design example contain system control information machine specific vision pre learn application typical vision system image acquisition digital image produce image sensor light camera include range sensor camera sensor image datum image image sequence typically light image image relate pre processing vision method apply image datum order extract specific information usually process order assure certain assumption imply method example assure image noise assure sensor noise information assure relevant information detect scale space image structure scale feature extraction image feature level extract image datum typical example feature line edge point point feature relate motion detection segmentation point processing decision image point region image relevant processing example specific set point segmentation multiple image region contain specific object segmentation image scene object object object refer scene visual temporal segmentation segmentation multiple video frame temporal high level processing input typically small set datum example set point image region contain specific object processing deal example datum model base application specific assumption estimation application specific object pose object image recognition detect object different image different view object decision decision require application example automatic inspection application recognition application human medical military recognition application image understanding system image understanding system include level level include image edge region level include high level include object scene event topic research design level concept concept temporal scale description inference refer process new control refer process inference search technique apply processing inference control search use focus inference hardware vision system contain image acquisition camera control vision contain software order vision system space industrial contain control environment complete include camera support vision system use visible light camera view scene frame frame second usually vision system use image acquisition hardware visible light structure light scanner camera image scanner image hardware image process vision algorithm process visible light image video system frame second digital signal processing graphic hardware high speed image acquisition processing real time system order frame second application real time video system processing certain algorithm high speed image acquisition measurement feature tracking vision system camera vision processing new class graphic process image machine vision space algorithm visual visual vision vision visual list list vision topic list technology artificial intelligence vision vision isbn digital process press isbn information processing application isbn robot vision press isbn vision system isbn dimensional vision press isbn scale space theory vision springer isbn vision process springer isbn text list signal processing vision isbn vision dimensional datum image springer isbn technique vision isbn digital image processing springer isbn multiple view geometry vision press isbn topic vision isbn vision image process isbn mathematical model vision springer isbn digital image processing approach springer isbn vision isbn vision algorithm application springer isbn algorithm image processing vision isbn vision visual press isbn feature extraction image process vision press isbn vision conference list vision complete list relevant vision conference vision code relate vision vision vision machine vision support vision research conference\n",
      "=====Inductive_logic_programming\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inductive logic programming ilp logic programming example background knowledge hypothesis give background knowledge example fact ilp logic program positive negative example positive example negative example background knowledge hypothesis inductive logic programming inductive model program logic program positive negative example inductive logic programming inductive logic programming inverse inverse entailment inverse entailment progol inductive theory fact definition background knowledge give logic theory clause logic program positive negative example give displaystyle displaystyle negated literal hypothesis logic necessity sufficiency weak consistency false strong consistency false displaystyle text necessity model text sufficiency land model text weak consistency land model textit false text strong consistency land land model textit false necessity hypothesis positive fact sufficiency hypothesis positive example displaystyle weak consistency hypothesis background knowledge strong consistency hypothesis negative example displaystyle give background knowledge imply weak consistency negative example give sufficiency strong consistency example example definition par fem dau background knowledge par par par par par fem fem fem fem displaystyle textit par land textit par land textit par land textit par land textit par land textit fem land textit fem land textit fem land textit fem positive example dau dau displaystyle textit dau land textit dau negative example approach inductive logic programming dau approach positive example literal complete background knowledge dau par par par par par fem fem fem fem dau par par par par par fem fem fem fem displaystyle align textit dau leftarrow textit par land textit par land textit par land textit par land textit par land textit fem land textit fem land textit fem land textit fem textit dau leftarrow textit par land textit par land textit par land textit par land textit par land textit fem land textit fem land textit fem land textit fem align clause dau par par par par par fem fem fem fem dau par par par par par fem fem fem fem displaystyle align textit dau lor lnot textit par lor lnot textit par lor lnot textit par lor lnot textit par lor lnot textit par lor lnot textit fem lor lnot textit fem lor lnot textit fem lor lnot textit fem textit dau lor lnot textit par lor lnot textit par lor lnot textit par lor lnot textit par lor lnot textit par lor lnot textit fem lor lnot textit fem lor lnot textit fem lor lnot textit fem align anti literal dau displaystyle textit dau x x ht dau displaystyle textit dau dau displaystyle textit dau par displaystyle lnot textit par x ht x par displaystyle lnot textit par par displaystyle lnot textit par fem displaystyle lnot textit fem x fem displaystyle lnot textit fem fem displaystyle lnot textit fem par displaystyle lnot textit par par displaystyle lnot textit par par displaystyle lnot textit par background knowledge literal par displaystyle lnot textit par x x par displaystyle lnot textit par par displaystyle lnot textit par negated literal negated literal positive literal negated literal displaystyle x x ht dau par fem displaystyle textit dau x x ht lor lnot textit par x ht x lor lnot textit fem x literal background knowledge clause dau par fem background knowledge fact displaystyle textit dau x x ht leftarrow textit par x ht x land textit fem x land text background knowledge fact clause hypothesis approach background knowledge fact clause displaystyle x displaystyle x ht displaystyle x ht displaystyle x displaystyle x definition necessity dau background knowledge imply positive example sufficiency hypothesis par fem displaystyle textit par land textit fem background knowledge imply positive example dau displaystyle textit dau par fem displaystyle textit par land textit fem background knowledge imply positive example dau displaystyle textit dau weak consistency background knowledge strong consistency definition fem par par displaystyle textit leftarrow textit fem land textit par land textit par approach clause literal approach literal selection approach inductive logic programming inductive logic programming program logic theory displaystyle hypothesis theory displaystyle ilp hypothesis search hypothesis selection hypothesis search inductive logic programming procedure hypothesis hypothesis selection selection score hypothesis score example score hypothesis score ilp complete logic theory displaystyle hypothesis theory hypothesis search procedure hypothesis search ilp progol hypothesis inverse entailment theory displaystyle land model land neg model neg theory theory displaystyle land neg model displaystyle model neg displaystyle model neg theory anti entailment anti entailment hypothesis search inverse anti anti entailment hypothesis search procedure ilp example progol hypothesis search procedure inverse entailment complete example complete anti entailment procedure inverse procedure ilp inductive program theory example model progol inductive inductive programming inductive\n",
      "=====Log-linear_models\n",
      "=======\n",
      "log linear model model linear model linear quantity model log linear log linear model log linear model quantity range quantity range model quantity range model range model log linear linear model linear model log linear model\n",
      "=====Classification_algorithms\n",
      "=======\n",
      "machine learn classification problem set category new observation set datum observation instance category know example assign give class give characteristic blood classification example recognition machine learn classification consider instance learn learning set observation procedure know involve group datum category distance observation set property know explanatory variable feature property blood type large value word real value blood classifier work observation observation distance function algorithm classification know term classifier function classification algorithm input datum category classification logistic regression procedure property observation term explanatory variable variable category predict know consider possible value variable machine learn observation know instance explanatory variable term feature group feature vector possible category predict class different term classification analysis type learning learning problem classification example problem recognition output value give input value example regression assign real value output input assign class value example assign word input assign input classification probabilistic classification algorithm statistical class give instance algorithm output class probabilistic algorithm output probability instance possible class class probability algorithm probabilistic classifier output value classifier know weight classifier output probability probabilistic classifier large machine learn problem procedure work statistical classification group problem linear function rule assign group new observation work value group group consider classification rule linear work classification rule different distance new observation assign group distance observation bayesian procedure procedure bayesian classification procedure different group bayesian procedure bayesian rule bayesian procedure involve group probability datum analysis group new observation binary multiclass classification classification problem binary classification multiclass classification binary classification class involve multiclass classification involve assign class classification binary classification multiclass classification binary classifier feature vector instance category predict feature vector property instance property term feature know explanatory variable variable feature feature binary blood type large value word real value blood instance image feature value image instance feature value different word algorithm work term datum real value value datum group linear classifier large algorithm classification term linear function assign score possible category feature vector instance vector weight predict category score type score function know linear function score score feature vector instance vector weight category score score assign instance category instance category score consider category algorithm know linear classifier procedure weight score example algorithm logistic regression logistic regression regression algorithm vector machine linear analysis algorithm learning classifier analysis learning classifier datum classifier set rule procedure value type input classification set large classification algorithm linear classifier linear logistic regression classifier vector machine vector machine classifier algorithm learn vector classifier performance characteristic datum classifier work give problem classifier performance characteristic datum classifier performance classifier give problem classification characteristic classification algorithm performance different class algorithm class classification datum procedure statistical image image analysis recognition recognition recognition classification statistical classification recognition classification\n",
      "=====Ensemble_learning\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn ensemble method multiple learn algorithm well performance learn algorithm statistical ensemble statistical machine learn ensemble set model typically learn algorithm perform hypothesis space hypothesis good prediction problem hypothesis space hypothesis problem good ensemble combine multiple hypothesis well hypothesis ensemble method multiple hypothesis base multiple classifier system cover hypothesis base prediction ensemble typically prediction single model ensemble learning algorithm perform algorithm decision tree ensemble method example random forest algorithm ensemble technique ensemble technique learning example detection ensemble ensemble learn algorithm train prediction train ensemble represent single hypothesis hypothesis hypothesis space model ensemble show represent training datum single model ensemble technique bag tend reduce problem training datum ensemble tend yield well result model ensemble method seek promote model combine random algorithm like random decision tree ensemble algorithm like reduce decision tree learning algorithm show technique model promote ensemble number component classifier ensemble accuracy prediction number problem ensemble datum ensemble classifier statistical number component number component classifier ensemble number classifier accuracy law ensemble show number component classifier class give high accuracy ensemble baye optimal classifier baye optimal classifier classification technique ensemble hypothesis hypothesis space average ensemble baye optimal classifier datum class hypothesis give vote training dataset sample hypothesis training datum vote hypothesis probability hypothesis baye optimal classifier displaystyle c h c h h h displaystyle class displaystyle set possible class displaystyle hypothesis space displaystyle probability displaystyle training datum ensemble baye optimal classifier represent hypothesis displaystyle hypothesis represent baye optimal classifier optimal hypothesis ensemble space space possible ensemble hypothesis displaystyle baye time displaystyle h h h displaystyle c h c h h bagging bagging involve model ensemble vote weight promote model bagging train model ensemble draw training set example random forest algorithm combine random decision tree bagging high classification accuracy boost involve ensemble training model training model boost show yield well accuracy bagging tend training datum boost algorithm well result bayesian averaging bayesian averaging ensemble technique seek baye optimal classifier sample hypothesis hypothesis space combine baye law baye optimal classifier bayesian model averaging bma hypothesis typically sample sample technique example sample draw hypothesis distribution displaystyle show hypothesis draw average baye law technique error error baye optimal classifier technique show result method promote perform ensemble technique bag base bayesian model averaging model combination bma accuracy bma selection high bma bayesian model combination bayesian model combination bmc bayesian model averaging bma sample model ensemble sample space possible ensemble model draw distribution bma give weight single model bmc bma tend yield well result result bmc show well average statistical bma bag baye law model weight probability datum give model typically model ensemble distribution training datum close ensemble sample model space possible training datum ensemble weight model ensemble close distribution training datum reduce method model selection possible ensemble weight give single model ensemble bma close distribution training datum bmc distribution select model close distribution seek combination model close distribution result bma cross validation select good model bucket model result bmc cross validation select good ensemble combination random sample possible bucket model bucket model ensemble technique model selection algorithm good model problem problem bucket model well result good model set problem typically well result average model set approach model selection cross validation selection model bucket time training dataset dataset train select model high average cross validation selection training set cross validation selection involve training learning model model bucket problem model good model weight prediction model bucket bucket model set problem training model time train learn learn approach seek problem involve train algorithm bucket performance algorithm algorithm involve training learn algorithm combine prediction learn algorithm algorithm train algorithm train prediction prediction algorithm algorithm represent ensemble technique model typically yield performance well single train model successfully learn classification learn learn bagging error perform bayesian model average package package bayesian model averaging include bayesian model selection package bayesian package bma package learn package machine learn package ensemble learn include package bag averaging method classification ensemble machine learning ensemble learning application train ensemble learn time number application application ensemble classifier include land cover land cover application datum class include ensemble learning approach base component decision tree boost random forest multiple classifier system land cover change detection change detection problem land cover change time change detection forest land application ensemble classifier change detection vote bayesian average probability combine single classifier ensemble classifier reduce error detection classification machine learning technique problem ensemble learning system show detection detection system like detection ensemble learning successfully system reduce error recognition recognition recognition ensemble base component technique ensemble recognition recognition base learning like recognition base approach base recognition performance ensemble learning successfully recognition fraud detection fraud detection fraud fraud fraud application machine learn ensemble learning technique system financial decision accuracy prediction financial decision ensemble classifier financial financial base problem ensemble classifier change datum ensemble classifier successfully like detection base dataset ensemble averaging machine learn bayesian time ensemble method algorithm boost algorithm ensemble learning machine learn bag boost bayesian model average bayesian model combination bucket model ensemble technique\n",
      "=====Artificial_neural_networks\n",
      "=======\n",
      "artificial neural network ann system computing system biological neural network brain system learn perform task consider example task example image recognition learn identify image cat example image cat cat result identify cat image prior cat example cat identify example process ann base connect unit node call artificial neuron model neuron biological brain connection biological brain signal neuron artificial neuron receive signal process signal neuron connect ann signal connection real number output neuron compute non function input connection call neuron typically weight adjust learn weight increase signal connection neuron threshold signal signal threshold typically neuron layer layer perform input signal layer input layer layer output layer layer multiple time goal ann approach problem human brain time perform task anns task include speech recognition machine network game consider human create model neural network create learn base neural know learn machine call simulate network create network layer method datum handle basic backpropagation control theory principle dynamic programming general method network function backpropagation parameter error gradient backpropagation algorithm training layer network method neural network follow basic process power process neural network introduce recognition level network train level time unsupervised learn backpropagation learn high level layer real value machine model layer create network learn high level concept cat image unsupervised training increase compute power gpus computing allow use large network image recognition problem know deep learning gradient problem gpus backpropagation layer neural network ann begin win ann approach human level task pattern recognition machine learn example long short term memory win connect recognition prior learn pattern human recognition model anns begin architecture human brain perform task algorithm result biological neuron connect pattern allow output neuron input network form artificial neural network simulate neuron neuron node connect node correspond biological connection weight node component neuron ann biological concept artificial neuron receive input input state activation threshold activation function produce output output function input external datum image output task image activation function input value change small change input produce small change output connection weight network connection connection output neuron input neuron connection weight give neuron multiple input output connection function function compute input neuron output neuron connection weight term result neuron typically multiple layer deep learning neuron layer connect neuron follow layer layer receive external data input layer layer produce result output layer layer layer network layer multiple connection pattern connect neuron layer connect neuron layer neuron layer connect neuron layer reduce number neuron layer neuron connection form know network network allow connection neuron layer know network hyperparameter hyperparameter value set learning process begin value parameter learn example hyperparameter include learn rate number layer batch size value hyperparameter hyperparameter example size layer depend number layer learn learn network handle task consider observation learn adjust weight threshold network accuracy result minimize error learn observation reduce error rate learning error rate typically learn error rate high network typically define cost function learn long output learning cost frequently define value output number error low output cat cat small learning reduce observation learn model application optimization theory statistical learning rate learn rate define size step model take adjust error observation high learning rate training time low accuracy low learning rate take long potential accuracy optimization error increase network connection weight rate use learning rate increase concept allow gradient change weight weight depend change gradient value change cost function define cost function frequently function property arise model model model probability cost backpropagation backpropagation method adjust connection weight error learning error connection gradient cost function give state weight weight stochastic gradient method learning machine network train network non neural network learn learning supervise learn unsupervised learn reinforcement learn correspond learning task supervise learn learning use set input output learn task produce output input cost function cost error minimize error network output output task learning pattern recognition know classification know function approximation supervise learn data speech recognition learn form function solution unsupervised learn unsupervised learn input datum give cost function function datum displaystyle textstyle network output cost function task model property model parameter example consider model displaystyle textstyle displaystyle textstyle cost displaystyle textstyle minimize cost produce value displaystyle textstyle datum cost function form depend application example information displaystyle textstyle displaystyle textstyle statistical probability model give data example task unsupervised learn general problem application include statistical distribution reinforcement learn application game take action receive environment goal win game low cost reinforcement learn weight network perform action minimize long term cost time perform action environment observation cost long term cost action cost prior learning environment model decision process state displaystyle textstyle s s action displaystyle textstyle state know probability distribution cost distribution displaystyle textstyle s observation distribution displaystyle textstyle s distribution displaystyle textstyle s s define distribution action give observation take define low cost anns learn component application dynamic programming ann give programming problem game resource anns accuracy reduce solution control problem task reinforcement learn control problem game decision task self learn self learn neural network introduce neural network self learn crossbar caa input situation output action behavior external input external reinforcement input environment caa compute crossbar decision action emotion situation emotion give memory crossbar self learn algorithm perform follow situation perform action receive situation compute emotion situation crossbar memory value reinforcement emotion situation caa exist environment environment environment receive emotion situation environment receive environment caa learn goal behavior environment situation distribution set allow model minimize cost method programming simulate non method optimization learn algorithm learn algorithm model neural network learn stochastic batch stochastic learning input create weight batch learn weight adjust base batch input error batch stochastic learning introduce process local gradient data reduce network local batch learn typically local perform batch error use batch small batch batch select datum set type anns state multiple type component include number unit number layer unit weight dynamic type allow learn learn produce result type allow require learn type hardware general include neural network processing datum long short term memory gradient problem handle signal low high component large speech recognition speech real network network multiple network task win game input network design neural architecture use machine learning ann design approach design network design system basic algorithm model use result network system include design include number type network layer size connection type hyperparameter define design learn neuron layer learning rate step use artificial neural network require model depend data application model learn learn algorithm exist learn algorithm algorithm hyperparameter train datum set select algorithm training datum require model cost function learn algorithm select result ann ann follow function approximation include time approximation model classification include pattern recognition decision datum processing include include control include control application model process artificial neural network application application include control control process control resource general game pattern recognition system signal classification recognition recognition speech recognition system datum machine network anns cancer include cancer cancer cancer cancer information anns anns model model ann example machine learn identify ann system design network anns simulate property system brain anns short term behavior individual neuron dynamic neural arise individual neuron behavior arise neural consider long short term neural system learn memory individual neuron level property power function approximation number neuron require network weight learn parameter architecture value weight real number value weight power machine number neuron connection use value weight result machine power model property correspond model give function information network model solution local exist depend cost function model optimization method begin local large data parameter method application goal create example training arise system network parameter approach training use training select hyperparameter minimize error use form concept perform select large prior probability model statistical learning theory goal minimize correspond error training set error datum supervise neural network use error cost function use statistical method train model set value network output distribution long output probability distribution network activation function function output layer neural network component component base network output probability classification give classification activation function displaystyle train neural network require train real potential solution include training example optimization algorithm large step change network connection follow example example call batch introduce algorithm theory ann function backpropagation step exist biological neural network information real neuron know neuron action potential frequently activation neuron receive action potential frequently information neuron neuron principle information handle biological neural network know anns general principle process information principle define network allow statistical basic function artificial neural network learn recognition result artificial neural network computing system human solution learn neural network handle task game neural network high create number probability resource neural machine biological brain use deep brain brain self signal statistical hardware large neural network require computing resource brain hardware task processing signal neuron simulate neuron architecture memory signal connection neuron require power time neural network hardware computing power gpus increase backpropagation algorithm training network layer deep use gpus reduce training time hardware non neural network type neural network processing call processing unit learn ann learn biological neural network learn algorithm neural network general principle allow learn machine example local non local learning deep architecture approach model neural network approach human external neural network neural network type brain human individual neuron neural network\n",
      "=====Neural_network_software\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural network software research develop artificial neural network software biological neural network adaptive artificial learn simulator neural network simulator software application artificial biological neural network type neural network produce neural network software simulator simulator neural network research simulator type neural network software research neural network type software neural network artificial neural network simulator component base development environment research platform artificial neural network simulator include neural network simulator neural biological neural network software simulator biological neural biological network simulator include datum analysis simulator research simulator datum analysis simulator application artificial neural network datum mining datum analysis simulator development environment datum analysis simulator use simple neural network datum analysis simulator use network type software use neural datum analysis simulator simulator neural network provide simple software software software develop platform development software use tlearn software provide simulator tlearn allow basic network simple network simple tlearn basic simulator basic application platform provide simple tlearn wintempla include network neural network network neural base wintempla neural wintempla neural network wintempla development environment development environment neural network software develop custom type neural network neural network environment analysis component base type development environment use base component base neural network adaptive component allow custom network custom component network allow adaptive adaptive component datum component base component base development environment develop neural network component software component platform component base development environment include software software component base environment include component base development environment simulator learn develop custom neural network neural network custom language platform basic type neural network simple neural network custom provide language neural network model application language model language pmml pmml base language provide application neural network model datum mining model pmml application pmml provide application model model application allow develop model application use application use model pmml model application pmml produce pmml include neural network produce pmml neural learn model pmml produce pmml mining model include neural network datum mining model produce pmml neural network mining model produce pmml neural network datum mining model model neural network learn software datum mining development environment neural network simulator\n",
      "=====Deep_learning\n",
      "=======\n",
      "deep learning deep learn learn machine learning method base artificial neural network learn supervise supervise unsupervised deep learning architecture deep neural network deep belief network recurrent neural network convolutional neural network apply field include vision speech recognition natural language processing recognition network filter machine translation drug medical image analysis game produce result case human artificial neural network anns information processing biological system anns biological brain specifically neural network biological brain deep learning machine learn algorithm use multiple layer extract level feature raw input example image process low layer identify layer identify human face deep learning model base artificial neural network specifically convolutional neural network cnn include organize layer deep generative model deep belief network deep machine deep learning level learn transform input datum representation image recognition application raw input layer encode layer encode layer encode layer recognize image contain face deep learning process learn feature level need hand example number layer layer size provide different word deep deep learning number layer datum transform deep learning system cap depth cap input output cap potentially connection input output feedforward neural network depth cap network number hide layer output layer recurrent neural network signal layer cap depth potentially depth shallow learn deep learning researcher deep learning involve cap depth cap depth show universal function layer function ability network deep model cap extract feature shallow model layer help learn feature deep learning architecture layer layer method deep learning help feature improve performance supervise learn task deep learning method feature translate datum representation layer structure representation deep learning algorithm apply unsupervised learn task datum label example deep structure train unsupervised neural deep belief network interpretation deep neural network term universal approximation probabilistic inference universal approximation concern feedforward neural network layer size approximate function publish activation function multi layer architecture show universal approximation non activation function linear unit universal approximation deep neural network concern network depth allow et al deep neural network activation large input network approximate function small input deep neural network universal probabilistic interpretation field machine learning feature inference training relate specifically probabilistic interpretation consider activation function probabilistic interpretation lead neural network probabilistic interpretation introduce researcher include term deep learning introduce machine learn artificial neural network context neuron learn algorithm supervise deep feedforward publish deep network layer train group method datum algorithm deep learning architecture specifically vision introduce et al apply backpropagation algorithm automatic deep neural network purpose recognize algorithm training require system recognize hand recognize object match image object model et al human brain use object model publish cresceptron method perform object recognition natural image cresceptron start purpose visual learning natural cresceptron layer similar require human hand feature cresceptron learn number feature layer feature represent cresceptron learn object analysis network deep neural network imagenet cresceptron reduce factor publish result multi layer neural network neural network layer self feature neural network multi layer classification neural network train layer feature extract feature layer demonstrate possible train network contain connect layer hide unit algorithm develop factor speed include gradient problem analyze model use task specific feature filter vector machine artificial neural network ann computational lack brain biological network shallow deep learn recurrent net anns year method non model hide model base generative model speech train analyze include gradient structure neural model lack training datum speech recognition researcher neural net generative deep neural network speech speaker recognition speaker recognition lead significant success deep neural network speech process speaker recognition success deep neural network speaker recognition demonstrate similar success speech recognition raw feature hand successfully architecture deep raw linear filter feature show feature contain raw feature speech later produce large scale result speech recognition deep learning method call long term memory lstm recurrent neural network publish lstm rnn gradient problem learn deep learning task require memory event time step speech lstm start speech certain task later classification lstm google speech recognition performance train lstm google search show layer feedforward neural network train layer time layer unsupervised machine backpropagation learn deep belief net deep learn state art system vision automatic speech recognition asr result set timit asr image classification large speech recognition task improve convolutional neural network cnn asr lstm vision deep learning industry early cnn process application deep learn large scale speech recognition start deep learning speech recognition deep generative model speech give capable large scale datum set deep neural net dnn training dnns generative model deep belief net neural net train large train datum backpropagation dnn large context output layer produce error rate low state art model hide model generative model base system recognition error produce type system different integrate deep learning time speech major speech recognition system analysis generative speech model dnn model early deep learning speech recognition lead use industry analysis performance error rate dnns generative model researcher deep learn timit large speech recognition large output layer dnn base context state deep learning involve call deep learning deep learning neural network train process unit gpus year google brain gpus capable dnn gpus increase speed deep learning system time gpus vector computation involve machine learn gpus speed training algorithm reduce time algorithm processing deep learning model deep learn lead win challenge multi task deep neural network predict target drug group deep learning detect target effect drug win datum challenge significant image object recognition cnns train backpropagation year include cnns cnns gpus style need vision approach time performance visual recognition contest win contest win image contest cnns play major vision et al lead show cnn improve vision similar et al win large scale imagenet significant shallow machine learning method et al win contest analysis large medical image detection year challenge error rate imagenet task deep learning reduce similar large scale speech recognition image image classification challenge task generate image cnns researcher imagenet start deep learning transform ai industry deep neural network neural network artificial neural network artificial neural network anns system system biological neural network brain system learn improve ability task consider example task specific example image recognition learn identify image contain cat analyze example image label cat cat result identify cat image use application algorithm base ann base connect unit call artificial neuron biological neuron biological brain connection neuron signal neuron neuron process signal signal neuron connect neuron state represent number typically neuron weight learn increase signal typically neuron organize layer different layer perform different input signal input output layer layer multiple time neural network approach problem way human brain time match specific ability lead backpropagation information network information neural network task include vision speech recognition machine translation network filter play video game medical neural network typically unit connection number number neuron human brain network perform task level human recognize face play deep neural network deep neural network dnn artificial neural network ann multiple layer input output layer dnn find manipulation input output linear relationship non linear relationship network layer output example dnn train recognize give image image certain user result network certain propose label manipulation consider layer dnn layer deep network dnns model non linear relationship dnn architecture generate model object layer layer feature low layer potentially model datum unit perform shallow network deep architecture include approach architecture success specific possible performance multiple architecture datum set dnn typically feedforward network datum input layer output layer dnn neuron value weight connection weight input output network recognize algorithm weight way algorithm certain manipulation process recurrent neural network datum application language model long term memory use convolutional deep neural network cnn vision cnn apply model automatic speech recognition asr challenge anns train dnn overfitte computation time dnn overfitte layer allow model train datum regularization method unit weight regularization regularization apply training overfitte regularization unit hide layer training help method small training set increase size reduce overfitte dnn consider training size number layer number unit layer learning rate weight time computational gradient training example example speed computation large processing architecture gpus produce significant training processing architecture vector computation look type neural network training algorithm model neural network require learning rate weight training process step new datum computational training algorithm linear number neuron involve application automatic speech recognition large scale automatic speech recognition case deep learning lstm rnn learn deep learning task involve multi contain speech event time step time step lstm speech certain task success speech recognition base small scale recognition task base timit datum set contain speaker major speaker sentence small size timit task concern recognition word recognition allow language model model speech recognition error rate list include early result error rate dnns speaker recognition speech recognition lstm major scale dnn training training feature processing deep model dnn relate deep model multi task learning dnn relate deep model cnns speech rnn lstm type deep model include base model integrate deep generative model major commercial speech recognition system google search speech base deep learning image recognition set image classification datum set include training example example timit small size user multiple list result set deep learning base image recognition produce result human deep learning train example analysis analyze case human connect large visual art processing image recognition increase application deep learning technique visual art task dnn capable example identify style give neural style style give apply video generate base visual input field natural language process neural network language model early lstm help improve machine translation language model technique field word embed word embed word layer deep learn architecture transform word representation word word dataset represent point vector word embed rnn input layer allow network sentence vector grammar vector grammar probabilistic context grammar rnn word sentence detect deep neural architecture provide result analysis information language machine translation style recognition classification development word embed sentence embed google translate use large end end long term memory network google neural machine translation use example base machine translation method learn example translate sentence time google translate language network encode sentence translation use language drug large drug win target effect target effect effect research use deep learning predict target target effect drug deep learning structure base drug predict target multiple generative neural network produce way relationship deep learn approximate value possible term value function show natural interpretation value recommendation system recommendation system deep learning extract feature factor model base recommendation deep learning apply learn user multiple model use base approach recommendation multiple task ann predict function relationship medical deep learning predict base datum datum deep learning show medical image analysis deep learning show produce result medical application classification detection image mobile advertising find mobile mobile advertising challenge datum point consider target deep learning large advertising dataset datum point advertising information form machine learning improve image deep learning successfully apply problem application include learn method field image train image dataset deep image train image need detection deep learning successfully apply detection anti deep anti detection recognize relationship datum learn detect predict specific event supervise learning technique classification unsupervised learn detection state defense apply deep learning train robot new task human brain development deep learning theory brain development specifically development propose early theory computational model deep learning system model propose learn brain factor self neural network deep learning model like neural network layer filter layer consider information layer output input layer process self organize state brain organize call factor different brain connect layer brain approach deep learning model hand backpropagation algorithm propose increase process researcher argue unsupervised form deep learning base generative model deep belief network biological generative neural network model relate base process human brain encode deep network example computation perform deep learning unit similar neuron neural representation develop deep learning model similar visual unit level commercial facebook ai perform task google develop capable learning play video game datum input demonstrate learn game google translate use lstm translate language demonstrate mobile application use deep learning recognize object time ai integrate deep learning researcher develop machine learning call training propose new method robot learn perform task human develop tame new algorithm call deep tame later introduce research researcher deep tame deep learning provide robot ability learn new task deep tame robot learn task human video human perform task robot later task help provide deep learning case field theory concern lack theory method learn deep architecture gradient theory algorithm approximate deep learning method look point deep learning look step ai deep learning method lack need research deep learn large challenge machine technique lack way represent relationship way perform inference long way integrate information object typically system like use technique like deep learning technique technique inference deep learning possible train machine vision perform task represent non machine propose concern low level publish representation state deep layer neural network datum image train demonstrate visual research time error deep learning architecture image image image representation multi artificial intelligence architecture deep learning architecture form state image grammar event learn grammar visual training datum term human language artificial intelligence ai deep learning research show artificial neural network identify system use function input anns way ann find match human recognize example image ann find match image look human like search target manipulation term researcher ann image error identify point generate image image look different human group show image successfully image classification defense image search possible image search image identify image group show certain recognition potentially allow researcher ann anns train detect potentially lead similar malware defense industry anns train ann base anti malware defense malware algorithm anti malware ability target group demonstrate certain google malware datum datum machine learning training set human deep learning system training verification datum generate human argue low purpose form human recognize type human generate training datum embed computation task game image recognition google search result face facebook label image information self argue commercial end user application deep learning facebook face recognition need training datum ann train human generate verification datum ann purpose facebook introduce feature user recognize image like label image facebook user generate verification datum train network time argue human user generate training verification datum commercial end user application deep learning system human artificial intelligence application artificial intelligence deep learning state network list artificial intelligence state machine list dataset machine learn research\n",
      "=====Decision_trees\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree decision tool tree model decision outcome utility decision tree commonly operation research decision analysis tool decision tree node represent represent outcome node represent decision path represent rule decision analysis decision tree influence diagram decision tool value utility decision tree node decision node represent node represent node represent tree commonly operation research operation decision decision tree model model model decision tree decision tree influence diagram utility decision analysis tool example operation research decision tree decision tree draw decision tree node path node path draw decision tree example decision rule decision tree decision rule outcome node condition path rule condition condition condition outcome decision rule rule decision tree commonly decision tree draw analysis example analysis decision utility example model example commonly operation research lifeguard beach beach example example beach lifeguard beach beach lifeguard beach example decision tree draw beach decision tree lifeguard lifeguard beach optimal lifeguard beach influence diagram decision tree represent influence diagram rule decision tree model rule datum optimal decision tree tree datum optimal tree decision tool decision tree influence diagram decision tree decision tree model value outcome value model model decision decision tree datum optimal decision tree datum decision tree decision tree decision tree datum decision tree value outcome decision tree example example decision tree decision tree\n",
      "=====Machine_learning_task\n",
      "=======\n",
      "machine learn study algorithm statistical model system use perform specific task pattern inference instead subset artificial intelligence machine learn algorithm build mathematical model base sample datum know training data order prediction decision program perform task machine learn algorithm variety application email vision algorithm perform task machine learn related computational statistic focus make prediction study mathematical optimization method theory application field machine learning datum mining field study machine learning focus datum analysis unsupervised learning application problem machine learn predictive machine learning provide definition algorithm study machine learning field program learn experience class task performance measure performance task measure improve experience definition task machine learn definition define field term compute intelligence machine machine characteristic machine machine learn task machine learn task category supervise learn algorithm build mathematical model set data contain input desire output example task image contain object training datum supervise learn algorithm include image object input image label output contain object input semi supervise learn algorithm mathematical model training datum sample input label classification algorithm regression algorithm type supervise learn classification algorithm output set value classification algorithm email input email output email algorithm email output prediction represent value true regression algorithm continuous output mean value example continuous value object unsupervised learn algorithm build mathematical model set data contain input desire output label unsupervised learn algorithm structure datum like group datum unsupervised learn discover pattern data group input category feature learn process feature input set datum learn algorithm desire output train label set input base input training label human user reinforcement learn algorithm give form positive negative reinforcement environment learn game human algorithm machine learning include model program give set language similar machine learn algorithm probability density function density problem learn algorithm learn inductive bias base experience learn algorithm generate sequence learn experience know new self human use learn relationship field field game artificial intelligence term machine learn book machine learn research book learning machine machine learning pattern classification machine learn related pattern recognition book report give neural network learn machine learning artificial intelligence ai researcher machine learn datum attempt approach problem method term neural network model linear model statistic probabilistic employ medical increase knowledge base approach ai machine learn probabilistic system theoretical problem datum representation system come ai statistic knowledge base learning ai lead inductive logic program statistical research field ai pattern recognition information neural network research ai time ai field researcher include come machine learning separate field field goal artificial intelligence problem nature focus approach ai method model statistic probability theory increase information ability datum mining machine learn datum mining employ method machine learn focus prediction base know learn training datum datum mining focus discovery previously unknown datum analysis knowledge discovery database datum mining use machine learning method different goal machine learning employ datum mining method unsupervised learn improve accuracy research separate conference separate journal come machine learning performance usually ability know knowledge knowledge discovery datum mining task discovery previously unknown knowledge know knowledge unsupervised method supervised method task supervised method training datum optimization machine learn optimization learning problem loss function training set example loss function prediction model train problem instance example classification label instance model train predict label set example field goal generalization optimization algorithm loss training set machine learning loss sample statistic machine learning statistic related field term method goal statistic inference sample machine learning predictive pattern machine learn theoretical tool statistic term datum field statistical datum model algorithmic model algorithmic model mean machine learn algorithm like method machine learn lead field statistical learning theory experience generalization context ability learn machine perform new example task experience learn datum set training example come unknown probability consider space build model space prediction new computational analysis machine learn algorithm performance theoretical know computational learning theory training set learning theory usually performance algorithm instead probabilistic performance common bias way generalization good performance context generalization complexity hypothesis complexity function datum hypothesis function model fit data complexity model increase training hypothesis model generalization addition performance learn study time complexity learn computational learn theory consider polynomial time time complexity result positive result class function learn polynomial time negative result class learn polynomial time approach type learn algorithm type machine learn algorithm approach type datum input output type task problem solve supervise learn supervise learn algorithm build mathematical model set data contain input desire output datum know training data set training example training example input desire output know signal mathematical model training example represent vector call feature vector training datum represent matrix optimization function supervise learn algorithm learn function predict output associate new input function allow algorithm output input training data algorithm improve accuracy output prediction time learn perform task supervised learn algorithm include classification regression classification algorithm output set value regression algorithm output value similarity learning area supervise machine learn related regression classification goal learn example similarity function measure similar related object application recommendation system semi supervised learn algorithm training example training label improve model supervised learn training label label result large training set unsupervised learn unsupervised learn algorithm set datum contain input structure datum like group datum algorithm learn test datum label instead unsupervised learn algorithm identify datum base new data application unsupervised learning field density statistic unsupervised learning datum feature cluster analysis set observation subset call cluster observation cluster similar observation different cluster different technique different structure datum define similarity example similarity cluster cluster method base density semi supervise learning semi supervised learning unsupervised learning label training datum supervise learn label training datum machine learning researcher datum label data learn accuracy reinforcement learn reinforcement learning area machine learn software action environment field study game theory theory research information theory base optimization system intelligence statistic genetic algorithm machine learning environment typically represent decision process reinforcement learn algorithm use programming technique reinforcement learn algorithm knowledge mathematical model model reinforcement learn algorithm learn game human self learn self learn machine learn neural network self learn caa learn caa self learn algorithm compute decision action emotion consequence situation emotion self learn algorithm matrix machine learn situation perform action receive consequence situation compute emotion consequence situation input situation output action separate reinforcement input input environment value reinforcement emotion consequence situation caa exist environment environment genetic environment receive emotion situation environment receive vector genetic environment caa learn goal environment contain situation feature learn learn algorithm discover representation input provide training example include component analysis cluster analysis feature learn algorithm call representation learn algorithm attempt information input way make perform classification prediction technique allow input come unknown datum generate feature allow machine learn feature use perform specific task feature learning supervise unsupervised supervised feature learning feature learn label input datum example include artificial neural network supervise dictionary learning unsupervised feature learning feature learn input datum example include dictionary learning component analysis matrix form cluster learn algorithm attempt learn representation dimensional sparse algorithm attempt learn representation sparse mean mathematical model learn algorithm learn dimensional representation representation datum high dimensional vector learn algorithm discover representation feature high feature define term generate feature machine learn representation datum feature learn machine learn task classification input process real datum image datum attempt define specific feature discover feature representation algorithm sparse dictionary learning sparse dictionary learning feature learn method training example represent linear function sparse matrix method solve method sparse dictionary learning algorithm sparse dictionary learning apply classification problem class previously training example dictionary class build new training example associate class represent dictionary sparse dictionary learning apply image image represent image dictionary anomaly detection datum mining anomaly detection know detection item observation datum typically item represent medical problem anomaly context network detection object object pattern common statistical definition object detection method unsupervised algorithm fail datum instead cluster analysis algorithm cluster form pattern category anomaly detection technique exist unsupervised anomaly detection technique anomaly test datum set instance datum set normal instance fit datum set supervised anomaly detection technique datum set label normal train statistical classification problem nature detection semi supervise anomaly detection technique model represent normal give normal training datum set test test instance generate model association rule association rule learning rule base machine learning method relationship variable large database identify rule discover database measure rule base machine learn term machine learning method learn rule apply knowledge define characteristic rule base machine learn algorithm set rule represent knowledge machine learn algorithm identify model apply instance order prediction rule base machine learning approach include learn system association rule learn artificial system base rule association rule discover large datum system example rule datum information decision addition analysis association rule employ application area include mining detection continuous sequence mining association rule learn typically consider order item learn system rule base machine learn algorithm discovery component typically genetic algorithm learn component perform supervised learn reinforcement learn unsupervised learning identify set context rule apply knowledge order prediction inductive logic programming approach rule learn logic programming representation input example knowledge hypothesis give know knowledge set example represent database logic program positive negative example inductive programming related field consider programming language represent hypothesis logic program program inductive logic programming language theoretical inductive machine learn build model inference program logic program positive negative example term inductive theory mathematical order set model perform machine learning model train training datum process datum prediction type model research machine learning system artificial neural network artificial neural network system system neural network brain system learn perform task consider example program task specific rule model base call artificial neuron model neuron brain connection like brain information signal artificial neuron artificial neuron receive signal process signal artificial neuron common signal connection artificial neuron real output artificial neuron compute non linear function input connection artificial neuron call artificial neuron typically learn increase signal connection artificial neuron signal signal typically artificial neuron layer different layer perform different input signal layer input layer layer output layer layer time goal approach solve problem way human brain time perform specific task lead artificial neural network variety task include vision recognition machine network game medical learning layer artificial neural network approach model way human brain process vision application learn vision recognition decision tree decision tree learn use decision tree predictive model observation item represent item value represent predictive approach statistic datum mining machine learning tree model variable set value call classification tree tree structure represent class label represent feature lead class label decision tree variable continuous value typically real call regression tree decision analysis decision tree represent decision decision make datum mining decision tree datum result classification tree input decision make vector machine vector machine svm vector network set related supervised learning method classification regression give set training example category svm training algorithm build model predict new example category svm training algorithm non probabilistic linear method exist use svm probabilistic classification set addition perform linear classification perform non linear classification call input high dimensional feature space regression analysis regression analysis large variety statistical method relationship input variable associate feature common form linear regression good fit give datum mathematical method high bias regression non linear problem model include polynomial regression fit regression statistical classification regression non input variable high dimensional space bayesian network bayesian network network model probabilistic model represent set variable example bayesian network represent probabilistic relationship give network compute probability algorithm exist perform inference learn bayesian network model sequence variable like signal sequence call bayesian network generalization bayesian network represent solve decision problem call genetic algorithm genetic algorithm algorithm technique process method generate new good give problem machine learn genetic algorithm machine learning technique improve performance genetic algorithm training model usually machine learning model data order perform usually train machine learning model large sample datum training set datum training set image datum user training machine learning model learn learn new approach training machine learning model training process allow user datum increase training process example use machine learn train prediction model user google application application machine learn include program predict user improve accuracy exist recommendation algorithm researcher research theory build model good pattern recommendation recommendation journal research use machine learning predict predict medical machine learn medical software report machine learn algorithm apply field study previously nature research book machine learn machine learn field machine learning program fail result datum datum datum bias problem task algorithm tool people problem self fail attempt use machine learn fail time bias machine learning approach different datum bias machine learning train predict new group represent training datum train data machine learn bias language model learn datum contain human like bias machine learning system bias people google people google training datum real similar non people system test learn language use machine learn bias machine learning use human good artificial intelligence include artificial ai people people people tool model classification machine learning model accuracy technique like method datum training test set training set test set performance training model test set method datum subset perform consider subset subset training model addition method sample instance model accuracy addition accuracy report mean true positive rate true negative rate report positive rate negative rate rate fail characteristic method model ability previously rate provide information characteristic associate area machine learning system train bias bias use algorithmic bias example data lead machine learn bias similarity datum algorithmic rule machine learn human language contain bias machine train language learn bias form bias health care health care system generate machine true improve health care increase example algorithm provide test algorithm machine learn health care provide tool bias previously bias software software contain variety machine learn algorithm include software software software journal journal machine learn research machine learn nature machine intelligence neural conference conference neural information system conference machine learn machine learn database machine learn software machine learn google machine learning use\n",
      "=====Ensemble_learning\n",
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn ensemble method multiple learn algorithm well performance learn algorithm statistical ensemble statistical machine learn ensemble set model typically learn algorithm perform hypothesis space hypothesis good prediction problem hypothesis space hypothesis problem good ensemble combine multiple hypothesis well hypothesis ensemble method multiple hypothesis base multiple classifier system cover hypothesis base prediction ensemble typically prediction single model ensemble learning algorithm perform algorithm decision tree ensemble method example random forest algorithm ensemble technique ensemble technique learning example detection ensemble ensemble learn algorithm train prediction train ensemble represent single hypothesis hypothesis hypothesis space model ensemble show represent training datum single model ensemble technique bag tend reduce problem training datum ensemble tend yield well result model ensemble method seek promote model combine random algorithm like random decision tree ensemble algorithm like reduce decision tree learning algorithm show technique model promote ensemble number component classifier ensemble accuracy prediction number problem ensemble datum ensemble classifier statistical number component number component classifier ensemble number classifier accuracy law ensemble show number component classifier class give high accuracy ensemble baye optimal classifier baye optimal classifier classification technique ensemble hypothesis hypothesis space average ensemble baye optimal classifier datum class hypothesis give vote training dataset sample hypothesis training datum vote hypothesis probability hypothesis baye optimal classifier displaystyle c h c h h h displaystyle class displaystyle set possible class displaystyle hypothesis space displaystyle probability displaystyle training datum ensemble baye optimal classifier represent hypothesis displaystyle hypothesis represent baye optimal classifier optimal hypothesis ensemble space space possible ensemble hypothesis displaystyle baye time displaystyle h h h displaystyle c h c h h bagging bagging involve model ensemble vote weight promote model bagging train model ensemble draw training set example random forest algorithm combine random decision tree bagging high classification accuracy boost involve ensemble training model training model boost show yield well accuracy bagging tend training datum boost algorithm well result bayesian averaging bayesian averaging ensemble technique seek baye optimal classifier sample hypothesis hypothesis space combine baye law baye optimal classifier bayesian model averaging bma hypothesis typically sample sample technique example sample draw hypothesis distribution displaystyle show hypothesis draw average baye law technique error error baye optimal classifier technique show result method promote perform ensemble technique bag base bayesian model averaging model combination bma accuracy bma selection high bma bayesian model combination bayesian model combination bmc bayesian model averaging bma sample model ensemble sample space possible ensemble model draw distribution bma give weight single model bmc bma tend yield well result result bmc show well average statistical bma bag baye law model weight probability datum give model typically model ensemble distribution training datum close ensemble sample model space possible training datum ensemble weight model ensemble close distribution training datum reduce method model selection possible ensemble weight give single model ensemble bma close distribution training datum bmc distribution select model close distribution seek combination model close distribution result bma cross validation select good model bucket model result bmc cross validation select good ensemble combination random sample possible bucket model bucket model ensemble technique model selection algorithm good model problem problem bucket model well result good model set problem typically well result average model set approach model selection cross validation selection model bucket time training dataset dataset train select model high average cross validation selection training set cross validation selection involve training learning model model bucket problem model good model weight prediction model bucket bucket model set problem training model time train learn learn approach seek problem involve train algorithm bucket performance algorithm algorithm involve training learn algorithm combine prediction learn algorithm algorithm train algorithm train prediction prediction algorithm algorithm represent ensemble technique model typically yield performance well single train model successfully learn classification learn learn bagging error perform bayesian model average package package bayesian model averaging include bayesian model selection package bayesian package bma package learn package machine learn package ensemble learn include package bag averaging method classification ensemble machine learning ensemble learning application train ensemble learn time number application application ensemble classifier include land cover land cover application datum class include ensemble learning approach base component decision tree boost random forest multiple classifier system land cover change detection change detection problem land cover change time change detection forest land application ensemble classifier change detection vote bayesian average probability combine single classifier ensemble classifier reduce error detection classification machine learning technique problem ensemble learning system show detection detection system like detection ensemble learning successfully system reduce error recognition recognition recognition ensemble base component technique ensemble recognition recognition base learning like recognition base approach base recognition performance ensemble learning successfully recognition fraud detection fraud detection fraud fraud fraud application machine learn ensemble learning technique system financial decision accuracy prediction financial decision ensemble classifier financial financial base problem ensemble classifier change datum ensemble classifier successfully like detection base dataset ensemble averaging machine learn bayesian time ensemble method algorithm boost algorithm ensemble learning machine learn bag boost bayesian model average bayesian model combination bucket model ensemble technique\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-493e52cdecc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0marticles_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "#Extract wikipedia articles (to convert into feature vectors)\n",
    "file = open(\"nodes.txt\", \"r\")\n",
    "articles_cleaned = []\n",
    "freq_threshold = 3\n",
    "for line in file:\n",
    "    print(\"=====\" + line + \"=======\")\n",
    "    page = wikipedia.page(wikipedia.search(line.rstrip(\"\\n\"))[0])\n",
    "    content = page.content\n",
    "    cleaned = preprocess(content) #strip punctuations and stopwords and weird characters\n",
    "    cleaned = \" \".join(cleaned)\n",
    "    doc = nlp(cleaned)\n",
    "    lemm = [token.lemma_ for token in doc]\n",
    "    d = defaultdict(int)\n",
    "    for item in lemm:\n",
    "        d[item] += 1\n",
    "    tokens=[key for key,value in d.items() if value>freq_threshold] #all words with frequency of more than some number\n",
    "    texts = [word for word in lemm if word in tokens]\n",
    "    texts = \" \".join(texts)\n",
    "    articles_cleaned.append(texts)\n",
    "    print(texts)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaai', 'ab', 'ability', 'able', 'abstract', 'access', 'account', 'accuracy', 'achieve', 'acm', 'acquire', 'acquisition', 'action', 'activation', 'activity', 'actual', 'acyclic', 'adaptation', 'adaptive', 'add', 'addition', 'address', 'adjacent', 'adjust', 'advertising', 'ai', 'aic', 'aid', 'aim', 'ais', 'al', 'algorithm', 'algorithmic', 'aliase', 'alice', 'align', 'allow', 'alpha', 'alphago', 'alphazero', 'analysis', 'analyze', 'ann', 'anneal', 'annotation', 'anns', 'annual', 'anomaly', 'answer', 'ant', 'anti', 'antibody', 'ap', 'application', 'apply', 'approach', 'appropriate', 'approx', 'approximate', 'approximation', 'aptitude', 'arbitrary', 'architecture', 'area', 'argmax', 'argmin', 'argue', 'argument', 'arise', 'arity', 'array', 'arrive', 'arrow', 'art', 'artificial', 'ask', 'asr', 'assess', 'assign', 'assignment', 'associate', 'association', 'assume', 'assumption', 'assure', 'attempt', 'attribute', 'auditory', 'author', 'automate', 'automatic', 'automatically', 'autonomous', 'available', 'average', 'averaging', 'award', 'axis', 'background', 'backpropagation', 'bag', 'bagging', 'ball', 'base', 'basic', 'batch', 'baum', 'baye', 'bayesian', 'beach', 'beat', 'bee', 'begin', 'behavior', 'belief', 'belong', 'benchmark', 'beta', 'better', 'bias', 'big', 'bigl', 'bigr', 'binary', 'biological', 'bit', 'blanket', 'block', 'blood', 'bma', 'bmc', 'board', 'bob', 'boldsymbol', 'book', 'boolean', 'boost', 'border', 'bouldin', 'boundary', 'brain', 'branch', 'broad', 'bucket', 'build', 'building', 'caa', 'call', 'camera', 'cancer', 'candidate', 'canonical', 'cap', 'capable', 'capacity', 'capitalize', 'car', 'care', 'case', 'cat', 'categorical', 'category', 'cattell', 'causal', 'causality', 'causation', 'cause', 'cdot', 'cell', 'cellular', 'center', 'centroid', 'certain', 'cfi', 'chain', 'challenge', 'champion', 'chance', 'change', 'characteristic', 'chess', 'child', 'chinese', 'choice', 'choose', 'chromosome', 'chunk', 'citeseer', 'cl', 'claim', 'class', 'classification', 'classifier', 'classify', 'clause', 'click', 'climb', 'clique', 'clonal', 'close', 'closely', 'cluster', 'clustering', 'cnn', 'cnns', 'code', 'coefficient', 'collection', 'colony', 'color', 'column', 'combination', 'combinatorial', 'combine', 'come', 'commercial', 'commission', 'common', 'commonly', 'communalitie', 'communality', 'community', 'compare', 'competitive', 'complete', 'complex', 'complexity', 'component', 'compose', 'computation', 'computational', 'compute', 'computer', 'computing', 'concentration', 'concept', 'concern', 'condition', 'conditional', 'conference', 'configuration', 'confusion', 'connect', 'connection', 'connectivity', 'consequence', 'consider', 'consist', 'consistency', 'constant', 'constraint', 'construct', 'contain', 'content', 'contest', 'context', 'continuous', 'contrast', 'control', 'convergence', 'convex', 'convolutional', 'coordinate', 'copy', 'correct', 'correlate', 'correlation', 'correspond', 'cost', 'count', 'cov', 'covariance', 'cover', 'cowle', 'create', 'cresceptron', 'criterion', 'cross', 'crossbar', 'crossover', 'current', 'custom', 'cutoff', 'dag', 'dan', 'dasgupta', 'data', 'database', 'dataset', 'datum', 'dau', 'day', 'dbscan', 'dc', 'dca', 'deal', 'december', 'decimate', 'decimation', 'decision', 'deep', 'deepmind', 'defeat', 'defense', 'define', 'definition', 'degree', 'delta', 'demonstrate', 'density', 'depend', 'dependency', 'dependent', 'depth', 'derive', 'descendant', 'descent', 'describe', 'description', 'design', 'desire', 'detect', 'detection', 'determine', 'develop', 'development', 'diagonal', 'diagram', 'dictionary', 'differ', 'difference', 'different', 'difficult', 'digital', 'dimension', 'dimensional', 'dimensionality', 'direct', 'directly', 'dirichlet', 'discipline', 'discourse', 'discover', 'discovery', 'discrete', 'discriminant', 'disease', 'display', 'displaystyle', 'distance', 'distinct', 'distribution', 'diversity', 'divide', 'dnn', 'dnns', 'document', 'dog', 'doi', 'domain', 'door', 'dot', 'downsample', 'draw', 'drop', 'drug', 'dt', 'dual', 'dunn', 'dw', 'dynamic', 'ea', 'early', 'easily', 'economic', 'ed', 'edge', 'edu', 'efa', 'effect', 'efficiency', 'efficient', 'efficiently', 'eigenvalue', 'eigenvector', 'elbow', 'element', 'ell', 'email', 'embed', 'emission', 'emotion', 'empirical', 'employ', 'encode', 'end', 'energy', 'engineer', 'engineering', 'english', 'ensemble', 'entailment', 'entity', 'environment', 'epidemiology', 'equal', 'equation', 'error', 'especially', 'estimate', 'estimation', 'et', 'eta', 'evaluate', 'evaluation', 'event', 'evidence', 'evolution', 'evolutionary', 'evolve', 'exact', 'example', 'exchange', 'exist', 'exp', 'expect', 'expectation', 'experience', 'experimental', 'expert', 'explain', 'explanatory', 'exploratory', 'explore', 'express', 'expression', 'extend', 'extension', 'external', 'extra', 'extract', 'extraction', 'fa', 'fabrigar', 'face', 'facebook', 'fact', 'factor', 'factoring', 'factorize', 'fail', 'false', 'family', 'fan', 'feature', 'feedforward', 'fem', 'field', 'filter', 'financial', 'find', 'finite', 'fit', 'fitness', 'fix', 'flow', 'fn', 'focus', 'follow', 'forecasting', 'foreground', 'forest', 'form', 'formula', 'forward', 'fouri', 'fourth', 'fowlke', 'fp', 'frac', 'frame', 'framework', 'fraud', 'free', 'frequency', 'frequentist', 'frequently', 'function', 'future', 'ga', 'gain', 'game', 'gamma', 'gas', 'gather', 'gaussian', 'gda', 'gene', 'general', 'generalization', 'generally', 'generate', 'generation', 'generative', 'genetic', 'genexprotool', 'genie', 'genome', 'genotype', 'geometry', 'gep', 'geq', 'give', 'global', 'glover', 'goal', 'good', 'google', 'govern', 'gp', 'gpus', 'gradient', 'gram', 'grammar', 'graph', 'graphic', 'graphical', 'graphs', 'grass', 'ground', 'group', 'growth', 'guarantee', 'guidance', 'guide', 'guideline', 'hand', 'handicap', 'handle', 'handwritten', 'hard', 'hardware', 'hat', 'haussler', 'head', 'health', 'hebbian', 'help', 'heuristic', 'hidden', 'hide', 'hierarchical', 'high', 'hill', 'hinge', 'histogram', 'hit', 'hmm', 'hmms', 'holland', 'homeotic', 'house', 'ht', 'html', 'http', 'huang', 'hui', 'human', 'hyperparameter', 'hyperplane', 'hypothesis', 'identification', 'identify', 'ilp', 'image', 'imagenet', 'immune', 'immunology', 'implement', 'implementation', 'imply', 'important', 'improve', 'include', 'increase', 'independence', 'independent', 'index', 'indexthe', 'indicate', 'indicator', 'individual', 'induce', 'induction', 'inductive', 'industrial', 'industry', 'infer', 'inference', 'influence', 'information', 'infty', 'initial', 'initially', 'inner', 'input', 'insertion', 'inspection', 'inspire', 'instance', 'instead', 'integer', 'integrate', 'intelligence', 'inter', 'interaction', 'interactive', 'interface', 'internal', 'interpret', 'interpretation', 'intervention', 'intra', 'introduce', 'introduction', 'inverse', 'inversion', 'involve', 'isbn', 'ise', 'issue', 'ist', 'item', 'iteration', 'iterative', 'jaccard', 'january', 'java', 'jie', 'john', 'joint', 'journal', 'jöreskog', 'karl', 'ke', 'kearn', 'kernel', 'kind', 'knapsack', 'know', 'knowledge', 'korea', 'koza', 'label', 'labelme', 'lack', 'lambda', 'land', 'landscape', 'langle', 'language', 'laplacian', 'large', 'latent', 'later', 'law', 'layer', 'lda', 'ldot', 'lead', 'learn', 'learning', 'leave', 'lee', 'leftarrow', 'leiman', 'length', 'leq', 'let', 'level', 'library', 'lie', 'life', 'lifeguard', 'light', 'like', 'likelihood', 'likely', 'line', 'linear', 'linearly', 'link', 'linkage', 'lisrel', 'list', 'literal', 'ln', 'lnot', 'load', 'loading', 'local', 'log', 'logic', 'logistic', 'long', 'look', 'lor', 'lose', 'loss', 'low', 'lstm', 'lvert', 'machine', 'main', 'maintain', 'major', 'make', 'mallow', 'malware', 'manifold', 'manipulation', 'map', 'margin', 'mark', 'market', 'markov', 'mass', 'master', 'match', 'mathbb', 'mathbf', 'mathcal', 'mathematical', 'mathrm', 'matrix', 'max', 'maximization', 'maximize', 'maximum', 'mean', 'measure', 'measurement', 'medical', 'member', 'memetic', 'memm', 'memory', 'mercer', 'meta', 'metaheuristic', 'method', 'methodology', 'mid', 'military', 'million', 'minimization', 'minimize', 'mining', 'missile', 'mixture', 'mobile', 'model', 'modeler', 'modification', 'molecular', 'moment', 'morphology', 'motion', 'move', 'mrf', 'mrfs', 'mt', 'mu', 'multi', 'multicellular', 'multiclass', 'multigenic', 'multiple', 'mutate', 'mutation', 'mutual', 'na', 'naive', 'name', 'native', 'natural', 'nature', 'near', 'nearest', 'necessarily', 'necessity', 'need', 'neg', 'negated', 'negative', 'neighbor', 'net', 'network', 'neural', 'neuron', 'new', 'nicosia', 'nlp', 'nmax', 'nmf', 'nn', 'node', 'noise', 'noisy', 'nominal', 'non', 'nonlinear', 'nonstationary', 'norm', 'normal', 'note', 'noun', 'number', 'numeral', 'numeric', 'numerical', 'object', 'objective', 'oblique', 'observable', 'observation', 'observe', 'observed', 'observer', 'obtain', 'occur', 'october', 'official', 'offspring', 'omega', 'open', 'operation', 'operator', 'operatorname', 'optic', 'optical', 'optimal', 'optimization', 'optimize', 'optimum', 'order', 'ordering', 'organism', 'organize', 'original', 'orthogonal', 'outcome', 'outlier', 'outline', 'output', 'overfitte', 'overlap', 'pa', 'pac', 'package', 'page', 'pair', 'panel', 'par', 'parallel', 'paramet', 'parameter', 'parent', 'parse', 'partial', 'partially', 'particle', 'particular', 'particularly', 'partition', 'partitioning', 'path', 'pattern', 'pc', 'pca', 'pdf', 'penalty', 'penguin', 'people', 'perception', 'perceptron', 'perform', 'performance', 'perp', 'person', 'personality', 'phase', 'phenomenon', 'phenotype', 'physics', 'pi', 'platform', 'play', 'player', 'pls', 'pm', 'pmml', 'point', 'poisson', 'policy', 'polygon', 'polynomial', 'pool', 'popular', 'population', 'pose', 'position', 'positive', 'possible', 'posterior', 'potential', 'potentially', 'power', 'powerful', 'pp', 'pr', 'pre', 'precision', 'predict', 'prediction', 'predictive', 'preprocesse', 'preserve', 'press', 'prevent', 'previous', 'previously', 'primal', 'primarily', 'principal', 'principle', 'prior', 'probabilistic', 'probability', 'probably', 'problem', 'procedure', 'proceeding', 'process', 'processing', 'produce', 'product', 'professional', 'progol', 'program', 'programming', 'progress', 'project', 'projection', 'promote', 'property', 'propose', 'prove', 'provide', 'psu', 'psychology', 'psychometric', 'publication', 'publish', 'purity', 'purpose', 'quadratic', 'quality', 'quantitative', 'quantity', 'query', 'question', 'rain', 'rainy', 'rand', 'random', 'randomly', 'range', 'rangle', 'rank', 'rate', 'raw', 'reach', 'real', 'reason', 'recall', 'receive', 'recent', 'recognition', 'recognize', 'recombination', 'recombine', 'recommendation', 'reconstruction', 'record', 'recurrent', 'red', 'reduce', 'reduction', 'refer', 'region', 'regression', 'regret', 'regularization', 'regularize', 'reinforcement', 'relate', 'related', 'relationship', 'relative', 'relevant', 'removal', 'replace', 'replication', 'report', 'represent', 'representation', 'reproduction', 'require', 'research', 'researcher', 'residual', 'resignation', 'resource', 'respect', 'result', 'retain', 'return', 'right', 'rightarrow', 'risk', 'rnc', 'rnn', 'robot', 'root', 'rotation', 'roulette', 'rule', 'run', 'rvert', 'sage', 'sample', 'sampler', 'say', 'scale', 'scanner', 'scene', 'schemata', 'scheme', 'schmid', 'science', 'scientific', 'score', 'scree', 'search', 'second', 'sedol', 'see', 'seek', 'segmentation', 'select', 'selection', 'self', 'sem', 'semantic', 'semi', 'sense', 'sensor', 'sentence', 'separate', 'separation', 'sequence', 'serve', 'server', 'set', 'sgn', 'shallow', 'shape', 'shift', 'short', 'show', 'sigma', 'sign', 'signal', 'significant', 'significantly', 'silhouette', 'sim', 'similar', 'similarity', 'simple', 'simplicity', 'simulate', 'simulation', 'simulator', 'simultaneous', 'single', 'situation', 'size', 'small', 'smooth', 'smoothness', 'social', 'soft', 'software', 'solution', 'solve', 'sound', 'south', 'space', 'sparse', 'speak', 'speaker', 'special', 'specific', 'specifically', 'specify', 'speech', 'speed', 'springer', 'sprinkler', 'sps', 'square', 'squared', 'standard', 'standardize', 'star', 'start', 'state', 'statistic', 'statistical', 'step', 'stochastic', 'stone', 'strategy', 'strength', 'string', 'strong', 'structural', 'structure', 'structured', 'student', 'study', 'style', 'sub', 'subject', 'subjective', 'subset', 'subspace', 'subtask', 'success', 'successfully', 'successor', 'sufficiency', 'suggest', 'suit', 'sum', 'summit', 'sunny', 'supervise', 'supervised', 'support', 'suppose', 'svm', 'svms', 'swarm', 'symbol', 'symbolic', 'symmetric', 'system', 'table', 'tabu', 'tag', 'tail', 'take', 'tame', 'target', 'task', 'team', 'technique', 'technology', 'temporal', 'tend', 'term', 'terminal', 'test', 'testing', 'text', 'textit', 'textstyle', 'textual', 'tfrac', 'th', 'theorem', 'theoretical', 'theory', 'theta', 'think', 'threshold', 'tie', 'time', 'timit', 'title', 'tlearn', 'tn', 'tool', 'toolkit', 'topic', 'total', 'tp', 'tracking', 'tractable', 'tradeoff', 'traditional', 'trail', 'train', 'training', 'transductive', 'transform', 'transition', 'translate', 'translation', 'transposition', 'traverse', 'tree', 'trick', 'true', 'truth', 'tsvm', 'turn', 'tutorial', 'type', 'typical', 'typically', 'uncertainty', 'uncorrelated', 'underlie', 'underset', 'understand', 'understanding', 'undirected', 'uniform', 'unigram', 'unique', 'unit', 'unity', 'universal', 'university', 'unknown', 'unlabele', 'unlabeled', 'unobserved', 'unsupervised', 'urn', 'use', 'user', 'usual', 'usually', 'utility', 'valid', 'validation', 'value', 'vapnik', 'varepsilon', 'variable', 'variance', 'variant', 'variation', 'variety', 'varimax', 'varphi', 'vary', 'vdot', 'vec', 'vector', 'vehicle', 'verbal', 'verification', 'version', 'versus', 'victory', 'video', 'view', 'visible', 'vision', 'visual', 'visualization', 'viterbi', 'vladimir', 'vocabulary', 'vol', 'vote', 'waikato', 'warmuth', 'way', 'weak', 'weather', 'weight', 'weka', 'well', 'wet', 'wheel', 'win', 'wintempla', 'wold', 'word', 'wordnet', 'work', 'world', 'wright', 'write', 'year', 'yield', 'zealand', 'zen', 'zero', 'zeta']\n",
      "(63, 1317)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(articles_cleaned)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_names = []\n",
    "file = open(\"nodes.txt\", \"r\")\n",
    "for line in file:\n",
    "    article_names.append(line.rstrip(\"\\n\"))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<63x1317 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6404 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"article_name\"] = article_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to a file\n",
    "df.to_hdf(\"embeddings.h5\", key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaai</th>\n",
       "      <th>ab</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abstract</th>\n",
       "      <th>access</th>\n",
       "      <th>account</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieve</th>\n",
       "      <th>acm</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>wright</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>article_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Artificial_neural_networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neural_network_software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Deep_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applied_machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029068</td>\n",
       "      <td>0.055252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>AlphaGo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unsupervised_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Structured_prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Graphical_models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Bayesian_networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Causal_inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Markov_networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Loss_functions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>Support_vector_machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Latent_variable_models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Structural_equation_models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030832</td>\n",
       "      <td>0.019277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Factor_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cluster_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Clustering_criteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cluster_analysis_algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Signal_processing_conferences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.767445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Artificial_intelligence_conferences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Data_mining_and_machine_learning_software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Social_network_analysis_software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Machine_learning_algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Genetic_algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Artificial_immune_systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Gene_expression_programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Bayesian_networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Statistical_natural_language_processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Markov_networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Evolutionary_algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Genetic_programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Genetic_algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Artificial_immune_systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Gene_expression_programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Gene_expression_programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Nature-inspired_metaheuristics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Genetic_programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Datasets_in_machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Datasets_in_computer_vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Dimension_reduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030832</td>\n",
       "      <td>0.019277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Factor_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Machine_learning_researchers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Supervised_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Semisupervised_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Computational_learning_theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Kernel_methods_for_machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>Support_vector_machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Learning_in_computer_vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Inductive_logic_programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Log-linear_models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Classification_algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Ensemble_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Artificial_neural_networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neural_network_software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Deep_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Decision_trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Machine_learning_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Ensemble_learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 1318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aaai        ab   ability      able  abstract    access   account  \\\n",
       "0   0.000000  0.000000  0.024664  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.022439  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.024664  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.036182   \n",
       "16  0.000000  0.030832  0.019277  0.000000  0.000000  0.000000  0.061387   \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "21  0.767445  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "22  0.000000  0.000000  0.000000  0.000000  0.000000  0.181094  0.000000   \n",
       "23  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "24  0.000000  0.000000  0.024664  0.000000  0.000000  0.000000  0.000000   \n",
       "25  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "26  0.000000  0.000000  0.000000  0.000000  0.086748  0.000000  0.000000   \n",
       "27  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "28  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "33  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "34  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "35  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "36  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "37  0.000000  0.000000  0.000000  0.000000  0.086748  0.000000  0.000000   \n",
       "38  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "39  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "40  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "41  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "42  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "43  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "44  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "45  0.000000  0.030832  0.019277  0.000000  0.000000  0.000000  0.061387   \n",
       "46  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "47  0.000000  0.000000  0.000000  0.060839  0.000000  0.000000  0.000000   \n",
       "48  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "49  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "50  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "51  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "52  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "53  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "54  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "55  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "56  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "57  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "58  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "59  0.000000  0.000000  0.022439  0.000000  0.000000  0.000000  0.000000   \n",
       "60  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61  0.000000  0.000000  0.024664  0.000000  0.000000  0.000000  0.000000   \n",
       "62  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    accuracy   achieve       acm  ...     world    wright     write      year  \\\n",
       "0   0.043163  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.031660  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.022867   \n",
       "4   0.043163  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.036335  0.000000  ...  0.079808  0.000000  0.000000  0.030695   \n",
       "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  ...  0.000000  0.053537  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "21  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "22  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "23  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "24  0.043163  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "25  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "26  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "27  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "28  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.000000  ...  0.110025  0.000000  0.115769  0.000000   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "33  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "34  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "35  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "36  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "37  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "38  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "39  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "40  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "41  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "42  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "43  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "44  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "45  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "46  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "47  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "48  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "49  0.000000  0.000000  0.282484  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "50  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "51  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "52  0.000000  0.000000  0.000000  ...  0.030805  0.000000  0.000000  0.000000   \n",
       "53  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "54  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "55  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "56  0.058868  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "57  0.031660  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "58  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "59  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.022867   \n",
       "60  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "61  0.043163  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "62  0.058868  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       yield   zealand       zen      zero      zeta  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.029068  0.055252  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.032246   \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "16  0.025568  0.000000  0.000000  0.016370  0.000000   \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "21  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "22  0.000000  0.103482  0.000000  0.000000  0.000000   \n",
       "23  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "24  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "25  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "26  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "27  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "28  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...       ...       ...   \n",
       "33  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "34  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "35  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "36  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "37  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "38  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "39  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "40  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "41  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "42  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "43  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "44  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "45  0.025568  0.000000  0.000000  0.016370  0.000000   \n",
       "46  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "47  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "48  0.056653  0.000000  0.000000  0.000000  0.000000   \n",
       "49  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "50  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "51  0.000000  0.000000  0.000000  0.000000  0.032246   \n",
       "52  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "53  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "54  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "55  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "56  0.038244  0.000000  0.000000  0.000000  0.000000   \n",
       "57  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "58  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "59  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "62  0.038244  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                 article_name  \n",
       "0                            Machine_learning  \n",
       "1                  Artificial_neural_networks  \n",
       "2                     Neural_network_software  \n",
       "3                               Deep_learning  \n",
       "4                    Applied_machine_learning  \n",
       "5                                     AlphaGo  \n",
       "6                       Unsupervised_learning  \n",
       "7                       Structured_prediction  \n",
       "8                            Graphical_models  \n",
       "9                           Bayesian_networks  \n",
       "10                           Causal_inference  \n",
       "11                            Markov_networks  \n",
       "12                             Loss_functions  \n",
       "13                    Support_vector_machines  \n",
       "14                     Latent_variable_models  \n",
       "15                 Structural_equation_models  \n",
       "16                            Factor_analysis  \n",
       "17                           Cluster_analysis  \n",
       "18                        Clustering_criteria  \n",
       "19                Cluster_analysis_algorithms  \n",
       "20              Signal_processing_conferences  \n",
       "21        Artificial_intelligence_conferences  \n",
       "22  Data_mining_and_machine_learning_software  \n",
       "23           Social_network_analysis_software  \n",
       "24                Machine_learning_algorithms  \n",
       "25                         Genetic_algorithms  \n",
       "26                  Artificial_immune_systems  \n",
       "27                Gene_expression_programming  \n",
       "28                          Bayesian_networks  \n",
       "29    Statistical_natural_language_processing  \n",
       "..                                        ...  \n",
       "33                            Markov_networks  \n",
       "34                    Evolutionary_algorithms  \n",
       "35                        Genetic_programming  \n",
       "36                         Genetic_algorithms  \n",
       "37                  Artificial_immune_systems  \n",
       "38                Gene_expression_programming  \n",
       "39                Gene_expression_programming  \n",
       "40             Nature-inspired_metaheuristics  \n",
       "41                        Genetic_programming  \n",
       "42               Datasets_in_machine_learning  \n",
       "43                Datasets_in_computer_vision  \n",
       "44                        Dimension_reduction  \n",
       "45                            Factor_analysis  \n",
       "46               Machine_learning_researchers  \n",
       "47                        Supervised_learning  \n",
       "48                    Semisupervised_learning  \n",
       "49              Computational_learning_theory  \n",
       "50        Kernel_methods_for_machine_learning  \n",
       "51                    Support_vector_machines  \n",
       "52                Learning_in_computer_vision  \n",
       "53                Inductive_logic_programming  \n",
       "54                          Log-linear_models  \n",
       "55                  Classification_algorithms  \n",
       "56                          Ensemble_learning  \n",
       "57                 Artificial_neural_networks  \n",
       "58                    Neural_network_software  \n",
       "59                              Deep_learning  \n",
       "60                             Decision_trees  \n",
       "61                      Machine_learning_task  \n",
       "62                          Ensemble_learning  \n",
       "\n",
       "[63 rows x 1318 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read from file\n",
    "pd.read_hdf(\"embeddings.h5\", 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
